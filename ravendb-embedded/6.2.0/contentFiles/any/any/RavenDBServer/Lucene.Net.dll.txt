public abstract class Lucene.Net.Analysis.Analyzer : object {
    private LightWeightThreadLocal`1<object> tokenStreams;
    private bool isDisposed;
    [ObsoleteAttribute]
protected internal bool overridesTokenStreamMethod;
    protected internal object PreviousTokenStream { get; protected internal set; }
    public abstract virtual TokenStream TokenStream(string fieldName, TextReader reader);
    public virtual TokenStream ReusableTokenStream(string fieldName, TextReader reader);
    protected internal virtual object get_PreviousTokenStream();
    protected internal virtual void set_PreviousTokenStream(object value);
    [ObsoleteAttribute("This is only present to preserve back-compat of classes that subclass a core analyzer and override tokenStream but not reusableTokenStream ")]
protected internal virtual void SetOverridesTokenStreamMethod();
    public virtual int GetPositionIncrementGap(string fieldName);
    public virtual int GetOffsetGap(IFieldable field);
    public void Close();
    public virtual void Dispose();
    protected virtual void Dispose(bool disposing);
}
public class Lucene.Net.Analysis.ASCIIFoldingFilter : TokenFilter {
    private Char[] output;
    private int outputPos;
    private ITermAttribute termAtt;
    public ASCIIFoldingFilter(TokenStream input);
    public virtual bool IncrementToken();
    public void FoldToASCII(Char[] input, int length);
}
public abstract class Lucene.Net.Analysis.BaseCharFilter : CharFilter {
    private Int32[] offsets;
    private Int32[] diffs;
    private int size;
    protected int LastCumulativeDiff { get; }
    protected BaseCharFilter(CharStream in);
    protected internal virtual int Correct(int currentOff);
    protected int get_LastCumulativeDiff();
    [ObsoleteAttribute("Use LastCumulativeDiff property instead")]
protected int GetLastCumulativeDiff();
    protected void AddOffCorrectMap(int off, int cumulativeDiff);
}
public class Lucene.Net.Analysis.CachingTokenFilter : TokenFilter {
    private LinkedList`1<State> cache;
    private IEnumerator`1<State> iterator;
    private State finalState;
    public CachingTokenFilter(TokenStream input);
    public virtual bool IncrementToken();
    public virtual void End();
    public virtual void Reset();
    private void FillCache();
}
public class Lucene.Net.Analysis.CharArraySet : object {
    private bool _ReadOnly;
    private static int INIT_SIZE;
    private Char[][] _Entries;
    private int _Count;
    private bool _IgnoreCase;
    public static CharArraySet EMPTY_SET;
    public int Count { get; }
    public bool IsEmpty { get; }
    public bool IsReadOnly { get; private set; }
    public CharArraySet(int startSize, bool ignoreCase);
    public CharArraySet(IEnumerable`1<string> c, bool ignoreCase);
    public CharArraySet(IEnumerable`1<object> c, bool ignoreCase);
    private CharArraySet(Char[][] entries, bool ignoreCase, int count);
    private static CharArraySet();
    private void Init(int startSize, bool ignoreCase);
    private void AddItems(IEnumerable`1<T> items);
    public virtual bool Contains(Char[] text, int off, int len);
    public virtual bool Contains(string text);
    private int GetSlot(Char[] text, int off, int len);
    private int GetSlot(string text);
    public sealed virtual bool Add(string text);
    public bool Add(Char[] text);
    private bool Equals(Char[] text1, int off, int len, Char[] text2);
    private bool Equals(string text1, Char[] text2);
    private void Rehash();
    private int GetHashCode(Char[] text, int offset, int len);
    private int GetHashCode(string text);
    public sealed virtual int get_Count();
    public bool get_IsEmpty();
    public bool Contains(object item);
    public bool Add(object item);
    private sealed virtual override void System.Collections.Generic.ICollection<System.String>.Add(string item);
    public static CharArraySet UnmodifiableSet(CharArraySet set);
    public static CharArraySet Copy(ISet`1<T> set);
    public sealed virtual void Clear();
    public sealed virtual bool get_IsReadOnly();
    private void set_IsReadOnly(bool value);
    public sealed virtual void UnionWith(IEnumerable`1<string> other);
    public void AddAll(IEnumerable`1<string> coll);
    public void RemoveAll(ICollection`1<string> c);
    public void RetainAll(ICollection`1<string> c);
    private sealed virtual override void System.Collections.Generic.ICollection<System.String>.CopyTo(String[] array, int arrayIndex);
    private sealed virtual override void System.Collections.Generic.ISet<System.String>.IntersectWith(IEnumerable`1<string> other);
    private sealed virtual override void System.Collections.Generic.ISet<System.String>.ExceptWith(IEnumerable`1<string> other);
    private sealed virtual override void System.Collections.Generic.ISet<System.String>.SymmetricExceptWith(IEnumerable`1<string> other);
    private sealed virtual override bool System.Collections.Generic.ISet<System.String>.IsSubsetOf(IEnumerable`1<string> other);
    private sealed virtual override bool System.Collections.Generic.ISet<System.String>.IsSupersetOf(IEnumerable`1<string> other);
    private sealed virtual override bool System.Collections.Generic.ISet<System.String>.IsProperSupersetOf(IEnumerable`1<string> other);
    private sealed virtual override bool System.Collections.Generic.ISet<System.String>.IsProperSubsetOf(IEnumerable`1<string> other);
    private sealed virtual override bool System.Collections.Generic.ISet<System.String>.Overlaps(IEnumerable`1<string> other);
    private sealed virtual override bool System.Collections.Generic.ISet<System.String>.SetEquals(IEnumerable`1<string> other);
    private sealed virtual override bool System.Collections.Generic.ICollection<System.String>.Remove(string item);
    public IEnumerator`1<string> StringEnumerator();
    public sealed virtual IEnumerator`1<string> GetEnumerator();
    private sealed virtual override IEnumerator System.Collections.IEnumerable.GetEnumerator();
}
public abstract class Lucene.Net.Analysis.CharFilter : CharStream {
    private long currentPosition;
    private bool isDisposed;
    protected internal CharStream input;
    protected internal CharFilter(CharStream in_Renamed);
    protected internal virtual int Correct(int currentOff);
    public virtual int CorrectOffset(int currentOff);
    protected virtual void Dispose(bool disposing);
    public virtual int Read(Char[] cbuf, int off, int len);
    public bool MarkSupported();
    public void Mark(int readAheadLimit);
    public void Reset();
}
public class Lucene.Net.Analysis.CharReader : CharStream {
    private long currentPosition;
    private bool isDisposed;
    internal StreamReader input;
    private CharReader(StreamReader in_Renamed);
    public static CharStream Get(TextReader input);
    public virtual int CorrectOffset(int currentOff);
    protected virtual void Dispose(bool disposing);
    public virtual int Read(Char[] cbuf, int off, int len);
    public bool MarkSupported();
    public void Mark(int readAheadLimit);
    public void Reset();
}
public abstract class Lucene.Net.Analysis.CharStream : StreamReader {
    protected CharStream(StreamReader reader);
    public abstract virtual int CorrectOffset(int currentOff);
}
public abstract class Lucene.Net.Analysis.CharTokenizer : Tokenizer {
    private int offset;
    private int bufferIndex;
    private int dataLen;
    private static int MAX_WORD_LEN;
    private static int IO_BUFFER_SIZE;
    private Char[] ioBuffer;
    private ITermAttribute termAtt;
    private IOffsetAttribute offsetAtt;
    protected CharTokenizer(TextReader input);
    protected CharTokenizer(AttributeSource source, TextReader input);
    protected CharTokenizer(AttributeFactory factory, TextReader input);
    protected internal abstract virtual bool IsTokenChar(char c);
    protected internal virtual char Normalize(char c);
    public virtual bool IncrementToken();
    public virtual void End();
    public virtual void Reset(TextReader input);
}
[ObsoleteAttribute("If you build a new index, use ASCIIFoldingFilter which covers a superset of Latin 1.  This class is included for use with existing indexes and will be removed in a future release (possible Lucene 4.0).")]
public class Lucene.Net.Analysis.ISOLatin1AccentFilter : TokenFilter {
    private Char[] output;
    private int outputPos;
    private ITermAttribute termAtt;
    public ISOLatin1AccentFilter(TokenStream input);
    public virtual bool IncrementToken();
    public void RemoveAccents(Char[] input, int length);
}
public class Lucene.Net.Analysis.KeywordAnalyzer : Analyzer {
    public virtual TokenStream TokenStream(string fieldName, TextReader reader);
    public virtual TokenStream ReusableTokenStream(string fieldName, TextReader reader);
}
public class Lucene.Net.Analysis.KeywordTokenizer : Tokenizer {
    private static int DEFAULT_BUFFER_SIZE;
    private bool done;
    private int finalOffset;
    private ITermAttribute termAtt;
    private IOffsetAttribute offsetAtt;
    public KeywordTokenizer(TextReader input);
    public KeywordTokenizer(TextReader input, int bufferSize);
    public KeywordTokenizer(AttributeSource source, TextReader input, int bufferSize);
    public KeywordTokenizer(AttributeFactory factory, TextReader input, int bufferSize);
    private void Init(int bufferSize);
    public virtual bool IncrementToken();
    public virtual void End();
    public virtual void Reset(TextReader input);
}
public class Lucene.Net.Analysis.LengthFilter : TokenFilter {
    internal int min;
    internal int max;
    private ITermAttribute termAtt;
    public LengthFilter(TokenStream in_Renamed, int min, int max);
    public virtual bool IncrementToken();
}
public class Lucene.Net.Analysis.LetterTokenizer : CharTokenizer {
    public LetterTokenizer(TextReader in);
    public LetterTokenizer(AttributeSource source, TextReader in);
    public LetterTokenizer(AttributeFactory factory, TextReader in);
    protected internal virtual bool IsTokenChar(char c);
}
public class Lucene.Net.Analysis.LowerCaseFilter : TokenFilter {
    private ITermAttribute termAtt;
    public LowerCaseFilter(TokenStream in);
    public virtual bool IncrementToken();
}
public class Lucene.Net.Analysis.LowerCaseTokenizer : LetterTokenizer {
    public LowerCaseTokenizer(TextReader in);
    public LowerCaseTokenizer(AttributeSource source, TextReader in);
    public LowerCaseTokenizer(AttributeFactory factory, TextReader in);
    protected internal virtual char Normalize(char c);
}
public class Lucene.Net.Analysis.MappingCharFilter : BaseCharFilter {
    private NormalizeCharMap normMap;
    private LinkedList`1<char> buffer;
    private string replacement;
    private int charPointer;
    private int nextCharCounter;
    public MappingCharFilter(NormalizeCharMap normMap, CharStream in);
    public MappingCharFilter(NormalizeCharMap normMap, TextReader in);
    public virtual int Read();
    private int NextChar();
    private void PushChar(int c);
    private void PushLastChar(int c);
    private NormalizeCharMap Match(NormalizeCharMap map);
    public virtual int Read(Char[] cbuf, int off, int len);
}
public class Lucene.Net.Analysis.NormalizeCharMap : object {
    internal HashMap`2<char, NormalizeCharMap> submap;
    internal string normStr;
    internal int diff;
    public virtual void Add(string singleMatch, string replacement);
}
public class Lucene.Net.Analysis.NumericTokenStream : TokenStream {
    public static string TOKEN_TYPE_FULL_PREC;
    public static string TOKEN_TYPE_LOWER_PREC;
    private ITermAttribute termAtt;
    private ITypeAttribute typeAtt;
    private IPositionIncrementAttribute posIncrAtt;
    private int shift;
    private int valSize;
    private int precisionStep;
    private long value_Renamed;
    public NumericTokenStream(int precisionStep);
    public NumericTokenStream(AttributeSource source, int precisionStep);
    public NumericTokenStream(AttributeFactory factory, int precisionStep);
    private void InitBlock();
    public NumericTokenStream SetLongValue(long value_Renamed);
    public NumericTokenStream SetIntValue(int value_Renamed);
    public NumericTokenStream SetDoubleValue(double value_Renamed);
    public NumericTokenStream SetFloatValue(float value_Renamed);
    public virtual void Reset();
    protected virtual void Dispose(bool disposing);
    public virtual bool IncrementToken();
    private bool IncrementTokenUnlikely();
    private T ThrowValueSizeIsNotValid();
    public virtual string ToString();
}
public class Lucene.Net.Analysis.PerFieldAnalyzerWrapper : Analyzer {
    private Analyzer defaultAnalyzer;
    private HashMap`2<string, Analyzer> analyzerMap;
    public PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer);
    public PerFieldAnalyzerWrapper(Analyzer defaultAnalyzer, IEnumerable`1<KeyValuePair`2<string, Analyzer>> fieldAnalyzers);
    public virtual void AddAnalyzer(string fieldName, Analyzer analyzer);
    public virtual TokenStream TokenStream(string fieldName, TextReader reader);
    public virtual TokenStream ReusableTokenStream(string fieldName, TextReader reader);
    public virtual int GetPositionIncrementGap(string fieldName);
    public virtual int GetOffsetGap(IFieldable field);
    public virtual string ToString();
}
public class Lucene.Net.Analysis.PorterStemFilter : TokenFilter {
    private PorterStemmer stemmer;
    private ITermAttribute termAtt;
    public PorterStemFilter(TokenStream in_Renamed);
    public virtual bool IncrementToken();
}
internal class Lucene.Net.Analysis.PorterStemmer : object {
    private Char[] b;
    private int i;
    private int j;
    private int k;
    private int k0;
    private bool dirty;
    private static int INC;
    private static int EXTRA;
    public int ResultLength { get; }
    public Char[] ResultBuffer { get; }
    public virtual void Reset();
    public virtual void Add(char ch);
    public virtual string ToString();
    public virtual int get_ResultLength();
    public virtual Char[] get_ResultBuffer();
    private bool Cons(int i);
    private int M();
    private bool Vowelinstem();
    private bool Doublec(int j);
    private bool Cvc(int i);
    private bool Ends(string s);
    internal virtual void Setto(string s);
    internal virtual void R(string s);
    private void Step1();
    private void Step2();
    private void Step3();
    private void Step4();
    private void Step5();
    private void Step6();
    public virtual string Stem(string s);
    public virtual bool Stem(Char[] word);
    public virtual bool Stem(Char[] wordBuffer, int offset, int wordLen);
    public virtual bool Stem(Char[] word, int wordLen);
    public virtual bool Stem();
    public virtual bool Stem(int i0);
}
public class Lucene.Net.Analysis.SimpleAnalyzer : Analyzer {
    public virtual TokenStream TokenStream(string fieldName, TextReader reader);
    public virtual TokenStream ReusableTokenStream(string fieldName, TextReader reader);
}
public class Lucene.Net.Analysis.Standard.StandardAnalyzer : Analyzer {
    private ISet`1<string> stopSet;
    private bool replaceInvalidAcronym;
    private bool enableStopPositionIncrements;
    public static ISet`1<string> STOP_WORDS_SET;
    private Version matchVersion;
    public static int DEFAULT_MAX_TOKEN_LENGTH;
    private int maxTokenLength;
    public int MaxTokenLength { get; public set; }
    public StandardAnalyzer(Version matchVersion);
    public StandardAnalyzer(Version matchVersion, ISet`1<string> stopWords);
    public StandardAnalyzer(Version matchVersion, FileInfo stopwords);
    public StandardAnalyzer(Version matchVersion, TextReader stopwords);
    private static StandardAnalyzer();
    public virtual TokenStream TokenStream(string fieldName, TextReader reader);
    public virtual int get_MaxTokenLength();
    public virtual void set_MaxTokenLength(int value);
    public virtual TokenStream ReusableTokenStream(string fieldName, TextReader reader);
}
public class Lucene.Net.Analysis.Standard.StandardFilter : TokenFilter {
    private static string APOSTROPHE_TYPE;
    private static string ACRONYM_TYPE;
    private ITypeAttribute typeAtt;
    private ITermAttribute termAtt;
    public StandardFilter(TokenStream in_Renamed);
    private static StandardFilter();
    public virtual bool IncrementToken();
}
public class Lucene.Net.Analysis.Standard.StandardTokenizer : Tokenizer {
    private StandardTokenizerImpl scanner;
    public static int ALPHANUM;
    public static int APOSTROPHE;
    public static int ACRONYM;
    public static int COMPANY;
    public static int EMAIL;
    public static int HOST;
    public static int NUM;
    public static int CJ;
    [ObsoleteAttribute("this solves a bug where HOSTs that end with '.' are identified as ACRONYMs.")]
public static int ACRONYM_DEP;
    public static String[] TOKEN_TYPES;
    private bool replaceInvalidAcronym;
    private int maxTokenLength;
    private ITermAttribute termAtt;
    private IOffsetAttribute offsetAtt;
    private IPositionIncrementAttribute posIncrAtt;
    private ITypeAttribute typeAtt;
    public int MaxTokenLength { get; public set; }
    public StandardTokenizer(Version matchVersion, TextReader input);
    public StandardTokenizer(Version matchVersion, AttributeSource source, TextReader input);
    public StandardTokenizer(Version matchVersion, AttributeFactory factory, TextReader input);
    private static StandardTokenizer();
    private void InitBlock();
    public int get_MaxTokenLength();
    public void set_MaxTokenLength(int value);
    private void Init(TextReader input, Version matchVersion);
    public virtual bool IncrementToken();
    public virtual void End();
    public virtual void Reset(TextReader reader);
    [ObsoleteAttribute("Remove in 3.X and make true the only valid value. See https://issues.apache.org/jira/browse/LUCENE-1068")]
public void SetReplaceInvalidAcronym(bool replaceInvalidAcronym);
}
internal class Lucene.Net.Analysis.Standard.StandardTokenizerImpl : object {
    public static int YYEOF;
    private static int ZZ_BUFFERSIZE;
    public static int YYINITIAL;
    private static string ZZ_CMAP_PACKED;
    private static Char[] ZZ_CMAP;
    private static Int32[] ZZ_ACTION;
    private static string ZZ_ACTION_PACKED_0;
    private static Int32[] ZZ_ROWMAP;
    private static string ZZ_ROWMAP_PACKED_0;
    private static Int32[] ZZ_TRANS;
    private static string ZZ_TRANS_PACKED_0;
    private static int ZZ_UNKNOWN_ERROR;
    private static int ZZ_NO_MATCH;
    private static int ZZ_PUSHBACK_2BIG;
    private static String[] ZZ_ERROR_MSG;
    private static Int32[] ZZ_ATTRIBUTE;
    private static string ZZ_ATTRIBUTE_PACKED_0;
    private TextReader zzReader;
    private int zzState;
    private int zzLexicalState;
    private Char[] zzBuffer;
    private int zzMarkedPos;
    private int zzPushbackPos;
    private int zzCurrentPos;
    private int zzStartRead;
    private int zzEndRead;
    private int yyline;
    private int yychar;
    private int yycolumn;
    private bool zzAtBOL;
    private bool zzAtEOF;
    public static int ALPHANUM;
    public static int APOSTROPHE;
    public static int ACRONYM;
    public static int COMPANY;
    public static int EMAIL;
    public static int HOST;
    public static int NUM;
    public static int CJ;
    [ObsoleteAttribute("this solves a bug where HOSTs that end with '.' are identified as ACRONYMs")]
public static int ACRONYM_DEP;
    public static String[] TOKEN_TYPES;
    internal StandardTokenizerImpl(TextReader in_Renamed);
    internal StandardTokenizerImpl(Stream in_Renamed);
    private static StandardTokenizerImpl();
    private static Int32[] ZzUnpackAction();
    private static int ZzUnpackAction(string packed, int offset, Int32[] result);
    private static Int32[] ZzUnpackRowMap();
    private static int ZzUnpackRowMap(string packed, int offset, Int32[] result);
    private static Int32[] ZzUnpackTrans();
    private static int ZzUnpackTrans(string packed, int offset, Int32[] result);
    private static Int32[] ZzUnpackAttribute();
    private static int ZzUnpackAttribute(string packed, int offset, Int32[] result);
    public int Yychar();
    internal void Reset(TextReader r);
    internal void GetText(Token t);
    internal void GetText(ITermAttribute t);
    private static Char[] ZzUnpackCMap(string packed);
    private bool ZzRefill();
    private bool ZzRefillUnlikely();
    public void Yyclose();
    public void Yyreset(TextReader reader);
    public int Yystate();
    public void Yybegin(int newState);
    public string Yytext();
    public char Yycharat(int pos);
    public int Yylength();
    private void ZzScanError(int errorCode);
    public virtual void Yypushback(int number);
    public virtual int GetNextToken();
}
public class Lucene.Net.Analysis.StopAnalyzer : Analyzer {
    private ISet`1<string> stopWords;
    private bool enablePositionIncrements;
    public static ISet`1<string> ENGLISH_STOP_WORDS_SET;
    public StopAnalyzer(Version matchVersion);
    public StopAnalyzer(Version matchVersion, ISet`1<string> stopWords);
    public StopAnalyzer(Version matchVersion, FileInfo stopwordsFile);
    public StopAnalyzer(Version matchVersion, TextReader stopwords);
    private static StopAnalyzer();
    public virtual TokenStream TokenStream(string fieldName, TextReader reader);
    public virtual TokenStream ReusableTokenStream(string fieldName, TextReader reader);
}
public class Lucene.Net.Analysis.StopFilter : TokenFilter {
    private CharArraySet stopWords;
    private bool enablePositionIncrements;
    private ITermAttribute termAtt;
    private IPositionIncrementAttribute posIncrAtt;
    public bool EnablePositionIncrements { get; public set; }
    public StopFilter(bool enablePositionIncrements, TokenStream input, ISet`1<string> stopWords, bool ignoreCase);
    public StopFilter(bool enablePositionIncrements, TokenStream in, ISet`1<string> stopWords);
    public static ISet`1<string> MakeStopSet(String[] stopWords);
    public static ISet`1<string> MakeStopSet(IList`1<object> stopWords);
    public static ISet`1<string> MakeStopSet(String[] stopWords, bool ignoreCase);
    public static ISet`1<string> MakeStopSet(IList`1<object> stopWords, bool ignoreCase);
    public virtual bool IncrementToken();
    public static bool GetEnablePositionIncrementsVersionDefault(Version matchVersion);
    public bool get_EnablePositionIncrements();
    public void set_EnablePositionIncrements(bool value);
}
public class Lucene.Net.Analysis.TeeSinkTokenFilter : TokenFilter {
    private LinkedList`1<WeakReference> sinks;
    private static SinkFilter ACCEPT_ALL_FILTER;
    public TeeSinkTokenFilter(TokenStream input);
    private static TeeSinkTokenFilter();
    public SinkTokenStream NewSinkTokenStream();
    public SinkTokenStream NewSinkTokenStream(SinkFilter filter);
    public void AddSinkTokenStream(SinkTokenStream sink);
    public void ConsumeAllTokens();
    public virtual bool IncrementToken();
    public virtual void End();
}
public class Lucene.Net.Analysis.Token : Attribute {
    public static string DEFAULT_TYPE;
    private static int MIN_BUFFER_SIZE;
    private Char[] termBuffer;
    private int termLength;
    private int startOffset;
    private int endOffset;
    private string type;
    private int flags;
    private Payload payload;
    private int positionIncrement;
    public static AttributeFactory TOKEN_ATTRIBUTE_FACTORY;
    public int PositionIncrement { get; public set; }
    public string Term { get; }
    public int StartOffset { get; public set; }
    public int EndOffset { get; public set; }
    public string Type { get; public set; }
    public int Flags { get; public set; }
    public Payload Payload { get; public set; }
    public Token(int start, int end);
    public Token(int start, int end, string typ);
    public Token(int start, int end, int flags);
    public Token(string text, int start, int end);
    public Token(string text, int start, int end, string typ);
    public Token(string text, int start, int end, int flags);
    public Token(Char[] startTermBuffer, int termBufferOffset, int termBufferLength, int start, int end);
    private static Token();
    public virtual void set_PositionIncrement(int value);
    public virtual int get_PositionIncrement();
    public sealed virtual string get_Term();
    public sealed virtual void SetTermBuffer(Char[] buffer, int offset, int length);
    public sealed virtual void SetTermBuffer(string buffer);
    public sealed virtual void SetTermBuffer(string buffer, int offset, int length);
    public sealed virtual Char[] TermBuffer();
    public virtual Char[] ResizeTermBuffer(int newSize);
    private void GrowTermBuffer(int newSize);
    private void InitTermBuffer();
    public sealed virtual int TermLength();
    public sealed virtual void SetTermLength(int length);
    public virtual int get_StartOffset();
    public virtual void set_StartOffset(int value);
    public virtual int get_EndOffset();
    public virtual void set_EndOffset(int value);
    public virtual void SetOffset(int startOffset, int endOffset);
    public sealed virtual string get_Type();
    public sealed virtual void set_Type(string value);
    public virtual int get_Flags();
    public virtual void set_Flags(int value);
    public virtual Payload get_Payload();
    public virtual void set_Payload(Payload value);
    public virtual string ToString();
    public virtual void Clear();
    public virtual object Clone();
    public virtual Token Clone(Char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset);
    public virtual bool Equals(object obj);
    private bool SubEqual(object o1, object o2);
    public virtual int GetHashCode();
    private void ClearNoTermBuffer();
    public virtual Token Reinit(Char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset, string newType);
    public virtual Token Reinit(Char[] newTermBuffer, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset);
    public virtual Token Reinit(string newTerm, int newStartOffset, int newEndOffset, string newType);
    public virtual Token Reinit(string newTerm, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset, string newType);
    public virtual Token Reinit(string newTerm, int newStartOffset, int newEndOffset);
    public virtual Token Reinit(string newTerm, int newTermOffset, int newTermLength, int newStartOffset, int newEndOffset);
    public virtual void Reinit(Token prototype);
    public virtual void Reinit(Token prototype, string newTerm);
    public virtual void Reinit(Token prototype, Char[] newTermBuffer, int offset, int length);
    public virtual void CopyTo(Attribute target);
}
public class Lucene.Net.Analysis.Tokenattributes.FlagsAttribute : Attribute {
    private int flags;
    public int Flags { get; public set; }
    public sealed virtual int get_Flags();
    public sealed virtual void set_Flags(int value);
    public virtual void Clear();
    public virtual bool Equals(object other);
    public virtual int GetHashCode();
    public virtual void CopyTo(Attribute target);
    public virtual object Clone();
}
public interface Lucene.Net.Analysis.Tokenattributes.IFlagsAttribute {
    public int Flags { get; public set; }
    public abstract virtual int get_Flags();
    public abstract virtual void set_Flags(int value);
}
public interface Lucene.Net.Analysis.Tokenattributes.IOffsetAttribute {
    public int StartOffset { get; }
    public int EndOffset { get; }
    public abstract virtual int get_StartOffset();
    public abstract virtual void SetOffset(int startOffset, int endOffset);
    public abstract virtual int get_EndOffset();
}
public interface Lucene.Net.Analysis.Tokenattributes.IPayloadAttribute {
    public Payload Payload { get; public set; }
    public abstract virtual Payload get_Payload();
    public abstract virtual void set_Payload(Payload value);
}
public interface Lucene.Net.Analysis.Tokenattributes.IPositionIncrementAttribute {
    public int PositionIncrement { get; public set; }
    public abstract virtual void set_PositionIncrement(int value);
    public abstract virtual int get_PositionIncrement();
}
public interface Lucene.Net.Analysis.Tokenattributes.ITermAttribute {
    public string Term { get; }
    public abstract virtual string get_Term();
    public abstract virtual void SetTermBuffer(Char[] buffer, int offset, int length);
    public abstract virtual void SetTermBuffer(string buffer);
    public abstract virtual void SetTermBuffer(string buffer, int offset, int length);
    public abstract virtual Char[] TermBuffer();
    public abstract virtual Char[] ResizeTermBuffer(int newSize);
    public abstract virtual int TermLength();
    public abstract virtual void SetTermLength(int length);
}
public interface Lucene.Net.Analysis.Tokenattributes.ITypeAttribute {
    public string Type { get; public set; }
    public abstract virtual string get_Type();
    public abstract virtual void set_Type(string value);
}
public class Lucene.Net.Analysis.Tokenattributes.OffsetAttribute : Attribute {
    private int startOffset;
    private int endOffset;
    public int StartOffset { get; }
    public int EndOffset { get; }
    public sealed virtual int get_StartOffset();
    public sealed virtual void SetOffset(int startOffset, int endOffset);
    public sealed virtual int get_EndOffset();
    public virtual void Clear();
    public void ClearFast();
    public virtual bool Equals(object other);
    public virtual int GetHashCode();
    public virtual void CopyTo(Attribute target);
    public virtual object Clone();
}
public class Lucene.Net.Analysis.Tokenattributes.PayloadAttribute : Attribute {
    private Payload payload;
    public Payload Payload { get; public set; }
    public PayloadAttribute(Payload payload);
    public sealed virtual Payload get_Payload();
    public sealed virtual void set_Payload(Payload value);
    public virtual void Clear();
    public virtual object Clone();
    public virtual bool Equals(object other);
    public virtual int GetHashCode();
    public virtual void CopyTo(Attribute target);
}
public class Lucene.Net.Analysis.Tokenattributes.PositionIncrementAttribute : Attribute {
    private int positionIncrement;
    public int PositionIncrement { get; public set; }
    public sealed virtual void set_PositionIncrement(int value);
    public sealed virtual int get_PositionIncrement();
    private int ThrowIncrementGreaterThanZero(int value);
    public virtual void Clear();
    public void ClearFast();
    public virtual bool Equals(object other);
    public virtual int GetHashCode();
    public virtual void CopyTo(Attribute target);
    public virtual object Clone();
}
public class Lucene.Net.Analysis.Tokenattributes.TermAttribute : Attribute {
    private static int MIN_BUFFER_SIZE;
    private Char[] termBuffer;
    private int termLength;
    public string Term { get; }
    private static TermAttribute();
    public sealed virtual string get_Term();
    public sealed virtual void SetTermBuffer(Char[] buffer, int offset, int length);
    public sealed virtual void SetTermBuffer(string buffer);
    public sealed virtual void SetTermBuffer(string buffer, int offset, int length);
    public sealed virtual Char[] TermBuffer();
    public sealed virtual Char[] ResizeTermBuffer(int newSize);
    private void GrowTermBuffer(int newSize);
    private void InitTermBuffer();
    public sealed virtual int TermLength();
    public sealed virtual void SetTermLength(int length);
    private void ThrowLengthExceedsTermBuffer(int length);
    public virtual int GetHashCode();
    public virtual void Clear();
    public void ClearFast();
    public virtual object Clone();
    public virtual bool Equals(object other);
    public virtual string ToString();
    public virtual void CopyTo(Attribute target);
}
public class Lucene.Net.Analysis.Tokenattributes.TypeAttribute : Attribute {
    private string type;
    public static string DEFAULT_TYPE;
    public string Type { get; public set; }
    public TypeAttribute(string type);
    public sealed virtual string get_Type();
    public sealed virtual void set_Type(string value);
    public virtual void Clear();
    public void ClearFast();
    public virtual bool Equals(object other);
    public virtual int GetHashCode();
    public virtual void CopyTo(Attribute target);
    public virtual object Clone();
}
public abstract class Lucene.Net.Analysis.TokenFilter : TokenStream {
    protected internal TokenStream input;
    private bool isDisposed;
    protected internal TokenFilter(TokenStream input);
    public virtual void End();
    protected virtual void Dispose(bool disposing);
    public virtual void Reset();
}
public abstract class Lucene.Net.Analysis.Tokenizer : TokenStream {
    protected internal TextReader input;
    private bool isDisposed;
    protected internal Tokenizer(TextReader input);
    protected internal Tokenizer(AttributeFactory factory);
    protected internal Tokenizer(AttributeFactory factory, TextReader input);
    protected internal Tokenizer(AttributeSource source);
    protected internal Tokenizer(AttributeSource source, TextReader input);
    protected virtual void Dispose(bool disposing);
    protected internal int CorrectOffset(int currentOff);
    public virtual void Reset(TextReader input);
}
public abstract class Lucene.Net.Analysis.TokenStream : AttributeSource {
    protected internal TokenStream(AttributeSource input);
    protected internal TokenStream(AttributeFactory factory);
    public abstract virtual bool IncrementToken();
    public virtual void End();
    public virtual void Reset();
    [ObsoleteAttribute("Use Dispose() instead")]
public void Close();
    public sealed virtual void Dispose();
    protected abstract virtual void Dispose(bool disposing);
}
public class Lucene.Net.Analysis.WhitespaceAnalyzer : Analyzer {
    public virtual TokenStream TokenStream(string fieldName, TextReader reader);
    public virtual TokenStream ReusableTokenStream(string fieldName, TextReader reader);
}
public class Lucene.Net.Analysis.WhitespaceTokenizer : CharTokenizer {
    public WhitespaceTokenizer(TextReader in);
    public WhitespaceTokenizer(AttributeSource source, TextReader in);
    public WhitespaceTokenizer(AttributeFactory factory, TextReader in);
    protected internal virtual bool IsTokenChar(char c);
}
public class Lucene.Net.Analysis.WordlistLoader : object {
    public static ISet`1<string> GetWordSet(FileInfo wordfile);
    public static ISet`1<string> GetWordSet(FileInfo wordfile, string comment);
    public static ISet`1<string> GetWordSet(TextReader reader);
    public static ISet`1<string> GetWordSet(TextReader reader, string comment);
    public static Dictionary`2<string, string> GetStemDict(FileInfo wordstemfile);
}
public abstract class Lucene.Net.Documents.AbstractField : object {
    protected internal string internalName;
    protected internal bool storeTermVector;
    protected internal bool storeOffsetWithTermVector;
    protected internal bool storePositionWithTermVector;
    protected internal bool internalOmitNorms;
    protected internal bool internalIsStored;
    protected internal bool internalIsIndexed;
    protected internal bool internalIsTokenized;
    protected internal bool internalIsBinary;
    protected internal bool lazy;
    protected internal bool internalOmitTermFreqAndPositions;
    protected internal float internalBoost;
    protected internal object fieldsData;
    protected internal TokenStream tokenStream;
    protected internal int internalBinaryLength;
    protected internal int internalbinaryOffset;
    public float Boost { get; public set; }
    public string Name { get; }
    public bool IsStored { get; }
    public bool IsIndexed { get; }
    public bool IsTokenized { get; }
    public bool IsTermVectorStored { get; }
    public bool IsStoreOffsetWithTermVector { get; }
    public bool IsStorePositionWithTermVector { get; }
    public bool IsBinary { get; }
    public int BinaryLength { get; }
    public int BinaryOffset { get; }
    public bool OmitNorms { get; public set; }
    public bool OmitTermFreqAndPositions { get; public set; }
    public bool IsLazy { get; }
    public TokenStream TokenStreamValue { get; }
    public TextReader ReaderValue { get; }
    protected internal AbstractField(string name, Store store, Index index, TermVector termVector);
    public virtual float get_Boost();
    public virtual void set_Boost(float value);
    public virtual string get_Name();
    protected internal virtual void SetStoreTermVector(TermVector termVector);
    public sealed virtual bool get_IsStored();
    public sealed virtual bool get_IsIndexed();
    public sealed virtual bool get_IsTokenized();
    public sealed virtual bool get_IsTermVectorStored();
    public virtual bool get_IsStoreOffsetWithTermVector();
    public virtual bool get_IsStorePositionWithTermVector();
    public sealed virtual bool get_IsBinary();
    public virtual Byte[] GetBinaryValue(IState state);
    public virtual Byte[] GetBinaryValue(Byte[] result, IState state);
    public virtual int get_BinaryLength();
    public virtual int get_BinaryOffset();
    public virtual bool get_OmitNorms();
    public virtual void set_OmitNorms(bool value);
    public virtual void set_OmitTermFreqAndPositions(bool value);
    public virtual bool get_OmitTermFreqAndPositions();
    public virtual bool get_IsLazy();
    public virtual string ToString();
    public abstract virtual TokenStream get_TokenStreamValue();
    public abstract virtual TextReader get_ReaderValue();
    public abstract virtual string StringValue(IState state);
}
public class Lucene.Net.Documents.CompressionTools : object {
    public static Byte[] Compress(Byte[] value_Renamed, int offset, int length, int compressionLevel);
    public static Byte[] Compress(Byte[] value_Renamed, int offset, int length);
    public static Byte[] Compress(Byte[] value_Renamed);
    public static Byte[] CompressString(string value_Renamed);
    public static Byte[] CompressString(string value_Renamed, int compressionLevel);
    public static Byte[] Decompress(Byte[] value_Renamed);
    public static string DecompressString(Byte[] value_Renamed);
}
[ObsoleteAttribute("If you build a new index, use DateTools or NumericField instead.This class is included for use with existing indices and will be removed in a future release (possibly Lucene 4.0).")]
public class Lucene.Net.Documents.DateField : object {
    private static int DATE_LEN;
    private static DateField();
    public static string MIN_DATE_STRING();
    public static string MAX_DATE_STRING();
    public static string DateToString(DateTime date);
    public static string TimeToString(long time);
    public static long StringToTime(string s);
    public static DateTime StringToDate(string s);
}
public class Lucene.Net.Documents.DateTools : object {
    private static string YEAR_FORMAT;
    private static string MONTH_FORMAT;
    private static string DAY_FORMAT;
    private static string HOUR_FORMAT;
    private static string MINUTE_FORMAT;
    private static string SECOND_FORMAT;
    private static string MILLISECOND_FORMAT;
    private static Calendar calInstance;
    private static DateTools();
    public static string DateToString(DateTime date, Resolution resolution);
    public static string TimeToString(long time, Resolution resolution);
    public static long StringToTime(string dateString);
    public static DateTime StringToDate(string dateString);
    public static DateTime Round(DateTime date, Resolution resolution);
    public static long Round(long time, Resolution resolution);
}
public class Lucene.Net.Documents.Document : object {
    internal IList`1<IFieldable> fields;
    private float boost;
    private static Field[] NO_FIELDS;
    private static IFieldable[] NO_FIELDABLES;
    private static String[] NO_STRINGS;
    private static Byte[][] NO_BYTES;
    public float Boost { get; public set; }
    public IList`1<IFieldable> fields_ForNUnit { get; }
    private static Document();
    public float get_Boost();
    public void set_Boost(float value);
    public void Add(IFieldable field);
    public void RemoveField(string name);
    public void RemoveFields(string name);
    public Field GetField(string name);
    public IFieldable GetFieldable(string name);
    public string Get(string name, IState state);
    public IList`1<IFieldable> GetFields();
    public Field[] GetFields(string name);
    public IFieldable[] GetFieldables(string name);
    public String[] GetValues(string name, IState state);
    public Byte[][] GetBinaryValues(string name, IState state);
    public Byte[] GetBinaryValue(string name, IState state);
    public virtual string ToString();
    public IList`1<IFieldable> get_fields_ForNUnit();
}
public class Lucene.Net.Documents.Field : AbstractField {
    public TextReader ReaderValue { get; }
    public TokenStream TokenStreamValue { get; }
    public Field(string name, string value, Store store, Index index);
    public Field(string name, string value, Store store, Index index, TermVector termVector);
    public Field(string name, bool internName, string value, Store store, Index index, TermVector termVector);
    public Field(string name, TextReader reader);
    public Field(string name, TextReader reader, TermVector termVector);
    public Field(string name, TokenStream tokenStream);
    public Field(string name, TokenStream tokenStream, TermVector termVector);
    public Field(string name, Byte[] value_Renamed, Store store);
    public Field(string name, Byte[] value_Renamed, int offset, int length, Store store);
    public virtual string StringValue(IState state);
    public virtual TextReader get_ReaderValue();
    public virtual TokenStream get_TokenStreamValue();
    public void SetValue(string value);
    public void SetValue(TextReader value);
    public void SetValue(Byte[] value);
    public void SetValue(Byte[] value, int offset, int length);
    public void SetTokenStream(TokenStream tokenStream);
}
[ExtensionAttribute]
public static class Lucene.Net.Documents.FieldExtensions : object {
    [ExtensionAttribute]
public static bool IsStored(Store store);
    [ExtensionAttribute]
public static bool IsIndexed(Index index);
    [ExtensionAttribute]
public static bool IsAnalyzed(Index index);
    [ExtensionAttribute]
public static bool OmitNorms(Index index);
    [ExtensionAttribute]
public static bool IsStored(TermVector tv);
    [ExtensionAttribute]
public static bool WithPositions(TermVector tv);
    [ExtensionAttribute]
public static bool WithOffsets(TermVector tv);
    public static Index ToIndex(bool indexed, bool analyed);
    public static Index ToIndex(bool indexed, bool analyzed, bool omitNorms);
    public static TermVector ToTermVector(bool stored, bool withOffsets, bool withPositions);
}
public interface Lucene.Net.Documents.FieldSelector {
    public abstract virtual FieldSelectorResult Accept(string fieldName);
}
public enum Lucene.Net.Documents.FieldSelectorResult : Enum {
    public int value__;
    public static FieldSelectorResult INVALID;
    public static FieldSelectorResult LOAD;
    public static FieldSelectorResult LAZY_LOAD;
    public static FieldSelectorResult NO_LOAD;
    public static FieldSelectorResult LOAD_AND_BREAK;
    public static FieldSelectorResult SIZE;
    public static FieldSelectorResult SIZE_AND_BREAK;
}
public interface Lucene.Net.Documents.IFieldable {
    public float Boost { get; public set; }
    public string Name { get; }
    public TextReader ReaderValue { get; }
    public TokenStream TokenStreamValue { get; }
    public bool IsStored { get; }
    public bool IsIndexed { get; }
    public bool IsTokenized { get; }
    public bool IsTermVectorStored { get; }
    public bool IsStoreOffsetWithTermVector { get; }
    public bool IsStorePositionWithTermVector { get; }
    public bool IsBinary { get; }
    public bool OmitNorms { get; public set; }
    public bool IsLazy { get; }
    public int BinaryOffset { get; }
    public int BinaryLength { get; }
    public bool OmitTermFreqAndPositions { get; public set; }
    public abstract virtual float get_Boost();
    public abstract virtual void set_Boost(float value);
    public abstract virtual string get_Name();
    public abstract virtual string StringValue(IState state);
    public abstract virtual TextReader get_ReaderValue();
    public abstract virtual TokenStream get_TokenStreamValue();
    public abstract virtual bool get_IsStored();
    public abstract virtual bool get_IsIndexed();
    public abstract virtual bool get_IsTokenized();
    public abstract virtual bool get_IsTermVectorStored();
    public abstract virtual bool get_IsStoreOffsetWithTermVector();
    public abstract virtual bool get_IsStorePositionWithTermVector();
    public abstract virtual bool get_IsBinary();
    public abstract virtual bool get_OmitNorms();
    public abstract virtual void set_OmitNorms(bool value);
    public abstract virtual bool get_IsLazy();
    public abstract virtual int get_BinaryOffset();
    public abstract virtual int get_BinaryLength();
    public abstract virtual Byte[] GetBinaryValue(IState state);
    public abstract virtual Byte[] GetBinaryValue(Byte[] result, IState state);
    public abstract virtual void set_OmitTermFreqAndPositions(bool value);
    public abstract virtual bool get_OmitTermFreqAndPositions();
}
public class Lucene.Net.Documents.LoadFirstFieldSelector : object {
    public virtual FieldSelectorResult Accept(string fieldName);
}
public class Lucene.Net.Documents.MapFieldSelector : object {
    internal IDictionary`2<string, FieldSelectorResult> fieldSelections;
    public MapFieldSelector(IDictionary`2<string, FieldSelectorResult> fieldSelections);
    public MapFieldSelector(IList`1<string> fields);
    public MapFieldSelector(String[] fields);
    public virtual FieldSelectorResult Accept(string field);
}
[ObsoleteAttribute("For new indexes use NumericUtils instead, which provides a sortable binary representation (prefix encoded) of numeric values. To index and efficiently query numeric values use NumericField and NumericRangeQuery. This class is included for use with existing indices and will be removed in a future release (possibly Lucene 4.0).")]
public class Lucene.Net.Documents.NumberTools : object {
    private static int RADIX;
    private static char NEGATIVE_PREFIX;
    private static char POSITIVE_PREFIX;
    public static string MIN_STRING_VALUE;
    public static string MAX_STRING_VALUE;
    public static int STR_SIZE;
    private static string digits;
    private static Int64[] powersOf36;
    private static NumberTools();
    public static string LongToString(long l);
    public static long StringToLong(string str);
    public static string ToString(long lval);
    public static long ToLong(string t);
}
public class Lucene.Net.Documents.NumericField : AbstractField {
    private NumericTokenStream tokenStream;
    public TokenStream TokenStreamValue { get; }
    public TextReader ReaderValue { get; }
    public ValueType NumericValue { get; }
    public NumericField(string name);
    public NumericField(string name, Store store, bool index);
    public NumericField(string name, int precisionStep);
    public NumericField(string name, int precisionStep, Store store, bool index);
    public virtual TokenStream get_TokenStreamValue();
    public virtual Byte[] GetBinaryValue(Byte[] result, IState state);
    public virtual TextReader get_ReaderValue();
    public virtual string StringValue(IState state);
    public ValueType get_NumericValue();
    public NumericField SetLongValue(long value_Renamed);
    public NumericField SetIntValue(int value_Renamed);
    public NumericField SetDoubleValue(double value_Renamed);
    public NumericField SetFloatValue(float value_Renamed);
}
public class Lucene.Net.Documents.SetBasedFieldSelector : object {
    private ISet`1<string> fieldsToLoad;
    private ISet`1<string> lazyFieldsToLoad;
    public SetBasedFieldSelector(ISet`1<string> fieldsToLoad, ISet`1<string> lazyFieldsToLoad);
    public virtual FieldSelectorResult Accept(string fieldName);
}
public abstract class Lucene.Net.Index.AbstractAllTermDocs : object {
    protected int maxDoc;
    protected int internalDoc;
    public int Doc { get; }
    public int Freq { get; }
    protected AbstractAllTermDocs(int maxDoc);
    public sealed virtual void Seek(Term term, IState state);
    public sealed virtual void Seek(TermEnum termEnum, IState state);
    public sealed virtual int get_Doc();
    public sealed virtual int get_Freq();
    public sealed virtual bool Next(IState state);
    public sealed virtual int Read(Int32[] docs, Int32[] freqs, IState state);
    public sealed virtual bool SkipTo(int target, IState state);
    public sealed virtual void Close();
    public sealed virtual void Dispose();
    protected abstract virtual void Dispose(bool disposing);
    public abstract virtual bool IsDeleted(int doc);
}
internal class Lucene.Net.Index.AllTermDocs : AbstractAllTermDocs {
    protected internal BitVector deletedDocs;
    protected internal AllTermDocs(SegmentReader parent);
    protected virtual void Dispose(bool disposing);
    public virtual bool IsDeleted(int doc);
}
public class Lucene.Net.Index.ArrayHolder : object {
    private int _size;
    private Directory _directory;
    private string _name;
    private Int64[] _longArray;
    private Term[] _termArray;
    private TermInfo[] _termInfoArray;
    private int _usages;
    private long _managedAllocations;
    public static Action`1<long> OnArrayHolderCreated;
    public static Action`1<long> OnArrayHolderDisposed;
    public Span`1<long> LongArray { get; }
    public Span`1<TermInfo> InfoArray { get; }
    public Span`1<Term> IndexTerms { get; }
    public ArrayHolder(int size, Directory directory, string name);
    public Span`1<long> get_LongArray();
    public Span`1<TermInfo> get_InfoArray();
    public Span`1<Term> get_IndexTerms();
    public void AddRef();
    public void ReleaseRef();
    public static ArrayHolder GenerateArrayHolder(Directory directory, string name, FieldInfos fieldInfos, int readBufferSize, int indexDivisor, IState state);
    public sealed virtual void Dispose();
    protected virtual override void Finalize();
}
public class Lucene.Net.Index.ByteBlockPool : object {
    public Byte[][] buffers;
    internal int bufferUpto;
    public int byteUpto;
    public Byte[] buffer;
    public int byteOffset;
    private bool trackAllocations;
    private Allocator allocator;
    internal static Int32[] nextLevelArray;
    internal static Int32[] levelSizeArray;
    internal static int FIRST_LEVEL_SIZE;
    public static int FIRST_LEVEL_SIZE_For_NUnit_Test;
    public static int FIRST_LEVEL_SIZE_ForNUnit { get; }
    public ByteBlockPool(Allocator allocator, bool trackAllocations);
    private static ByteBlockPool();
    private void InitBlock();
    public void Reset();
    public void NextBuffer();
    public int NewSlice(int size);
    private int NewSliceUnlikely(int size);
    public int AllocSlice(Byte[] slice, int upto);
    public static int get_FIRST_LEVEL_SIZE_ForNUnit();
}
public class Lucene.Net.Index.ByteSliceReader : IndexInput {
    internal ByteBlockPool pool;
    internal int bufferUpto;
    internal Byte[] buffer;
    public int upto;
    internal int limit;
    internal int level;
    public int bufferOffset;
    public int endIndex;
    public void Init(ByteBlockPool pool, int startIndex, int endIndex);
    public bool Eof();
    public virtual byte ReadByte(IState state);
    public long WriteTo(IndexOutput out);
    public void NextSlice();
    public virtual void ReadBytes(Byte[] b, int offset, int len, IState state);
    public virtual long FilePointer(IState state);
    public virtual long Length(IState state);
    public virtual void Seek(long pos, IState state);
    protected virtual void Dispose(bool disposing);
    public virtual object Clone(IState state);
}
public class Lucene.Net.Index.ByteSliceWriter : object {
    private Byte[] slice;
    private int upto;
    private ByteBlockPool pool;
    internal int offset0;
    public int Address { get; }
    public ByteSliceWriter(ByteBlockPool pool);
    public void Init(int address);
    public void WriteByte(byte b);
    public void WriteBytes(Byte[] b, int offset, int len);
    public int get_Address();
    public void WriteVInt(int i);
}
internal class Lucene.Net.Index.CharBlockPool : object {
    public Char[][] buffers;
    internal int numBuffer;
    internal int bufferUpto;
    public int charUpto;
    public Char[] buffer;
    public int charOffset;
    private DocumentsWriter docWriter;
    public CharBlockPool(DocumentsWriter docWriter);
    private void InitBlock();
    public void Reset();
    public void NextBuffer();
}
public class Lucene.Net.Index.CheckIndex : object {
    private StreamWriter infoStream;
    private Directory dir;
    private static bool assertsOn;
    public CheckIndex(Directory dir);
    public virtual void SetInfoStream(StreamWriter out);
    private void Msg(string msg);
    public virtual Status CheckIndex_Renamed_Method(IState state);
    public virtual Status CheckIndex_Renamed_Method(List`1<string> onlySegments, IState state);
    private FieldNormStatus TestFieldNorms(IEnumerable`1<string> fieldNames, SegmentReader reader, IState state);
    private TermIndexStatus TestTermIndex(SegmentInfo info, SegmentReader reader, IState state);
    private StoredFieldStatus TestStoredFields(SegmentInfo info, SegmentReader reader, NumberFormatInfo format, IState state);
    private TermVectorStatus TestTermVectors(SegmentInfo info, SegmentReader reader, NumberFormatInfo format, IState state);
    public virtual void FixIndex(Status result, IState state);
    private static bool TestAsserts();
    private static bool AssertsOn();
}
public class Lucene.Net.Index.CompoundFileReader : Directory {
    private int readBufferSize;
    private bool isDisposed;
    private Directory directory;
    private string fileName;
    private IndexInput stream;
    private HashMap`2<string, FileEntry> entries;
    public Directory Directory { get; }
    public string Name { get; }
    public CompoundFileReader(Directory dir, string name, IState state);
    public CompoundFileReader(Directory dir, string name, int readBufferSize, IState state);
    public virtual Directory get_Directory();
    public virtual string get_Name();
    protected virtual void Dispose(bool disposing);
    public virtual IndexInput OpenInput(string id, IState state);
    public virtual IndexInput OpenInput(string id, int readBufferSize, IState state);
    public virtual ArrayHolder GetCache(string name, FieldInfos fieldInfos, int readBufferSize, int indexDivisor, IState state);
    public virtual void RemoveFromTermsIndexCache(string name);
    public virtual String[] ListAll(IState state);
    public virtual bool FileExists(string name, IState state);
    public virtual long FileModified(string name, IState state);
    public virtual void TouchFile(string name, IState state);
    public virtual void DeleteFile(string name, IState state);
    public void RenameFile(string from, string to);
    public virtual long FileLength(string name, IState state);
    public virtual IndexOutput CreateOutput(string name, IState state);
    public virtual Lock MakeLock(string name);
}
public class Lucene.Net.Index.CompoundFileWriter : object {
    private Directory directory;
    private string fileName;
    private HashSet`1<string> ids;
    private LinkedList`1<FileEntry> entries;
    private bool merged;
    private CheckAbort checkAbort;
    public Directory Directory { get; }
    public string Name { get; }
    public CompoundFileWriter(Directory dir, string name);
    internal CompoundFileWriter(Directory dir, string name, CheckAbort checkAbort);
    public Directory get_Directory();
    public string get_Name();
    public void AddFile(string file);
    [ObsoleteAttribute("Use Dispose() instead")]
public void Close();
    public sealed virtual void Dispose();
    private void CopyFile(FileEntry source, IndexOutput os, Byte[] buffer, IState state);
}
public class Lucene.Net.Index.ConcurrentMergeScheduler : MergeScheduler {
    private int mergeThreadPriority;
    protected internal IList`1<MergeThread> mergeThreads;
    private int _maxThreadCount;
    protected internal Directory dir;
    private bool closed;
    protected internal IndexWriter writer;
    protected internal int mergeThreadCount;
    internal static bool anyExceptions;
    private bool suppressExceptions;
    private static List`1<ConcurrentMergeScheduler> allInstances;
    public int MaxThreadCount { get; public set; }
    public virtual void set_MaxThreadCount(int value);
    public virtual int get_MaxThreadCount();
    public virtual int GetMergeThreadPriority();
    public virtual void SetMergeThreadPriority(int pri);
    private bool Verbose();
    private void Message(string message);
    private void InitMergeThreadPriority();
    protected virtual void Dispose(bool disposing);
    public virtual void Sync();
    private int MergeThreadCount();
    public virtual void Merge(IndexWriter writer, IState state);
    protected internal virtual void DoMerge(OneMerge merge, IState state);
    protected internal virtual MergeThread GetMergeThread(IndexWriter writer, OneMerge merge, IState state);
    protected internal virtual void HandleMergeException(Exception exc);
    public static bool AnyUnhandledExceptions();
    public static void ClearUnhandledExceptions();
    private void AddMyself();
    public virtual void SetSuppressExceptions();
    public virtual void ClearSuppressExceptions();
    public static void SetTestMode();
}
public class Lucene.Net.Index.CorruptIndexException : IOException {
    public CorruptIndexException(string message);
    public CorruptIndexException(string message, Exception exp);
    public CorruptIndexException(SerializationInfo info, StreamingContext context);
}
internal class Lucene.Net.Index.DefaultSkipListReader : MultiLevelSkipListReader {
    private bool currentFieldStoresPayloads;
    private Int64[] freqPointer;
    private Int64[] proxPointer;
    private Int32[] payloadLength;
    private long lastFreqPointer;
    private long lastProxPointer;
    private int lastPayloadLength;
    internal DefaultSkipListReader(IndexInput skipStream, int maxSkipLevels, int skipInterval);
    internal void Init(long skipPointer, long freqBasePointer, long proxBasePointer, int df, bool storesPayloads);
    internal long GetFreqPointer();
    internal long GetProxPointer();
    internal int GetPayloadLength();
    protected internal virtual void SeekChild(int level, IState state);
    protected internal virtual void SetLastSkipData(int level);
    protected internal virtual int ReadSkipData(int level, IndexInput skipStream, IState state);
}
internal class Lucene.Net.Index.DefaultSkipListWriter : MultiLevelSkipListWriter {
    private Int32[] lastSkipDoc;
    private Int32[] lastSkipPayloadLength;
    private Int64[] lastSkipFreqPointer;
    private Int64[] lastSkipProxPointer;
    private IndexOutput freqOutput;
    private IndexOutput proxOutput;
    private int curDoc;
    private bool curStorePayloads;
    private int curPayloadLength;
    private long curFreqPointer;
    private long curProxPointer;
    internal DefaultSkipListWriter(int skipInterval, int numberOfSkipLevels, int docCount, IndexOutput freqOutput, IndexOutput proxOutput);
    internal void SetFreqOutput(IndexOutput freqOutput);
    internal void SetProxOutput(IndexOutput proxOutput);
    internal void SetSkipData(int doc, bool storePayloads, int payloadLength);
    protected internal virtual void ResetSkip();
    protected internal virtual void WriteSkipData(int level, IndexOutput skipBuffer);
}
internal class Lucene.Net.Index.DeleteTermNum : object {
    internal int num;
    internal DeleteTermNum(int num);
    internal int GetNum();
    internal void SetNum(int num);
}
public class Lucene.Net.Index.DirectoryReader : IndexReader {
    protected internal Directory internalDirectory;
    protected internal bool readOnly;
    internal IndexWriter writer;
    private IndexDeletionPolicy deletionPolicy;
    private HashSet`1<string> synced;
    private Lock writeLock;
    private SegmentInfos segmentInfos;
    private SegmentInfos segmentInfosStart;
    private bool stale;
    private int termInfosIndexDivisor;
    private bool rollbackHasChanges;
    private SegmentReader[] subReaders;
    private Int32[] starts;
    private HashMap`2<string, Byte[]> normsCache;
    private int maxDoc;
    private int numDocs;
    private bool hasDeletions;
    private long maxIndexVersion;
    public long Version { get; }
    public int MaxDoc { get; }
    public bool HasDeletions { get; }
    public IDictionary`2<string, string> CommitUserData { get; }
    public int TermInfosIndexDivisor { get; }
    internal DirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, bool readOnly, int termInfosIndexDivisor, IState state);
    internal DirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, IState state);
    internal DirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, Int32[] oldStarts, IEnumerable`1<KeyValuePair`2<string, Byte[]>> oldNormsCache, bool readOnly, bool doClone, int termInfosIndexDivisor, IState state);
    public virtual string GetStringValueFor(string field, int doc, IState state);
    public virtual long GetLongValueFor(string field, LongParser parser, int doc, IState state);
    public virtual double GetDoubleValueFor(string field, DoubleParser parser, int doc, IState state);
    internal static IndexReader Open(Directory directory, IndexDeletionPolicy deletionPolicy, IndexCommit commit, bool readOnly, int termInfosIndexDivisor, IState state);
    private void Initialize(SegmentReader[] subReaders, IState state);
    public virtual object Clone(IState state);
    public virtual IndexReader Clone(bool openReadOnly, IState state);
    public virtual IndexReader Reopen(IState state);
    public virtual IndexReader Reopen(bool openReadOnly, IState state);
    public virtual IndexReader Reopen(IndexCommit commit, IState state);
    private IndexReader DoReopenFromWriter(bool openReadOnly, IndexCommit commit, IState state);
    internal virtual IndexReader DoReopen(bool openReadOnly, IndexCommit commit, IState state);
    private IndexReader DoReopenNoWriter(bool openReadOnly, IndexCommit commit, IState state);
    private DirectoryReader DoReopen(SegmentInfos infos, bool doClone, bool openReadOnly, IState state);
    public virtual long get_Version();
    public virtual ITermFreqVector[] GetTermFreqVectors(int n, IState state);
    public virtual ITermFreqVector GetTermFreqVector(int n, string field, IState state);
    public virtual void GetTermFreqVector(int docNumber, string field, TermVectorMapper mapper, IState state);
    public virtual void GetTermFreqVector(int docNumber, TermVectorMapper mapper, IState state);
    public virtual bool IsOptimized();
    public virtual int NumDocs();
    public virtual int get_MaxDoc();
    public virtual Document Document(int n, FieldSelector fieldSelector, IState state);
    public virtual bool IsDeleted(int n);
    public virtual bool get_HasDeletions();
    protected internal virtual void DoDelete(int n, IState state);
    protected internal virtual void DoUndeleteAll(IState state);
    private int ReaderIndex(int n);
    internal static int ReaderIndex(int n, Int32[] starts, int numSubReaders);
    public virtual bool HasNorms(string field, IState state);
    public virtual Byte[] Norms(string field, IState state);
    public virtual void Norms(string field, Byte[] result, int offset, IState state);
    protected internal virtual void DoSetNorm(int n, string field, byte value_Renamed, IState state);
    public virtual TermEnum Terms(IState state);
    public virtual TermEnum Terms(Term term, IState state);
    public virtual int DocFreq(Term t, IState state);
    public virtual TermDocs TermDocs(IState state);
    public virtual TermPositions TermPositions(IState state);
    protected internal virtual void AcquireWriteLock(IState state);
    protected internal virtual void DoCommit(IDictionary`2<string, string> commitUserData, IState state);
    internal virtual void StartCommit();
    internal virtual void RollbackCommit();
    public virtual IDictionary`2<string, string> get_CommitUserData();
    public virtual bool IsCurrent(IState state);
    protected internal virtual void DoClose(IState state);
    public virtual ICollection`1<string> GetFieldNames(FieldOption fieldNames);
    internal static ICollection`1<string> GetFieldNames(FieldOption fieldNames, IndexReader[] subReaders);
    public virtual IndexReader[] GetSequentialSubReaders();
    public virtual Directory Directory();
    public virtual int get_TermInfosIndexDivisor();
    public virtual IndexCommit IndexCommit(IState state);
    public static ICollection`1<IndexCommit> ListCommits(Directory dir, IState state);
}
internal abstract class Lucene.Net.Index.DocConsumer : object {
    public abstract virtual DocConsumerPerThread AddThread(DocumentsWriterThreadState perThread);
    public abstract virtual void Flush(ICollection`1<DocConsumerPerThread> threads, SegmentWriteState state, IState s);
    public abstract virtual void CloseDocStore(SegmentWriteState state, IState s);
    public abstract virtual void Abort();
    public abstract virtual bool FreeRAM();
}
internal abstract class Lucene.Net.Index.DocConsumerPerThread : object {
    public abstract virtual DocWriter ProcessDocument(IState state);
    public abstract virtual void Abort();
}
internal abstract class Lucene.Net.Index.DocFieldConsumer : object {
    internal FieldInfos fieldInfos;
    public abstract virtual void Flush(IDictionary`2<DocFieldConsumerPerThread, ICollection`1<DocFieldConsumerPerField>> threadsAndFields, SegmentWriteState state, IState s);
    public abstract virtual void CloseDocStore(SegmentWriteState state, IState s);
    public abstract virtual void Abort();
    public abstract virtual DocFieldConsumerPerThread AddThread(DocFieldProcessorPerThread docFieldProcessorPerThread);
    public abstract virtual bool FreeRAM();
    internal virtual void SetFieldInfos(FieldInfos fieldInfos);
}
internal abstract class Lucene.Net.Index.DocFieldConsumerPerField : object {
    public abstract virtual void ProcessFields(IFieldable[] fields, int count, IState state);
    public abstract virtual void Abort();
}
internal abstract class Lucene.Net.Index.DocFieldConsumerPerThread : object {
    public abstract virtual void StartDocument();
    public abstract virtual DocWriter FinishDocument();
    public abstract virtual DocFieldConsumerPerField AddField(FieldInfo fi);
    public abstract virtual void Abort();
}
internal class Lucene.Net.Index.DocFieldConsumers : DocFieldConsumer {
    internal DocFieldConsumer one;
    internal DocFieldConsumer two;
    internal PerDoc[] docFreeList;
    internal int freeCount;
    internal int allocCount;
    public DocFieldConsumers(DocFieldConsumer one, DocFieldConsumer two);
    private void InitBlock();
    internal virtual void SetFieldInfos(FieldInfos fieldInfos);
    public virtual void Flush(IDictionary`2<DocFieldConsumerPerThread, ICollection`1<DocFieldConsumerPerField>> threadsAndFields, SegmentWriteState state, IState s);
    public virtual void CloseDocStore(SegmentWriteState state, IState s);
    public virtual void Abort();
    public virtual bool FreeRAM();
    public virtual DocFieldConsumerPerThread AddThread(DocFieldProcessorPerThread docFieldProcessorPerThread);
    internal PerDoc GetPerDoc();
    internal void FreePerDoc(PerDoc perDoc);
}
internal class Lucene.Net.Index.DocFieldConsumersPerField : DocFieldConsumerPerField {
    internal DocFieldConsumerPerField one;
    internal DocFieldConsumerPerField two;
    internal DocFieldConsumersPerThread perThread;
    public DocFieldConsumersPerField(DocFieldConsumersPerThread perThread, DocFieldConsumerPerField one, DocFieldConsumerPerField two);
    public virtual void ProcessFields(IFieldable[] fields, int count, IState state);
    public virtual void Abort();
}
internal class Lucene.Net.Index.DocFieldConsumersPerThread : DocFieldConsumerPerThread {
    internal DocFieldConsumerPerThread one;
    internal DocFieldConsumerPerThread two;
    internal DocFieldConsumers parent;
    internal DocState docState;
    public DocFieldConsumersPerThread(DocFieldProcessorPerThread docFieldProcessorPerThread, DocFieldConsumers parent, DocFieldConsumerPerThread one, DocFieldConsumerPerThread two);
    public virtual void StartDocument();
    public virtual void Abort();
    public virtual DocWriter FinishDocument();
    public virtual DocFieldConsumerPerField AddField(FieldInfo fi);
}
internal class Lucene.Net.Index.DocFieldProcessor : DocConsumer {
    internal DocumentsWriter docWriter;
    internal FieldInfos fieldInfos;
    internal DocFieldConsumer consumer;
    internal StoredFieldsWriter fieldsWriter;
    public DocFieldProcessor(DocumentsWriter docWriter, DocFieldConsumer consumer);
    public virtual void CloseDocStore(SegmentWriteState state, IState s);
    public virtual void Flush(ICollection`1<DocConsumerPerThread> threads, SegmentWriteState state, IState s);
    public virtual void Abort();
    public virtual bool FreeRAM();
    public virtual DocConsumerPerThread AddThread(DocumentsWriterThreadState threadState);
}
internal class Lucene.Net.Index.DocFieldProcessorPerField : object {
    internal DocFieldConsumerPerField consumer;
    internal FieldInfo fieldInfo;
    internal DocFieldProcessorPerField next;
    internal int lastGen;
    internal int fieldCount;
    internal IFieldable[] fields;
    public DocFieldProcessorPerField(DocFieldProcessorPerThread perThread, FieldInfo fieldInfo);
    public void Abort();
}
internal class Lucene.Net.Index.DocFieldProcessorPerThread : DocConsumerPerThread {
    internal float docBoost;
    internal int fieldGen;
    internal DocFieldProcessor docFieldProcessor;
    internal FieldInfos fieldInfos;
    internal DocFieldConsumerPerThread consumer;
    internal DocFieldProcessorPerField[] fields;
    internal int fieldCount;
    internal DocFieldProcessorPerField[] fieldHash;
    internal int hashMask;
    internal int totalFieldCount;
    internal StoredFieldsWriterPerThread fieldsWriter;
    internal DocState docState;
    private Sorter`2<DocFieldProcessorPerField, DocFieldProcessorPerFieldComparer> _sorter;
    internal PerDoc[] docFreeList;
    internal int freeCount;
    internal int allocCount;
    public DocFieldProcessorPerThread(DocumentsWriterThreadState threadState, DocFieldProcessor docFieldProcessor);
    private void InitBlock();
    public virtual void Abort();
    public ICollection`1<DocFieldConsumerPerField> Fields();
    internal void TrimFields(SegmentWriteState state);
    private void Rehash();
    public virtual DocWriter ProcessDocument(IState state);
    internal PerDoc GetPerDoc();
    internal void FreePerDoc(PerDoc perDoc);
}
internal class Lucene.Net.Index.DocInverter : DocFieldConsumer {
    internal InvertedDocConsumer consumer;
    internal InvertedDocEndConsumer endConsumer;
    public DocInverter(InvertedDocConsumer consumer, InvertedDocEndConsumer endConsumer);
    internal virtual void SetFieldInfos(FieldInfos fieldInfos);
    public virtual void Flush(IDictionary`2<DocFieldConsumerPerThread, ICollection`1<DocFieldConsumerPerField>> threadsAndFields, SegmentWriteState state, IState s);
    public virtual void CloseDocStore(SegmentWriteState state, IState s);
    public virtual void Abort();
    public virtual bool FreeRAM();
    public virtual DocFieldConsumerPerThread AddThread(DocFieldProcessorPerThread docFieldProcessorPerThread);
}
internal class Lucene.Net.Index.DocInverterPerField : DocFieldConsumerPerField {
    private DocInverterPerThread perThread;
    private FieldInfo fieldInfo;
    internal InvertedDocConsumerPerField consumer;
    internal InvertedDocEndConsumerPerField endConsumer;
    internal DocState docState;
    internal FieldInvertState fieldState;
    public DocInverterPerField(DocInverterPerThread perThread, FieldInfo fieldInfo);
    public virtual void Abort();
    public virtual void ProcessFields(IFieldable[] fields, int count, IState state);
}
internal class Lucene.Net.Index.DocInverterPerThread : DocFieldConsumerPerThread {
    internal DocInverter docInverter;
    internal InvertedDocConsumerPerThread consumer;
    internal InvertedDocEndConsumerPerThread endConsumer;
    internal SingleTokenAttributeSource singleToken;
    internal DocState docState;
    internal FieldInvertState fieldState;
    internal ReusableStringReader stringReader;
    public DocInverterPerThread(DocFieldProcessorPerThread docFieldProcessorPerThread, DocInverter docInverter);
    private void InitBlock();
    public virtual void StartDocument();
    public virtual DocWriter FinishDocument();
    public virtual void Abort();
    public virtual DocFieldConsumerPerField AddField(FieldInfo fi);
}
public class Lucene.Net.Index.DocumentsWriter : object {
    internal IndexWriter writer;
    internal Directory directory;
    internal string segment;
    private string docStoreSegment;
    private int docStoreOffset;
    private int nextDocID;
    private int numDocsInRAM;
    internal int numDocsInStore;
    private static int MAX_THREAD_STATE;
    private DocumentsWriterThreadState[] threadStates;
    private HashMap`2<ThreadClass, DocumentsWriterThreadState> threadBindings;
    private int pauseThreads;
    internal bool flushPending;
    internal bool bufferIsFull;
    private bool aborting;
    internal int _offsetThreshold;
    private DocFieldProcessor docFieldProcessor;
    internal StreamWriter infoStream;
    internal int maxFieldLength;
    internal Similarity similarity;
    internal IList`1<string> newFiles;
    internal static IndexingChain DefaultIndexingChain;
    internal DocConsumer consumer;
    private UnsortedBufferedDeletes deletesInRAM;
    private SortedBufferedDeletes deletesFlushed;
    private int maxBufferedDeleteTerms;
    private long ramBufferSize;
    private long waitQueuePauseBytes;
    private long waitQueueResumeBytes;
    private long freeTrigger;
    private long freeLevel;
    private int maxBufferedDocs;
    private int flushedDocCount;
    private bool closed;
    private ICollection`1<string> abortedFiles;
    private SegmentWriteState flushState;
    internal IList`1<string> openFiles;
    internal IList`1<string> closedFiles;
    private Term lastDeleteTerm;
    internal SkipDocWriter skipDocWriter;
    internal long numBytesAlloc;
    internal long numBytesUsed;
    internal NumberFormatInfo nf;
    internal static int OBJECT_HEADER_BYTES;
    internal static int POINTER_NUM_BYTE;
    internal static int INT_NUM_BYTE;
    internal static int CHAR_NUM_BYTE;
    internal static int BYTES_PER_DEL_TERM;
    internal static int BYTES_PER_DEL_DOCID;
    internal static int BYTES_PER_DEL_QUERY;
    internal static int BYTE_BLOCK_SHIFT;
    internal static int BYTE_BLOCK_SIZE;
    internal static int BYTE_BLOCK_MASK;
    internal static int BYTE_BLOCK_NOT_MASK;
    internal static int INT_BLOCK_SHIFT;
    internal static int INT_BLOCK_SIZE;
    internal static int INT_BLOCK_MASK;
    internal ArrayPoolByteBlockAllocator byteBlockAllocator;
    internal static int PER_DOC_BLOCK_SIZE;
    private ByteBlockAllocator perDocAllocator;
    internal static int CHAR_BLOCK_SHIFT;
    internal static int CHAR_BLOCK_SIZE;
    internal static int CHAR_BLOCK_MASK;
    internal static int MAX_TERM_LENGTH;
    internal WaitQueue waitQueue;
    internal int MaxBufferedDocs { get; internal set; }
    internal string Segment { get; }
    internal int NumDocsInRAM { get; }
    internal string DocStoreSegment { get; }
    internal int DocStoreOffset { get; }
    internal bool AnyChanges { get; }
    internal int MaxBufferedDeleteTerms { get; internal set; }
    public static int BYTE_BLOCK_SIZE_ForNUnit { get; }
    public static int CHAR_BLOCK_SIZE_ForNUnit { get; }
    internal DocumentsWriter(Directory directory, IndexWriter writer, IndexingChain indexingChain);
    private static DocumentsWriter();
    private void InitBlock();
    internal PerDocBuffer NewPerDocBuffer();
    internal void UpdateFlushedDocCount(int n);
    internal int GetFlushedDocCount();
    internal void SetFlushedDocCount(int n);
    internal bool HasProx();
    internal void SetInfoStream(StreamWriter infoStream);
    internal void SetMaxFieldLength(int maxFieldLength);
    internal void SetSimilarity(Similarity similarity);
    internal void SetRAMBufferSizeMB(double mb);
    internal double GetRAMBufferSizeMB();
    internal int get_MaxBufferedDocs();
    internal void set_MaxBufferedDocs(int value);
    internal string get_Segment();
    internal int get_NumDocsInRAM();
    internal string get_DocStoreSegment();
    internal int get_DocStoreOffset();
    internal string CloseDocStore(IState state);
    internal ICollection`1<string> AbortedFiles();
    internal void Message(string message);
    internal IList`1<string> OpenFiles();
    internal IList`1<string> ClosedFiles();
    internal void AddOpenFile(string name);
    internal void RemoveOpenFile(string name);
    internal void SetAborting();
    internal void Abort();
    private void DoAfterFlush();
    internal bool PauseAllThreads();
    internal void ResumeAllThreads();
    private bool AllThreadsIdle();
    internal bool get_AnyChanges();
    private void InitFlushState(bool onlyDocStore);
    internal int Flush(bool closeDocStore, IState state);
    internal ICollection`1<string> GetFlushedFiles();
    internal void CreateCompoundFile(string segment);
    internal bool SetFlushPending();
    internal void ClearFlushPending();
    internal void PushDeletes();
    public sealed virtual void Dispose();
    internal void InitSegmentName(bool onlyDocStore);
    internal DocumentsWriterThreadState GetThreadState(Document doc, Term delTerm);
    internal bool AddDocument(Document doc, Analyzer analyzer, IState state);
    internal bool UpdateDocument(Term t, Document doc, Analyzer analyzer, IState state);
    internal bool UpdateDocument(Document doc, Analyzer analyzer, Term delTerm, IState s);
    internal int GetNumBufferedDeleteTerms();
    internal IDictionary`2<Term, DeleteTermNum> GetBufferedDeleteTerms();
    internal void RemapDeletes(SegmentInfos infos, Int32[][] docMaps, Int32[] delCounts, OneMerge merge, int mergeDocCount);
    private void WaitReady(DocumentsWriterThreadState state);
    internal bool BufferDeleteTerms(Term[] terms);
    internal bool BufferDeleteTerm(Term term);
    internal bool BufferDeleteQueries(Query[] queries);
    internal bool BufferDeleteQuery(Query query);
    internal bool DeletesFull();
    internal bool DoApplyDeletes();
    private bool TimeToFlushDeletes();
    internal void set_MaxBufferedDeleteTerms(int value);
    internal int get_MaxBufferedDeleteTerms();
    internal bool HasDeletes();
    internal bool ApplyDeletes(SegmentInfos infos, IState state);
    private bool CheckDeleteTerm(Term term);
    private bool ApplyDeletes(IndexReader reader, int docIDStart, IState state);
    private void AddDeleteTerm(Term term, int docCount);
    private void AddDeleteDocID(int docID);
    private void AddDeleteQuery(Query query, int docID);
    internal bool DoBalanceRAM();
    private void FinishDocument(DocumentsWriterThreadState perThread, DocWriter docWriter, IState state);
    internal void WaitForWaitQueue();
    internal long GetRAMUsed();
    internal Int32[] GetIntBlock(bool trackAllocations);
    internal void BytesAllocated(long numBytes);
    internal void BytesUsed(long numBytes);
    internal void RecycleIntBlocks(Int32[][] blocks, int start, int end);
    internal Char[] GetCharBlock();
    internal void RecycleCharBlocks(Char[][] blocks, int numBlocks);
    internal string ToMB(long v);
    internal void BalanceRAM();
    public static int get_BYTE_BLOCK_SIZE_ForNUnit();
    public static int get_CHAR_BLOCK_SIZE_ForNUnit();
}
internal class Lucene.Net.Index.DocumentsWriterThreadState : object {
    internal bool isIdle;
    internal int numThreads;
    internal bool doFlushAfter;
    internal DocConsumerPerThread consumer;
    internal DocState docState;
    internal DocumentsWriter docWriter;
    public DocumentsWriterThreadState(DocumentsWriter docWriter);
    internal void DoAfterFlush();
}
public class Lucene.Net.Index.FieldInfo : object {
    internal string name;
    internal bool isIndexed;
    internal int number;
    internal bool storeTermVector;
    internal bool storeOffsetWithTermVector;
    internal bool storePositionWithTermVector;
    internal bool omitNorms;
    internal bool omitTermFreqAndPositions;
    internal bool storePayloads;
    public bool storePayloads_ForNUnit { get; }
    public string name_ForNUnit { get; }
    public bool isIndexed_ForNUnit { get; }
    public bool omitNorms_ForNUnit { get; }
    public bool omitTermFreqAndPositions_ForNUnit { get; }
    public bool storeTermVector_ForNUnit { get; }
    internal FieldInfo(string na, bool tk, int nu, bool storeTermVector, bool storePositionWithTermVector, bool storeOffsetWithTermVector, bool omitNorms, bool storePayloads, bool omitTermFreqAndPositions);
    public sealed virtual object Clone();
    internal void Update(bool isIndexed, bool storeTermVector, bool storePositionWithTermVector, bool storeOffsetWithTermVector, bool omitNorms, bool storePayloads, bool omitTermFreqAndPositions);
    public bool get_storePayloads_ForNUnit();
    public string get_name_ForNUnit();
    public bool get_isIndexed_ForNUnit();
    public bool get_omitNorms_ForNUnit();
    public bool get_omitTermFreqAndPositions_ForNUnit();
    public bool get_storeTermVector_ForNUnit();
}
public class Lucene.Net.Index.FieldInfos : object {
    public static int FORMAT_PRE;
    public static int FORMAT_START;
    internal static int CURRENT_FORMAT;
    internal static byte IS_INDEXED;
    internal static byte STORE_TERMVECTOR;
    internal static byte STORE_POSITIONS_WITH_TERMVECTOR;
    internal static byte STORE_OFFSET_WITH_TERMVECTOR;
    internal static byte OMIT_NORMS;
    internal static byte STORE_PAYLOADS;
    internal static byte OMIT_TERM_FREQ_AND_POSITIONS;
    private List`1<FieldInfo> byNumber;
    private HashMap`2<string, FieldInfo> byName;
    private int format;
    public FieldInfos(Directory d, string name, IState state);
    private static FieldInfos();
    public sealed virtual object Clone();
    public void Add(Document doc);
    internal bool HasProx();
    public void AddIndexed(ICollection`1<string> names, bool storeTermVectors, bool storePositionWithTermVector, bool storeOffsetWithTermVector);
    public void Add(ICollection`1<string> names, bool isIndexed);
    public void Add(string name, bool isIndexed);
    public void Add(string name, bool isIndexed, bool storeTermVector);
    public void Add(string name, bool isIndexed, bool storeTermVector, bool storePositionWithTermVector, bool storeOffsetWithTermVector);
    public void Add(string name, bool isIndexed, bool storeTermVector, bool storePositionWithTermVector, bool storeOffsetWithTermVector, bool omitNorms);
    public FieldInfo Add(string name, bool isIndexed, bool storeTermVector, bool storePositionWithTermVector, bool storeOffsetWithTermVector, bool omitNorms, bool storePayloads, bool omitTermFreqAndPositions);
    private FieldInfo AddInternal(string name, bool isIndexed, bool storeTermVector, bool storePositionWithTermVector, bool storeOffsetWithTermVector, bool omitNorms, bool storePayloads, bool omitTermFreqAndPositions);
    public int FieldNumber(string fieldName);
    public FieldInfo FieldInfo(string fieldName);
    public string FieldName(int fieldNumber);
    public FieldInfo FieldInfo(int fieldNumber);
    public int Size();
    public bool HasVectors();
    public void Write(Directory d, string name, IState state);
    public void Write(IndexOutput output);
    private void Read(IndexInput input, string fileName, IState state);
}
public class Lucene.Net.Index.FieldInvertState : object {
    internal int position;
    internal int length;
    internal int numOverlap;
    internal int offset;
    internal float boost;
    internal AttributeSource attributeSource;
    public int Position { get; }
    public int Length { get; }
    public int NumOverlap { get; }
    public int Offset { get; }
    public float Boost { get; }
    public AttributeSource AttributeSource { get; }
    public FieldInvertState(int position, int length, int numOverlap, int offset, float boost);
    internal void Reset(float docBoost);
    public int get_Position();
    public int get_Length();
    public int get_NumOverlap();
    public int get_Offset();
    public float get_Boost();
    public AttributeSource get_AttributeSource();
}
public class Lucene.Net.Index.FieldReaderException : SystemException {
    public FieldReaderException(Exception cause);
    public FieldReaderException(string message);
    public FieldReaderException(string message, Exception cause);
    public FieldReaderException(SerializationInfo info, StreamingContext context);
}
public class Lucene.Net.Index.FieldSortedTermVectorMapper : TermVectorMapper {
    private HashMap`2<string, SortedSet`1<TermVectorEntry>> fieldToTerms;
    private SortedSet`1<TermVectorEntry> currentSet;
    private string currentField;
    private IComparer`1<TermVectorEntry> comparator;
    public IDictionary`2<string, SortedSet`1<TermVectorEntry>> FieldToTerms { get; }
    public IComparer`1<TermVectorEntry> Comparator { get; }
    public FieldSortedTermVectorMapper(IComparer`1<TermVectorEntry> comparator);
    public FieldSortedTermVectorMapper(bool ignoringPositions, bool ignoringOffsets, IComparer`1<TermVectorEntry> comparator);
    public virtual void Map(string term, int frequency, TermVectorOffsetInfo[] offsets, Int32[] positions);
    public virtual void SetExpectations(string field, int numTerms, bool storeOffsets, bool storePositions);
    public virtual IDictionary`2<string, SortedSet`1<TermVectorEntry>> get_FieldToTerms();
    public virtual IComparer`1<TermVectorEntry> get_Comparator();
}
public class Lucene.Net.Index.FieldsReader : object {
    private FieldInfos fieldInfos;
    private IndexInput cloneableFieldsStream;
    private IndexInput fieldsStream;
    private IndexInput cloneableIndexStream;
    private IndexInput indexStream;
    private int numTotalDocs;
    private int size;
    private bool closed;
    private int format;
    private int formatSize;
    private int docStoreOffset;
    private LightWeightThreadLocal`1<IndexInput> fieldsStreamTL;
    private bool isOriginal;
    private FieldsReader(FieldInfos fieldInfos, int numTotalDocs, int size, int format, int formatSize, int docStoreOffset, IndexInput cloneableFieldsStream, IndexInput cloneableIndexStream, IState state);
    public FieldsReader(Directory d, string segment, FieldInfos fn, IState state);
    internal FieldsReader(Directory d, string segment, FieldInfos fn, int readBufferSize, IState state);
    internal FieldsReader(Directory d, string segment, FieldInfos fn, int readBufferSize, int docStoreOffset, int size, IState state);
    public sealed virtual object Clone(IState state);
    internal void EnsureOpen();
    public sealed virtual void Dispose();
    public int Size();
    private void SeekIndex(int docID, IState state);
    internal bool CanReadRawDocs();
    public Document Doc(int n, FieldSelector fieldSelector, IState state);
    internal IndexInput RawDocs(Int32[] lengths, int startDocID, int numDocs, IState state);
    private void SkipField(bool binary, bool compressed, IState state);
    private void SkipField(bool binary, bool compressed, int toRead, IState state);
    private void AddFieldLazy(Document doc, FieldInfo fi, bool binary, bool compressed, bool tokenize, IState state);
    private void AddField(Document doc, FieldInfo fi, bool binary, bool compressed, bool tokenize, IState state);
    private int AddFieldSize(Document doc, FieldInfo fi, bool binary, bool compressed, IState state);
    private Byte[] Uncompress(Byte[] b);
}
internal class Lucene.Net.Index.FieldsWriter : object {
    internal static byte FIELD_IS_TOKENIZED;
    internal static byte FIELD_IS_BINARY;
    [ObsoleteAttribute("Kept for backwards-compatibility with <3.0 indexes; will be removed in 4.0")]
internal static byte FIELD_IS_COMPRESSED;
    internal static int FORMAT;
    internal static int FORMAT_VERSION_UTF8_LENGTH_IN_BYTES;
    internal static int FORMAT_LUCENE_3_0_NO_COMPRESSED_FIELDS;
    internal static int FORMAT_CURRENT;
    private FieldInfos fieldInfos;
    private IndexOutput fieldsStream;
    private IndexOutput indexStream;
    private bool doClose;
    internal FieldsWriter(Directory d, string segment, FieldInfos fn, IState state);
    internal FieldsWriter(IndexOutput fdx, IndexOutput fdt, FieldInfos fn);
    private static FieldsWriter();
    internal void SetFieldsStream(IndexOutput stream);
    internal void FlushDocument(int numStoredFields, RAMOutputStream buffer);
    internal void SkipDocument();
    internal void Flush();
    public sealed virtual void Dispose();
    internal void WriteField(FieldInfo fi, IFieldable field, IState state);
    internal void AddRawDocuments(IndexInput stream, Int32[] lengths, int numDocs, IState state);
    internal void AddDocument(Document doc, IState state);
}
public class Lucene.Net.Index.FilterIndexReader : IndexReader {
    protected internal IndexReader in_Renamed;
    public int MaxDoc { get; }
    public bool HasDeletions { get; }
    public long Version { get; }
    public object FieldCacheKey { get; }
    public object DeletesCacheKey { get; }
    public FilterIndexReader(IndexReader in_Renamed);
    public virtual Directory Directory();
    public virtual ITermFreqVector[] GetTermFreqVectors(int docNumber, IState state);
    public virtual ITermFreqVector GetTermFreqVector(int docNumber, string field, IState state);
    public virtual void GetTermFreqVector(int docNumber, string field, TermVectorMapper mapper, IState state);
    public virtual void GetTermFreqVector(int docNumber, TermVectorMapper mapper, IState state);
    public virtual int NumDocs();
    public virtual int get_MaxDoc();
    public virtual Document Document(int n, FieldSelector fieldSelector, IState state);
    public virtual bool IsDeleted(int n);
    public virtual bool get_HasDeletions();
    protected internal virtual void DoUndeleteAll(IState state);
    public virtual bool HasNorms(string field, IState state);
    public virtual Byte[] Norms(string f, IState state);
    public virtual void Norms(string f, Byte[] bytes, int offset, IState state);
    protected internal virtual void DoSetNorm(int d, string f, byte b, IState state);
    public virtual TermEnum Terms(IState state);
    public virtual TermEnum Terms(Term t, IState state);
    public virtual int DocFreq(Term t, IState state);
    public virtual TermDocs TermDocs(IState state);
    public virtual TermDocs TermDocs(Term term, IState state);
    public virtual TermPositions TermPositions(IState state);
    protected internal virtual void DoDelete(int n, IState state);
    protected internal virtual void DoCommit(IDictionary`2<string, string> commitUserData, IState state);
    protected internal virtual void DoClose(IState state);
    public virtual ICollection`1<string> GetFieldNames(FieldOption fieldNames);
    public virtual long get_Version();
    public virtual bool IsCurrent(IState state);
    public virtual bool IsOptimized();
    public virtual IndexReader[] GetSequentialSubReaders();
    public virtual string GetStringValueFor(string field, int doc, IState state);
    public virtual long GetLongValueFor(string field, LongParser parser, int doc, IState state);
    public virtual double GetDoubleValueFor(string field, DoubleParser parser, int doc, IState state);
    public virtual object Clone(IState state);
    public virtual object get_FieldCacheKey();
    public virtual object get_DeletesCacheKey();
}
internal abstract class Lucene.Net.Index.FormatPostingsDocsConsumer : object {
    internal abstract virtual FormatPostingsPositionsConsumer AddDoc(int docID, int termDocFreq);
    internal abstract virtual void Finish();
}
internal class Lucene.Net.Index.FormatPostingsDocsWriter : FormatPostingsDocsConsumer {
    internal IndexOutput out_Renamed;
    internal FormatPostingsTermsWriter parent;
    internal FormatPostingsPositionsWriter posWriter;
    internal DefaultSkipListWriter skipListWriter;
    internal int skipInterval;
    internal int totalNumDocs;
    internal bool omitTermFreqAndPositions;
    internal bool storePayloads;
    internal long freqStart;
    internal FieldInfo fieldInfo;
    internal int lastDocID;
    internal int df;
    private TermInfo termInfo;
    internal UTF8Result utf8;
    internal FormatPostingsDocsWriter(SegmentWriteState state, FormatPostingsTermsWriter parent, IState s);
    internal void SetField(FieldInfo fieldInfo);
    internal virtual FormatPostingsPositionsConsumer AddDoc(int docID, int termDocFreq);
    internal virtual void Finish();
    public sealed virtual void Dispose();
}
internal abstract class Lucene.Net.Index.FormatPostingsFieldsConsumer : object {
    internal abstract virtual FormatPostingsTermsConsumer AddField(FieldInfo field);
    internal abstract virtual void Finish();
}
internal class Lucene.Net.Index.FormatPostingsFieldsWriter : FormatPostingsFieldsConsumer {
    internal Directory dir;
    internal string segment;
    internal TermInfosWriter termsOut;
    internal FieldInfos fieldInfos;
    internal FormatPostingsTermsWriter termsWriter;
    internal DefaultSkipListWriter skipListWriter;
    internal int totalNumDocs;
    public FormatPostingsFieldsWriter(SegmentWriteState state, FieldInfos fieldInfos, IState s);
    internal virtual FormatPostingsTermsConsumer AddField(FieldInfo field);
    internal virtual void Finish();
}
internal abstract class Lucene.Net.Index.FormatPostingsPositionsConsumer : object {
    internal abstract virtual void AddPosition(int position, Byte[] payload, int payloadOffset, int payloadLength);
    internal abstract virtual void Finish();
}
internal class Lucene.Net.Index.FormatPostingsPositionsWriter : FormatPostingsPositionsConsumer {
    internal FormatPostingsDocsWriter parent;
    internal IndexOutput out_Renamed;
    internal bool omitTermFreqAndPositions;
    internal bool storePayloads;
    internal int lastPayloadLength;
    internal int lastPosition;
    internal FormatPostingsPositionsWriter(SegmentWriteState state, FormatPostingsDocsWriter parent, IState s);
    internal virtual void AddPosition(int position, Byte[] payload, int payloadOffset, int payloadLength);
    internal void SetField(FieldInfo fieldInfo);
    internal virtual void Finish();
    public sealed virtual void Dispose();
}
internal abstract class Lucene.Net.Index.FormatPostingsTermsConsumer : object {
    internal Char[] termBuffer;
    internal abstract virtual FormatPostingsDocsConsumer AddTerm(Char[] text, int start);
    internal virtual FormatPostingsDocsConsumer AddTerm(string text);
    internal abstract virtual void Finish();
}
internal class Lucene.Net.Index.FormatPostingsTermsWriter : FormatPostingsTermsConsumer {
    internal FormatPostingsFieldsWriter parent;
    internal FormatPostingsDocsWriter docsWriter;
    internal TermInfosWriter termsOut;
    internal FieldInfo fieldInfo;
    internal Char[] currentTerm;
    internal int currentTermStart;
    internal long freqStart;
    internal long proxStart;
    internal FormatPostingsTermsWriter(SegmentWriteState state, FormatPostingsFieldsWriter parent, IState s);
    internal void SetField(FieldInfo fieldInfo);
    internal virtual FormatPostingsDocsConsumer AddTerm(Char[] text, int start);
    internal virtual void Finish();
    public sealed virtual void Dispose();
}
internal class Lucene.Net.Index.FreqProxFieldMergeState : object {
    internal FreqProxTermsWriterPerField field;
    internal int numPostings;
    internal CharBlockPool charPool;
    internal RawPostingList[] postings;
    private PostingList p;
    internal Char[] text;
    internal int textOffset;
    private int postingUpto;
    internal ByteSliceReader freq;
    internal ByteSliceReader prox;
    internal int docID;
    internal int termFreq;
    public FreqProxFieldMergeState(FreqProxTermsWriterPerField field);
    internal bool NextTerm(IState state);
    public bool NextDoc(IState state);
}
internal class Lucene.Net.Index.FreqProxTermsWriter : TermsHashConsumer {
    private Byte[] payloadBuffer;
    internal UTF8Result termsUTF8;
    public virtual TermsHashConsumerPerThread AddThread(TermsHashPerThread perThread);
    internal virtual void CreatePostings(RawPostingList[] postings, int start, int count);
    private static int compareText(Char[] text1, int pos1, Char[] text2, int pos2);
    internal virtual void CloseDocStore(SegmentWriteState state, IState s);
    public virtual void Abort();
    public virtual void Flush(IDictionary`2<TermsHashConsumerPerThread, ICollection`1<TermsHashConsumerPerField>> threadsAndFields, SegmentWriteState state, IState s);
    internal void AppendPostings(FreqProxTermsWriterPerField[] fields, FormatPostingsFieldsConsumer consumer, IState state);
    internal virtual int BytesPerPosting();
}
internal class Lucene.Net.Index.FreqProxTermsWriterPerField : TermsHashConsumerPerField {
    internal FreqProxTermsWriterPerThread perThread;
    internal TermsHashPerField termsHashPerField;
    internal FieldInfo fieldInfo;
    internal DocState docState;
    internal FieldInvertState fieldState;
    internal bool omitTermFreqAndPositions;
    internal IPayloadAttribute payloadAttribute;
    internal bool hasPayloads;
    public FreqProxTermsWriterPerField(TermsHashPerField termsHashPerField, FreqProxTermsWriterPerThread perThread, FieldInfo fieldInfo);
    internal virtual int GetStreamCount();
    internal virtual void Finish();
    internal virtual void SkippingLongTerm();
    public sealed virtual int CompareTo(FreqProxTermsWriterPerField other);
    internal void Reset();
    internal virtual bool Start(IFieldable[] fields, int count);
    internal virtual void Start(IFieldable f);
    internal void WriteProx(PostingList p, int proxCode);
    internal virtual void NewTerm(RawPostingList p0);
    internal virtual void AddTerm(RawPostingList p0);
    public void Abort();
}
internal class Lucene.Net.Index.FreqProxTermsWriterPerThread : TermsHashConsumerPerThread {
    internal TermsHashPerThread termsHashPerThread;
    internal DocState docState;
    public FreqProxTermsWriterPerThread(TermsHashPerThread perThread);
    public virtual TermsHashConsumerPerField AddField(TermsHashPerField termsHashPerField, FieldInfo fieldInfo);
    public virtual void StartDocument();
    public virtual DocWriter FinishDocument();
    public virtual void Abort();
}
public abstract class Lucene.Net.Index.IndexCommit : object {
    public string SegmentsFileName { get; }
    public ICollection`1<string> FileNames { get; }
    public Directory Directory { get; }
    public bool IsDeleted { get; }
    public bool IsOptimized { get; }
    public long Version { get; }
    public long Generation { get; }
    public IDictionary`2<string, string> UserData { get; }
    public abstract virtual string get_SegmentsFileName();
    public abstract virtual ICollection`1<string> get_FileNames();
    public abstract virtual Directory get_Directory();
    public abstract virtual void Delete();
    public abstract virtual bool get_IsDeleted();
    public abstract virtual bool get_IsOptimized();
    public virtual bool Equals(object other);
    public virtual int GetHashCode();
    public abstract virtual long get_Version();
    public abstract virtual long get_Generation();
    public virtual long Timestamp(IState state);
    public abstract virtual IDictionary`2<string, string> get_UserData();
}
public interface Lucene.Net.Index.IndexDeletionPolicy {
    public abstract virtual void OnInit(IList`1<T> commits);
    public abstract virtual void OnCommit(IList`1<T> commits);
}
public class Lucene.Net.Index.IndexFileDeleter : object {
    private IList`1<string> deletable;
    private HashMap`2<string, RefCount> refCounts;
    private List`1<CommitPoint> commits;
    private List`1<ICollection`1<string>> lastFiles;
    private List`1<CommitPoint> commitsToDelete;
    private StreamWriter infoStream;
    private Directory directory;
    private IndexDeletionPolicy policy;
    private DocumentsWriter docWriter;
    internal bool startingCommitDeleted;
    private SegmentInfos lastSegmentInfos;
    private HashSet`1<string> synced;
    public static bool VERBOSE_REF_COUNTS;
    public SegmentInfos LastSegmentInfos { get; }
    public IndexFileDeleter(Directory directory, IndexDeletionPolicy policy, SegmentInfos segmentInfos, StreamWriter infoStream, DocumentsWriter docWriter, HashSet`1<string> synced, IState state);
    internal void SetInfoStream(StreamWriter infoStream);
    private void Message(string message);
    public SegmentInfos get_LastSegmentInfos();
    private void DeleteCommits(IState state);
    public void Refresh(string segmentName, IState state);
    public void Refresh(IState state);
    public sealed virtual void Dispose();
    private void DeletePendingFiles(IState state);
    public void Checkpoint(SegmentInfos segmentInfos, bool isCommit, IState state);
    internal void IncRef(SegmentInfos segmentInfos, bool isCommit, IState state);
    internal void IncRef(ICollection`1<string> files);
    internal void IncRef(string fileName);
    internal void DecRef(ICollection`1<string> files, IState state);
    internal void DecRef(string fileName, IState state);
    internal void DecRef(SegmentInfos segmentInfos, IState state);
    public bool Exists(string fileName);
    private RefCount GetRefCount(string fileName);
    internal void DeleteFiles(IList`1<string> files, IState state);
    internal void DeleteNewFiles(ICollection`1<string> files, IState state);
    internal void DeleteFile(string fileName, IState state);
}
public class Lucene.Net.Index.IndexFileNameFilter : object {
    private static IndexFileNameFilter singleton;
    private HashSet`1<string> extensions;
    private HashSet`1<string> extensionsInCFS;
    public static IndexFileNameFilter Filter { get; }
    private static IndexFileNameFilter();
    public virtual bool Accept(FileInfo dir, string name);
    public virtual bool IsCFSFile(string name);
    public static IndexFileNameFilter get_Filter();
}
public class Lucene.Net.Index.IndexFileNames : object {
    public static string SEGMENTS;
    public static string SEGMENTS_GEN;
    public static string DELETABLE;
    public static string NORMS_EXTENSION;
    public static string FREQ_EXTENSION;
    public static string PROX_EXTENSION;
    public static string TERMS_EXTENSION;
    public static string TERMS_INDEX_EXTENSION;
    public static string FIELDS_INDEX_EXTENSION;
    public static string FIELDS_EXTENSION;
    public static string VECTORS_FIELDS_EXTENSION;
    public static string VECTORS_DOCUMENTS_EXTENSION;
    public static string VECTORS_INDEX_EXTENSION;
    public static string COMPOUND_FILE_EXTENSION;
    public static string COMPOUND_FILE_STORE_EXTENSION;
    internal static string DELETES_EXTENSION;
    public static string FIELD_INFOS_EXTENSION;
    public static string PLAIN_NORMS_EXTENSION;
    public static string SEPARATE_NORMS_EXTENSION;
    public static string GEN_EXTENSION;
    public static String[] INDEX_EXTENSIONS;
    public static String[] INDEX_EXTENSIONS_IN_COMPOUND_FILE;
    public static String[] STORE_INDEX_EXTENSIONS;
    public static String[] NON_STORE_INDEX_EXTENSIONS;
    public static String[] COMPOUND_EXTENSIONS;
    public static String[] VECTOR_EXTENSIONS;
    private static IndexFileNames();
    public static string FileNameFromGeneration(string base_Renamed, string extension, long gen);
    internal static bool IsDocStoreFile(string fileName);
    internal static string SegmentFileName(string segmentName, string ext);
}
public abstract class Lucene.Net.Index.IndexReader : object {
    private bool closed;
    protected internal bool hasChanges;
    private int refCount;
    protected internal static int DEFAULT_TERMS_INDEX_DIVISOR;
    public int RefCount { get; }
    public long Version { get; }
    public IDictionary`2<string, string> CommitUserData { get; }
    public int MaxDoc { get; }
    public int NumDeletedDocs { get; }
    public bool HasDeletions { get; }
    public object FieldCacheKey { get; }
    public object DeletesCacheKey { get; }
    public long UniqueTermCount { get; }
    public int TermInfosIndexDivisor { get; }
    private static IndexReader();
    public abstract virtual string GetStringValueFor(string field, int doc, IState state);
    public abstract virtual long GetLongValueFor(string field, LongParser parser, int doc, IState state);
    public abstract virtual double GetDoubleValueFor(string field, DoubleParser parser, int doc, IState state);
    public virtual int get_RefCount();
    public virtual void IncRef();
    public virtual void DecRef(IState state);
    public void CloseWithoutCommit();
    protected internal void EnsureOpen();
    public static IndexReader Open(Directory directory, bool readOnly, IState state);
    public static IndexReader Open(IndexCommit commit, bool readOnly, IState state);
    public static IndexReader Open(Directory directory, IndexDeletionPolicy deletionPolicy, bool readOnly, IState state);
    public static IndexReader Open(Directory directory, IndexDeletionPolicy deletionPolicy, bool readOnly, int termInfosIndexDivisor, IState state);
    public static IndexReader Open(IndexCommit commit, IndexDeletionPolicy deletionPolicy, bool readOnly, IState state);
    public static IndexReader Open(IndexCommit commit, IndexDeletionPolicy deletionPolicy, bool readOnly, int termInfosIndexDivisor, IState state);
    private static IndexReader Open(Directory directory, IndexDeletionPolicy deletionPolicy, IndexCommit commit, bool readOnly, int termInfosIndexDivisor, IState state);
    public virtual IndexReader Reopen(IState state);
    public virtual IndexReader Reopen(bool openReadOnly, IState state);
    public virtual IndexReader Reopen(IndexCommit commit, IState state);
    public virtual object Clone(IState state);
    public virtual IndexReader Clone(bool openReadOnly, IState state);
    public virtual Directory Directory();
    public static long LastModified(Directory directory2, IState state);
    public static long GetCurrentVersion(Directory directory, IState state);
    public static IDictionary`2<string, string> GetCommitUserData(Directory directory, IState state);
    public virtual long get_Version();
    public virtual IDictionary`2<string, string> get_CommitUserData();
    public virtual bool IsCurrent(IState state);
    public virtual bool IsOptimized();
    public abstract virtual ITermFreqVector[] GetTermFreqVectors(int docNumber, IState state);
    public abstract virtual ITermFreqVector GetTermFreqVector(int docNumber, string field, IState state);
    public abstract virtual void GetTermFreqVector(int docNumber, string field, TermVectorMapper mapper, IState state);
    public abstract virtual void GetTermFreqVector(int docNumber, TermVectorMapper mapper, IState state);
    public static bool IndexExists(Directory directory, IState state);
    public abstract virtual int NumDocs();
    public abstract virtual int get_MaxDoc();
    public virtual int get_NumDeletedDocs();
    public virtual Document Document(int n, IState state);
    public abstract virtual Document Document(int n, FieldSelector fieldSelector, IState state);
    public abstract virtual bool IsDeleted(int n);
    public abstract virtual bool get_HasDeletions();
    public virtual bool HasNorms(string field, IState state);
    public abstract virtual Byte[] Norms(string field, IState state);
    public abstract virtual void Norms(string field, Byte[] bytes, int offset, IState state);
    public virtual void SetNorm(int doc, string field, byte value, IState state);
    protected internal abstract virtual void DoSetNorm(int doc, string field, byte value_Renamed, IState state);
    public virtual void SetNorm(int doc, string field, float value, IState state);
    public abstract virtual TermEnum Terms(IState state);
    public abstract virtual TermEnum Terms(Term t, IState state);
    public abstract virtual int DocFreq(Term t, IState state);
    public virtual TermDocs TermDocs(Term term, IState state);
    public abstract virtual TermDocs TermDocs(IState state);
    public virtual TermPositions TermPositions(Term term, IState state);
    public abstract virtual TermPositions TermPositions(IState state);
    public virtual void DeleteDocument(int docNum, IState state);
    protected internal abstract virtual void DoDelete(int docNum, IState state);
    public virtual int DeleteDocuments(Term term, IState state);
    public virtual void UndeleteAll(IState state);
    protected internal abstract virtual void DoUndeleteAll(IState state);
    protected internal virtual void AcquireWriteLock(IState state);
    public void Flush(IState state);
    public void Flush(IDictionary`2<string, string> commitUserData, IState state);
    public void Commit(IState state);
    public void Commit(IDictionary`2<string, string> commitUserData, IState state);
    protected internal abstract virtual void DoCommit(IDictionary`2<string, string> commitUserData, IState state);
    [ObsoleteAttribute("Use Dispose() instead")]
public void Close();
    public sealed virtual void Dispose();
    protected virtual void Dispose(bool disposing);
    protected internal abstract virtual void DoClose(IState state);
    public abstract virtual ICollection`1<string> GetFieldNames(FieldOption fldOption);
    public virtual IndexCommit IndexCommit(IState state);
    public static ICollection`1<IndexCommit> ListCommits(Directory dir, IState state);
    public virtual IndexReader[] GetSequentialSubReaders();
    public virtual object get_FieldCacheKey();
    public virtual object get_DeletesCacheKey();
    public virtual long get_UniqueTermCount();
    public virtual int get_TermInfosIndexDivisor();
}
public class Lucene.Net.Index.IndexWriter : object {
    public static long WRITE_LOCK_TIMEOUT;
    private long writeLockTimeout;
    public static string WRITE_LOCK_NAME;
    public static int DISABLE_AUTO_FLUSH;
    public static int DEFAULT_MAX_BUFFERED_DOCS;
    public static double DEFAULT_RAM_BUFFER_SIZE_MB;
    public static int DEFAULT_MAX_BUFFERED_DELETE_TERMS;
    public static int DEFAULT_MAX_FIELD_LENGTH;
    public static int DEFAULT_TERM_INDEX_INTERVAL;
    public static int MAX_TERM_LENGTH;
    private static int MERGE_READ_BUFFER_SIZE;
    private static object MESSAGE_ID_LOCK;
    private static int MESSAGE_ID;
    private int messageID;
    private Boolean modreq(System.Runtime.CompilerServices.IsVolatile) hitOOM;
    private Directory directory;
    private Analyzer analyzer;
    private Similarity similarity;
    private UInt32 modreq(System.Runtime.CompilerServices.IsVolatile) changeCount;
    private long lastCommitChangeCount;
    private SegmentInfos rollbackSegmentInfos;
    private HashMap`2<SegmentInfo, Nullable`1<int>> rollbackSegments;
    internal SegmentInfos modreq(System.Runtime.CompilerServices.IsVolatile) pendingCommit;
    internal UInt32 modreq(System.Runtime.CompilerServices.IsVolatile) pendingCommitChangeCount;
    private SegmentInfos localRollbackSegmentInfos;
    private int localFlushedDocCount;
    private SegmentInfos segmentInfos;
    private int optimizeMaxNumSegments;
    internal DocumentsWriter docWriter;
    private IndexFileDeleter deleter;
    private ISet`1<SegmentInfo> segmentsToOptimize;
    private Lock writeLock;
    private int termIndexInterval;
    private bool closed;
    private bool closing;
    private HashSet`1<SegmentInfo> mergingSegments;
    private MergePolicy mergePolicy;
    private MergeScheduler mergeScheduler;
    private LinkedList`1<OneMerge> pendingMerges;
    private ISet`1<OneMerge> runningMerges;
    private IList`1<OneMerge> mergeExceptions;
    private long mergeGen;
    private bool stopMerges;
    internal int flushCount;
    private int flushDeletesCount;
    private int readCount;
    private ThreadClass writeThread;
    internal ReaderPool readerPool;
    private int upgradeCount;
    private OptimizeScope _optimizeScope;
    private int readerTermsIndexDivisor;
    private Boolean modreq(System.Runtime.CompilerServices.IsVolatile) poolReaders;
    private int maxFieldLength;
    private StreamWriter infoStream;
    private static StreamWriter defaultInfoStream;
    private object commitLock;
    private HashSet`1<string> synced;
    private HashSet`1<string> syncing;
    private IndexReaderWarmer mergedSegmentWarmer;
    public int PendingMergesCount { get; }
    public OptimizeScope OptimizeScope { get; }
    private LogMergePolicy LogMergePolicy { get; }
    public bool UseCompoundFile { get; public set; }
    public Similarity Similarity { get; }
    public int TermIndexInterval { get; public set; }
    public MergePolicy MergePolicy { get; }
    public MergeScheduler MergeScheduler { get; }
    public int MaxMergeDocs { get; public set; }
    public int ReaderTermsIndexDivisor { get; public set; }
    public int MergeFactor { get; public set; }
    public static StreamWriter DefaultInfoStream { get; public set; }
    public StreamWriter InfoStream { get; }
    public bool Verbose { get; }
    public long WriteLockTimeout { get; public set; }
    public static long DefaultWriteLockTimeout { get; public set; }
    public Directory Directory { get; }
    public Analyzer Analyzer { get; }
    public IndexReaderWarmer MergedSegmentWarmer { get; public set; }
    public IndexWriter(Directory d, Analyzer a, bool create, MaxFieldLength mfl, IState state);
    public IndexWriter(Directory d, Analyzer a, MaxFieldLength mfl, IState state);
    public IndexWriter(Directory d, Analyzer a, IndexDeletionPolicy deletionPolicy, MaxFieldLength mfl, IState state);
    public IndexWriter(Directory d, Analyzer a, bool create, IndexDeletionPolicy deletionPolicy, MaxFieldLength mfl, IState state);
    internal IndexWriter(Directory d, Analyzer a, bool create, IndexDeletionPolicy deletionPolicy, MaxFieldLength mfl, IndexingChain indexingChain, IndexCommit commit, IState state);
    public IndexWriter(Directory d, Analyzer a, IndexDeletionPolicy deletionPolicy, MaxFieldLength mfl, IndexCommit commit, IState state);
    private static IndexWriter();
    private void InitBlock();
    public int get_PendingMergesCount();
    public virtual IndexReader GetReader(IState state);
    public virtual IndexReader GetReader(int termInfosIndexDivisor, IState state);
    public virtual int NumDeletedDocs(SegmentInfo info, IState state);
    internal virtual void AcquireWrite();
    internal virtual void ReleaseWrite();
    internal virtual void AcquireRead();
    internal virtual void UpgradeReadToWrite();
    internal virtual void ReleaseRead();
    internal bool IsOpen(bool includePendingClose);
    protected internal void EnsureOpen(bool includePendingClose);
    protected internal void EnsureOpen();
    public virtual void Message(string message);
    private void SetMessageID(StreamWriter infoStream);
    public OptimizeScope get_OptimizeScope();
    private LogMergePolicy get_LogMergePolicy();
    public virtual bool get_UseCompoundFile();
    public virtual void set_UseCompoundFile(bool value);
    public virtual void SetSimilarity(Similarity similarity);
    public virtual Similarity get_Similarity();
    public virtual int get_TermIndexInterval();
    public virtual void set_TermIndexInterval(int value);
    private void Init(Directory d, Analyzer a, IndexDeletionPolicy deletionPolicy, int maxFieldLength, IndexingChain indexingChain, IndexCommit commit, IState state);
    private void Init(Directory d, Analyzer a, bool create, IndexDeletionPolicy deletionPolicy, int maxFieldLength, IndexingChain indexingChain, IndexCommit commit, IState state);
    private void SetRollbackSegmentInfos(SegmentInfos infos);
    public virtual void SetMergePolicy(MergePolicy mp);
    public virtual MergePolicy get_MergePolicy();
    public virtual void SetMergeScheduler(MergeScheduler mergeScheduler, IState state);
    public virtual MergeScheduler get_MergeScheduler();
    public virtual int get_MaxMergeDocs();
    public virtual void set_MaxMergeDocs(int value);
    public virtual void SetMaxFieldLength(int maxFieldLength);
    public virtual int GetMaxFieldLength();
    public int get_ReaderTermsIndexDivisor();
    public void set_ReaderTermsIndexDivisor(int value);
    public virtual void SetMaxBufferedDocs(int maxBufferedDocs);
    private void PushMaxBufferedDocs();
    public virtual int GetMaxBufferedDocs();
    public virtual void SetRAMBufferSizeMB(double mb);
    public virtual double GetRAMBufferSizeMB();
    public virtual void SetMaxBufferedDeleteTerms(int maxBufferedDeleteTerms);
    public virtual int GetMaxBufferedDeleteTerms();
    public virtual void set_MergeFactor(int value);
    public virtual int get_MergeFactor();
    public static void set_DefaultInfoStream(StreamWriter value);
    public static StreamWriter get_DefaultInfoStream();
    public virtual void SetInfoStream(StreamWriter infoStream, IState state);
    private void MessageState(IState state);
    public virtual StreamWriter get_InfoStream();
    public virtual bool get_Verbose();
    public virtual long get_WriteLockTimeout();
    public virtual void set_WriteLockTimeout(long value);
    public static void set_DefaultWriteLockTimeout(long value);
    public static long get_DefaultWriteLockTimeout();
    [ObsoleteAttribute("Use Dispose() instead")]
public void Close();
    public virtual void Dispose();
    public virtual void Dispose(bool waitForMerges);
    protected virtual void Dispose(bool disposing, bool waitForMerges, IState state);
    [ObsoleteAttribute("Use Dispose(bool) instead")]
public virtual void Close(bool waitForMerges);
    private bool ShouldClose();
    private void CloseInternal(bool waitForMerges, IState state);
    private bool FlushDocStores(IState state);
    public virtual Directory get_Directory();
    public virtual Analyzer get_Analyzer();
    public virtual int MaxDoc();
    public virtual int NumDocs(IState state);
    public virtual bool HasDeletions(IState state);
    public virtual void AddDocument(Document doc, IState state);
    public virtual void AddDocument(Document doc, Analyzer analyzer, IState state);
    public virtual void DeleteDocuments(Term term, IState state);
    public virtual void DeleteDocuments(IState state, Term[] terms);
    public virtual void DeleteDocuments(IState state, Query query);
    public virtual void DeleteDocuments(IState state, Query[] queries);
    public virtual void UpdateDocument(Term term, Document doc, IState state);
    public virtual void UpdateDocument(Term term, Document doc, Analyzer analyzer, IState state);
    internal int GetSegmentCount();
    internal int GetNumBufferedDocuments();
    public int GetDocCount(int i);
    internal int GetFlushCount();
    internal int GetFlushDeletesCount();
    internal string NewSegmentName();
    public virtual void Optimize(IState state, CancellationToken token);
    public virtual void Optimize(StreamWriter writer, IState state, CancellationToken token);
    public virtual void Optimize(int maxNumSegments, IState state, CancellationToken token);
    public virtual void Optimize(bool doWait, IState state, CancellationToken token);
    public virtual void Optimize(int maxNumSegments, bool doWait, IState state, CancellationToken token);
    public bool OptimizeMergesPending();
    public virtual void ExpungeDeletes(bool doWait, IState state);
    public virtual void ExpungeDeletes(IState state);
    public void MaybeMerge(IState state);
    private void MaybeMerge(bool optimize, IState state);
    private void MaybeMerge(int maxNumSegmentsOptimize, bool optimize, IState state);
    private void UpdatePendingMerges(int maxNumSegmentsOptimize, bool optimize, IState state);
    public virtual OneMerge GetNextMerge();
    private OneMerge GetNextExternalMerge();
    private void StartTransaction(bool haveReadLock, IState state);
    private void RollbackTransaction(IState state);
    private void CommitTransaction(IState state);
    public virtual void Rollback(IState state);
    private void RollbackInternal(IState state);
    public virtual void DeleteAll(IState state);
    private void FinishMerges(bool waitForMerges, IState state);
    public virtual void WaitForMerges();
    private void Checkpoint(IState state);
    private void FinishAddIndexes();
    private void BlockAddIndexes(bool includePendingClose);
    private void ResumeAddIndexes();
    private void ResetMergeExceptions();
    private void NoDupDirs(Directory[] dirs);
    public virtual void AddIndexesNoOptimize(IState state, Directory[] dirs);
    private bool HasExternalSegments();
    private void ResolveExternalSegments(IState state);
    public virtual void AddIndexes(IState state, IndexReader[] readers);
    protected virtual void DoAfterFlush();
    protected virtual void DoBeforeFlush();
    public void PrepareCommit(IState state);
    private void PrepareCommit(IDictionary`2<string, string> commitUserData, IState state);
    private void Commit(long sizeInBytes, IState state);
    public void Commit(IState state);
    public void Commit(IDictionary`2<string, string> commitUserData, IState state);
    private void FinishCommit(IState state);
    public void Flush(bool triggerMerge, bool flushDocStores, bool flushDeletes, IState state);
    private bool DoFlush(bool flushDocStores, bool flushDeletes, IState state);
    private bool DoFlushInternal(bool flushDocStores, bool flushDeletes, IState state);
    public long RamSizeInBytes();
    public int NumRamDocs();
    private int EnsureContiguousMerge(OneMerge merge, IState state);
    private void CommitMergedDeletes(OneMerge merge, SegmentReader mergeReader, IState state);
    private bool CommitMerge(OneMerge merge, SegmentMerger merger, int mergedDocCount, SegmentReader mergedReader, IState state);
    private void HandleMergeException(Exception t, OneMerge merge, IState state);
    public void Merge_ForNUnit(OneMerge merge, IState state);
    public void Merge(OneMerge merge, IState state);
    internal virtual void MergeSuccess(OneMerge merge);
    internal bool RegisterMerge(OneMerge merge, IState state);
    internal void MergeInit(OneMerge merge, IState state);
    private void _MergeInit(OneMerge merge, IState state);
    private void SetDiagnostics(SegmentInfo info, string source);
    private void SetDiagnostics(SegmentInfo info, string source, IDictionary`2<string, string> details);
    internal void MergeFinish(OneMerge merge);
    private void SetMergeDocStoreIsCompoundFile(OneMerge merge);
    private void CloseMergeReaders(OneMerge merge, bool suppressExceptions, IState state);
    private int MergeMiddle(OneMerge merge, IState state);
    internal virtual void AddMergeException(OneMerge merge);
    protected virtual bool ApplyDeletes(IState state);
    internal int GetBufferedDeleteTermsSize();
    internal int GetNumBufferedDeleteTerms();
    public virtual SegmentInfo NewestSegment();
    public virtual string SegString(IState state);
    private string SegString(SegmentInfos infos, IState state);
    private bool StartSync(string fileName, ICollection`1<string> pending);
    private void FinishSync(string fileName, bool success);
    private bool WaitForAllSynced(ICollection`1<string> syncing);
    private void DoWait();
    private void StartCommit(long sizeInBytes, IDictionary`2<string, string> commitUserData, IState state);
    public static bool IsLocked(Directory directory);
    public static void Unlock(Directory directory);
    public virtual void set_MergedSegmentWarmer(IndexReaderWarmer value);
    public virtual IndexReaderWarmer get_MergedSegmentWarmer();
    private void HandleOOM(OutOfMemoryException oom, string location);
    public virtual bool TestPoint(string name);
    internal virtual bool NrtIsCurrent(SegmentInfos infos);
    internal virtual bool IsClosed();
}
internal class Lucene.Net.Index.IntBlockPool : object {
    public Int32[][] buffers;
    internal int bufferUpto;
    public int intUpto;
    public Int32[] buffer;
    public int intOffset;
    private DocumentsWriter docWriter;
    internal bool trackAllocations;
    public IntBlockPool(DocumentsWriter docWriter, bool trackAllocations);
    private void InitBlock();
    public void Reset();
    public void NextBuffer();
}
internal abstract class Lucene.Net.Index.InvertedDocConsumer : object {
    internal FieldInfos fieldInfos;
    internal abstract virtual InvertedDocConsumerPerThread AddThread(DocInverterPerThread docInverterPerThread);
    public abstract virtual void Abort();
    internal abstract virtual void Flush(IDictionary`2<InvertedDocConsumerPerThread, ICollection`1<InvertedDocConsumerPerField>> threadsAndFields, SegmentWriteState state, IState s);
    internal abstract virtual void CloseDocStore(SegmentWriteState state, IState s);
    public abstract virtual bool FreeRAM();
    internal virtual void SetFieldInfos(FieldInfos fieldInfos);
}
internal abstract class Lucene.Net.Index.InvertedDocConsumerPerField : object {
    internal abstract virtual bool Start(IFieldable[] fields, int count);
    internal abstract virtual void Start(IFieldable field);
    internal abstract virtual void Add();
    internal abstract virtual void Finish();
    public abstract virtual void Abort();
}
internal abstract class Lucene.Net.Index.InvertedDocConsumerPerThread : object {
    public abstract virtual void StartDocument();
    internal abstract virtual InvertedDocConsumerPerField AddField(DocInverterPerField docInverterPerField, FieldInfo fieldInfo);
    public abstract virtual DocWriter FinishDocument();
    public abstract virtual void Abort();
}
internal abstract class Lucene.Net.Index.InvertedDocEndConsumer : object {
    public abstract virtual InvertedDocEndConsumerPerThread AddThread(DocInverterPerThread docInverterPerThread);
    public abstract virtual void Flush(IDictionary`2<InvertedDocEndConsumerPerThread, ICollection`1<InvertedDocEndConsumerPerField>> threadsAndFields, SegmentWriteState state, IState s);
    internal abstract virtual void CloseDocStore(SegmentWriteState state);
    public abstract virtual void Abort();
    internal abstract virtual void SetFieldInfos(FieldInfos fieldInfos);
}
internal abstract class Lucene.Net.Index.InvertedDocEndConsumerPerField : object {
    internal abstract virtual void Finish();
    internal abstract virtual void Abort();
}
internal abstract class Lucene.Net.Index.InvertedDocEndConsumerPerThread : object {
    internal abstract virtual void StartDocument();
    internal abstract virtual InvertedDocEndConsumerPerField AddField(DocInverterPerField docInverterPerField, FieldInfo fieldInfo);
    internal abstract virtual void FinishDocument();
    internal abstract virtual void Abort();
}
public interface Lucene.Net.Index.ITermFreqVector {
    public string Field { get; }
    public int Size { get; }
    public abstract virtual string get_Field();
    public abstract virtual int get_Size();
    public abstract virtual String[] GetTerms();
    public abstract virtual Int32[] GetTermFrequencies();
    public abstract virtual int IndexOf(string term);
    public abstract virtual Int32[] IndexesOf(String[] terms, int start, int len);
}
public class Lucene.Net.Index.KeepOnlyLastCommitDeletionPolicy : object {
    public sealed virtual void OnInit(IList`1<T> commits);
    public sealed virtual void OnCommit(IList`1<T> commits);
}
public class Lucene.Net.Index.LogByteSizeMergePolicy : LogMergePolicy {
    public static double DEFAULT_MIN_MERGE_MB;
    public static long DEFAULT_MAX_MERGE_MB;
    public static long DEFAULT_LARGE_SEGMENT_SIZE_MB;
    public double MaxMergeMB { get; public set; }
    public double LargeSegmentSizeMB { get; public set; }
    public double MinMergeMB { get; public set; }
    public LogByteSizeMergePolicy(IndexWriter writer);
    private static LogByteSizeMergePolicy();
    protected internal virtual long Size(SegmentInfo info, IState state);
    protected virtual void Dispose(bool disposing);
    public virtual double get_MaxMergeMB();
    public virtual void set_MaxMergeMB(double value);
    public virtual double get_LargeSegmentSizeMB();
    public virtual void set_LargeSegmentSizeMB(double value);
    public virtual double get_MinMergeMB();
    public virtual void set_MinMergeMB(double value);
}
public class Lucene.Net.Index.LogDocMergePolicy : LogMergePolicy {
    public static int DEFAULT_MIN_MERGE_DOCS;
    public int MinMergeDocs { get; public set; }
    public LogDocMergePolicy(IndexWriter writer);
    protected internal virtual long Size(SegmentInfo info, IState state);
    protected virtual void Dispose(bool disposing);
    public virtual int get_MinMergeDocs();
    public virtual void set_MinMergeDocs(int value);
}
public abstract class Lucene.Net.Index.LogMergePolicy : MergePolicy {
    public static double LEVEL_LOG_SPAN;
    public static int DEFAULT_MERGE_FACTOR;
    public static int DEFAULT_NUMBER_OF_LARGE_SEGMENTS_TO_MERGE_IN_A_SINGLE_BATCH;
    public static int DEFAULT_MAX_MERGE_DOCS;
    public static double DEFAULT_NO_CFS_RATIO;
    private int mergeFactor;
    private int numberOfLargeSegmentsToMergeInSingleBatch;
    internal long minMergeSize;
    internal long maxMergeSize;
    internal long largeSegmentSize;
    internal int maxMergeDocs;
    protected double internalNoCFSRatio;
    protected internal bool internalCalibrateSizeByDeletes;
    private bool useCompoundFile;
    private bool useCompoundDocStore;
    public double NoCFSRatio { get; public set; }
    public int MergeFactor { get; public set; }
    public int NumberOfLargeSegmentsToMergeInSingleBatch { get; public set; }
    public bool CalibrateSizeByDeletes { get; public set; }
    public int MaxMergeDocs { get; public set; }
    protected LogMergePolicy(IndexWriter writer);
    private static LogMergePolicy();
    protected internal virtual bool Verbose();
    public double get_NoCFSRatio();
    public void set_NoCFSRatio(double value);
    private void Message(string message);
    public virtual int get_MergeFactor();
    public virtual void set_MergeFactor(int value);
    public virtual int get_NumberOfLargeSegmentsToMergeInSingleBatch();
    public virtual void set_NumberOfLargeSegmentsToMergeInSingleBatch(int value);
    public virtual bool UseCompoundFile(SegmentInfos infos, SegmentInfo info);
    public virtual void SetUseCompoundFile(bool useCompoundFile);
    public virtual bool GetUseCompoundFile();
    public virtual bool UseCompoundDocStore(SegmentInfos infos);
    public virtual void SetUseCompoundDocStore(bool useCompoundDocStore);
    public virtual bool GetUseCompoundDocStore();
    public virtual void set_CalibrateSizeByDeletes(bool value);
    public virtual bool get_CalibrateSizeByDeletes();
    protected internal abstract virtual long Size(SegmentInfo info, IState state);
    protected internal virtual long SizeDocs(SegmentInfo info, IState state);
    protected internal virtual long SizeBytes(SegmentInfo info, IState state);
    private bool IsOptimized(SegmentInfos infos, int maxNumSegments, ISet`1<SegmentInfo> segmentsToOptimize, IState state);
    private bool IsOptimized(SegmentInfo info, IState state);
    public virtual MergeSpecification FindMergesForOptimize(SegmentInfos infos, int maxNumSegments, ISet`1<SegmentInfo> segmentsToOptimize, IState state);
    public virtual MergeSpecification FindMergesToExpungeDeletes(SegmentInfos segmentInfos, IState state);
    public virtual MergeSpecification FindMerges(SegmentInfos infos, IState state);
    protected OneMerge MakeOneMerge(SegmentInfos infos, SegmentInfos infosToMerge, IState state);
    public virtual void set_MaxMergeDocs(int value);
    public virtual int get_MaxMergeDocs();
}
internal class Lucene.Net.Index.MergeDocIDRemapper : object {
    internal Int32[] starts;
    internal Int32[] newStarts;
    internal Int32[][] docMaps;
    internal int minDocID;
    internal int maxDocID;
    internal int docShift;
    public MergeDocIDRemapper(SegmentInfos infos, Int32[][] docMaps, Int32[] delCounts, OneMerge merge, int mergedDocCount);
    public int Remap(int oldDocID);
}
public abstract class Lucene.Net.Index.MergePolicy : object {
    protected internal IndexWriter writer;
    protected MergePolicy(IndexWriter writer);
    public abstract virtual MergeSpecification FindMerges(SegmentInfos segmentInfos, IState state);
    public abstract virtual MergeSpecification FindMergesForOptimize(SegmentInfos segmentInfos, int maxSegmentCount, ISet`1<SegmentInfo> segmentsToOptimize, IState state);
    public abstract virtual MergeSpecification FindMergesToExpungeDeletes(SegmentInfos segmentInfos, IState state);
    [ObsoleteAttribute("Use Dispose() instead")]
public void Close();
    public sealed virtual void Dispose();
    protected abstract virtual void Dispose(bool disposing);
    public abstract virtual bool UseCompoundFile(SegmentInfos segments, SegmentInfo newSegment);
    public abstract virtual bool UseCompoundDocStore(SegmentInfos segments);
}
public abstract class Lucene.Net.Index.MergeScheduler : object {
    public abstract virtual void Merge(IndexWriter writer, IState state);
    [ObsoleteAttribute("Use Dispose() instead")]
public void Close();
    public sealed virtual void Dispose();
    protected abstract virtual void Dispose(bool disposing);
}
internal abstract class Lucene.Net.Index.MultiLevelSkipListReader : object {
    private int maxNumberOfSkipLevels;
    private int numberOfSkipLevels;
    private static int numberOfLevelsToBuffer;
    private int docCount;
    private bool haveSkipped;
    private bool isDisposed;
    private IndexInput[] skipStream;
    private Int64[] skipPointer;
    private Int32[] skipInterval;
    private Int32[] numSkipped;
    private Int32[] skipDoc;
    private int lastDoc;
    private Int64[] childPointer;
    private long lastChildPointer;
    private bool inputIsBuffered;
    protected MultiLevelSkipListReader(IndexInput skipStream, int maxSkipLevels, int skipInterval);
    internal virtual int GetDoc();
    internal virtual int SkipTo(int target, IState state);
    private bool LoadNextSkip(int level, IState state);
    protected internal virtual void SeekChild(int level, IState state);
    public sealed virtual void Dispose();
    protected virtual void Dispose(bool disposing);
    internal virtual void Init(long skipPointer, int df);
    private void LoadSkipLevels(IState state);
    protected internal abstract virtual int ReadSkipData(int level, IndexInput skipStream, IState state);
    protected internal virtual void SetLastSkipData(int level);
}
internal abstract class Lucene.Net.Index.MultiLevelSkipListWriter : object {
    private int numberOfSkipLevels;
    private int skipInterval;
    private RAMOutputStream[] skipBuffer;
    protected internal MultiLevelSkipListWriter(int skipInterval, int maxSkipLevels, int df);
    protected internal virtual void Init();
    protected internal virtual void ResetSkip();
    protected void ResetSkipInternal();
    protected internal abstract virtual void WriteSkipData(int level, IndexOutput skipBuffer);
    internal virtual void BufferSkip(int df);
    internal virtual long WriteSkip(IndexOutput output);
}
public class Lucene.Net.Index.MultipleTermPositions : object {
    private int _doc;
    private int _freq;
    private TermPositionsQueue _termPositionsQueue;
    private IntQueue _posList;
    private bool isDisposed;
    public int Doc { get; }
    public int Freq { get; }
    public int PayloadLength { get; }
    public bool IsPayloadAvailable { get; }
    public MultipleTermPositions(IndexReader indexReader, Term[] terms, IState state);
    public sealed virtual bool Next(IState state);
    public sealed virtual int NextPosition(IState state);
    public sealed virtual bool SkipTo(int target, IState state);
    public sealed virtual int get_Doc();
    public sealed virtual int get_Freq();
    [ObsoleteAttribute("Use Dispose() instead")]
public sealed virtual void Close();
    public sealed virtual void Dispose();
    protected virtual void Dispose(bool disposing);
    public virtual void Seek(Term arg0, IState state);
    public virtual void Seek(TermEnum termEnum, IState state);
    public virtual int Read(Int32[] arg0, Int32[] arg1, IState state);
    public virtual int get_PayloadLength();
    public virtual Byte[] GetPayload(Byte[] data, int offset, IState state);
    public virtual bool get_IsPayloadAvailable();
}
public class Lucene.Net.Index.MultiReader : IndexReader {
    protected internal IndexReader[] subReaders;
    private Int32[] starts;
    private Boolean[] decrefOnClose;
    private HashMap`2<string, Byte[]> normsCache;
    private int maxDoc;
    private int numDocs;
    private bool hasDeletions;
    public int MaxDoc { get; }
    public bool HasDeletions { get; }
    public long Version { get; }
    public MultiReader(IndexReader[] subReaders);
    public MultiReader(IndexReader[] subReaders, bool closeSubReaders);
    private void Initialize(IndexReader[] subReaders, bool closeSubReaders);
    public virtual string GetStringValueFor(string field, int doc, IState state);
    public virtual long GetLongValueFor(string field, LongParser parser, int doc, IState state);
    public virtual double GetDoubleValueFor(string field, DoubleParser parser, int doc, IState state);
    public virtual IndexReader Reopen(IState state);
    public virtual object Clone(IState state);
    protected internal virtual IndexReader DoReopen(bool doClone, IState state);
    public virtual ITermFreqVector[] GetTermFreqVectors(int n, IState state);
    public virtual ITermFreqVector GetTermFreqVector(int n, string field, IState state);
    public virtual void GetTermFreqVector(int docNumber, string field, TermVectorMapper mapper, IState state);
    public virtual void GetTermFreqVector(int docNumber, TermVectorMapper mapper, IState state);
    public virtual bool IsOptimized();
    public virtual int NumDocs();
    public virtual int get_MaxDoc();
    public virtual Document Document(int n, FieldSelector fieldSelector, IState state);
    public virtual bool IsDeleted(int n);
    public virtual bool get_HasDeletions();
    protected internal virtual void DoDelete(int n, IState state);
    protected internal virtual void DoUndeleteAll(IState state);
    private int ReaderIndex(int n);
    public virtual bool HasNorms(string field, IState state);
    public virtual Byte[] Norms(string field, IState state);
    public virtual void Norms(string field, Byte[] result, int offset, IState state);
    protected internal virtual void DoSetNorm(int n, string field, byte value_Renamed, IState state);
    public virtual TermEnum Terms(IState state);
    public virtual TermEnum Terms(Term term, IState state);
    public virtual int DocFreq(Term t, IState state);
    public virtual TermDocs TermDocs(IState state);
    public virtual TermPositions TermPositions(IState state);
    protected internal virtual void DoCommit(IDictionary`2<string, string> commitUserData, IState state);
    protected internal virtual void DoClose(IState state);
    public virtual ICollection`1<string> GetFieldNames(FieldOption fieldNames);
    public virtual bool IsCurrent(IState state);
    public virtual long get_Version();
    public virtual IndexReader[] GetSequentialSubReaders();
}
internal class Lucene.Net.Index.NormsWriter : InvertedDocEndConsumer {
    private static byte defaultNorm;
    private FieldInfos fieldInfos;
    private static NormsWriter();
    public virtual InvertedDocEndConsumerPerThread AddThread(DocInverterPerThread docInverterPerThread);
    public virtual void Abort();
    internal void Files(ICollection`1<string> files);
    internal virtual void SetFieldInfos(FieldInfos fieldInfos);
    public virtual void Flush(IDictionary`2<InvertedDocEndConsumerPerThread, ICollection`1<InvertedDocEndConsumerPerField>> threadsAndFields, SegmentWriteState state, IState s);
    internal virtual void CloseDocStore(SegmentWriteState state);
}
internal class Lucene.Net.Index.NormsWriterPerField : InvertedDocEndConsumerPerField {
    internal NormsWriterPerThread perThread;
    internal FieldInfo fieldInfo;
    internal DocState docState;
    internal Int32[] docIDs;
    internal Byte[] norms;
    internal int upto;
    internal FieldInvertState fieldState;
    public NormsWriterPerField(DocInverterPerField docInverterPerField, NormsWriterPerThread perThread, FieldInfo fieldInfo);
    public void Reset();
    internal virtual void Abort();
    public sealed virtual int CompareTo(NormsWriterPerField other);
    internal virtual void Finish();
}
internal class Lucene.Net.Index.NormsWriterPerThread : InvertedDocEndConsumerPerThread {
    internal NormsWriter normsWriter;
    internal DocState docState;
    public NormsWriterPerThread(DocInverterPerThread docInverterPerThread, NormsWriter normsWriter);
    internal virtual InvertedDocEndConsumerPerField AddField(DocInverterPerField docInverterPerField, FieldInfo fieldInfo);
    internal virtual void Abort();
    internal virtual void StartDocument();
    internal virtual void FinishDocument();
    internal bool FreeRAM();
}
public class Lucene.Net.Index.OptimizeScope : object {
    public bool IsDisposed;
    public bool IsRunning;
    public CancellationToken Token;
    public OptimizeScope(CancellationToken token);
    public sealed virtual void Dispose();
}
internal class Lucene.Net.Index.ParallelArrayTermVectorMapper : TermVectorMapper {
    private String[] terms;
    private Int32[] termFreqs;
    private Int32[][] positions;
    private TermVectorOffsetInfo[][] offsets;
    private int currentPosition;
    private bool storingOffsets;
    private bool storingPositions;
    private string field;
    public virtual void SetExpectations(string field, int numTerms, bool storeOffsets, bool storePositions);
    public virtual void Map(string term, int frequency, TermVectorOffsetInfo[] offsets, Int32[] positions);
    public virtual ITermFreqVector MaterializeVector();
}
public class Lucene.Net.Index.ParallelReader : IndexReader {
    private List`1<IndexReader> readers;
    private List`1<bool> decrefOnClose;
    internal bool incRefReaders;
    private SortedDictionary`2<string, IndexReader> fieldToReader;
    private HashMap`2<IndexReader, ICollection`1<string>> readerToFields;
    private List`1<IndexReader> storedFieldReaders;
    private int maxDoc;
    private int numDocs;
    private bool hasDeletions;
    public int MaxDoc { get; }
    public bool HasDeletions { get; }
    public long Version { get; }
    public ParallelReader(bool closeSubReaders);
    public virtual void Add(IndexReader reader);
    public virtual void Add(IndexReader reader, bool ignoreStoredFields);
    public virtual object Clone(IState state);
    public virtual string GetStringValueFor(string field, int doc, IState state);
    public virtual long GetLongValueFor(string field, LongParser parser, int doc, IState state);
    public virtual double GetDoubleValueFor(string field, DoubleParser parser, int doc, IState state);
    public virtual IndexReader Reopen(IState state);
    protected internal virtual IndexReader DoReopen(bool doClone, IState state);
    public virtual int NumDocs();
    public virtual int get_MaxDoc();
    public virtual bool get_HasDeletions();
    public virtual bool IsDeleted(int n);
    protected internal virtual void DoDelete(int n, IState state);
    protected internal virtual void DoUndeleteAll(IState state);
    public virtual Document Document(int n, FieldSelector fieldSelector, IState state);
    public virtual ITermFreqVector[] GetTermFreqVectors(int n, IState state);
    public virtual ITermFreqVector GetTermFreqVector(int n, string field, IState state);
    public virtual void GetTermFreqVector(int docNumber, string field, TermVectorMapper mapper, IState state);
    public virtual void GetTermFreqVector(int docNumber, TermVectorMapper mapper, IState state);
    public virtual bool HasNorms(string field, IState state);
    public virtual Byte[] Norms(string field, IState state);
    public virtual void Norms(string field, Byte[] result, int offset, IState state);
    protected internal virtual void DoSetNorm(int n, string field, byte value_Renamed, IState state);
    public virtual TermEnum Terms(IState state);
    public virtual TermEnum Terms(Term term, IState state);
    public virtual int DocFreq(Term term, IState state);
    public virtual TermDocs TermDocs(Term term, IState state);
    public virtual TermDocs TermDocs(IState state);
    public virtual TermPositions TermPositions(Term term, IState state);
    public virtual TermPositions TermPositions(IState state);
    public virtual bool IsCurrent(IState state);
    public virtual bool IsOptimized();
    public virtual long get_Version();
    public virtual IndexReader[] GetSubReaders();
    protected internal virtual void DoCommit(IDictionary`2<string, string> commitUserData, IState state);
    protected internal virtual void DoClose(IState state);
    public virtual ICollection`1<string> GetFieldNames(FieldOption fieldNames);
}
public class Lucene.Net.Index.Payload : object {
    protected internal Byte[] data;
    protected internal int internalOffset;
    protected internal int internalLength;
    public int Offset { get; }
    public int Length { get; }
    public Payload(Byte[] data);
    public Payload(Byte[] data, int offset, int length);
    public virtual void SetData(Byte[] value, int offset, int length);
    public virtual void SetData(Byte[] value);
    public virtual Byte[] GetData();
    public virtual int get_Offset();
    public virtual int get_Length();
    public virtual byte ByteAt(int index);
    public virtual Byte[] ToByteArray();
    public virtual void CopyTo(Byte[] target, int targetOffset);
    public virtual object Clone();
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
}
public class Lucene.Net.Index.PositionBasedTermVectorMapper : TermVectorMapper {
    private IDictionary`2<string, IDictionary`2<int, TVPositionInfo>> fieldToTerms;
    private string currentField;
    private IDictionary`2<int, TVPositionInfo> currentPositions;
    private bool storeOffsets;
    public bool IsIgnoringPositions { get; }
    public IDictionary`2<string, IDictionary`2<int, TVPositionInfo>> FieldToTerms { get; }
    public PositionBasedTermVectorMapper(bool ignoringOffsets);
    public virtual bool get_IsIgnoringPositions();
    public virtual void Map(string term, int frequency, TermVectorOffsetInfo[] offsets, Int32[] positions);
    public virtual void SetExpectations(string field, int numTerms, bool storeOffsets, bool storePositions);
    public virtual IDictionary`2<string, IDictionary`2<int, TVPositionInfo>> get_FieldToTerms();
}
internal abstract class Lucene.Net.Index.RawPostingList : object {
    internal static int BYTES_SIZE;
    internal int textStart;
    internal int intStart;
    internal int byteStart;
    private static RawPostingList();
}
public class Lucene.Net.Index.ReadOnlyDirectoryReader : DirectoryReader {
    internal ReadOnlyDirectoryReader(Directory directory, SegmentInfos sis, IndexDeletionPolicy deletionPolicy, int termInfosIndexDivisor, IState state);
    internal ReadOnlyDirectoryReader(Directory directory, SegmentInfos infos, SegmentReader[] oldReaders, Int32[] oldStarts, IDictionary`2<string, Byte[]> oldNormsCache, bool doClone, int termInfosIndexDivisor, IState state);
    internal ReadOnlyDirectoryReader(IndexWriter writer, SegmentInfos infos, int termInfosIndexDivisor, IState state);
    protected internal virtual void AcquireWriteLock(IState state);
}
public class Lucene.Net.Index.ReadOnlySegmentReader : SegmentReader {
    internal static void NoWrite();
    protected internal virtual void AcquireWriteLock(IState state);
    public virtual bool IsDeleted(int n);
}
internal class Lucene.Net.Index.ReusableStringReader : TextReader {
    internal int upto;
    internal int left;
    internal string s;
    internal void Init(string s);
    public int Read(Char[] c);
    public virtual int Read(Char[] c, int off, int len);
    public virtual void Close();
    public virtual int Read();
    public virtual int ReadBlock(Char[] buffer, int index, int count);
    public virtual string ReadLine();
    public virtual int Peek();
    public virtual string ReadToEnd();
}
public class Lucene.Net.Index.SegmentInfo : object {
    internal static int NO;
    internal static int YES;
    internal static int CHECK_DIR;
    internal static int WITHOUT_GEN;
    public string name;
    public int docCount;
    public Directory dir;
    private bool preLockless;
    private long delGen;
    private Int64[] normGen;
    private sbyte isCompoundFile;
    private bool hasSingleNormFile;
    private IList`1<string> files;
    internal long sizeInBytes;
    private int docStoreOffset;
    private string docStoreSegment;
    private bool docStoreIsCompoundFile;
    private int delCount;
    private bool hasProx;
    private IDictionary`2<string, string> diagnostics;
    public IDictionary`2<string, string> Diagnostics { get; internal set; }
    public int DocStoreOffset { get; internal set; }
    public bool DocStoreIsCompoundFile { get; internal set; }
    public string DocStoreSegment { get; }
    public bool HasProx { get; internal set; }
    public SegmentInfo(string name, int docCount, Directory dir);
    public SegmentInfo(string name, int docCount, Directory dir, bool isCompoundFile, bool hasSingleNormFile);
    public SegmentInfo(string name, int docCount, Directory dir, bool isCompoundFile, bool hasSingleNormFile, int docStoreOffset, string docStoreSegment, bool docStoreIsCompoundFile, bool hasProx);
    internal SegmentInfo(Directory dir, int format, IndexInput input, IState state);
    public virtual string ToString();
    internal void Reset(SegmentInfo src);
    public IDictionary`2<string, string> get_Diagnostics();
    internal void set_Diagnostics(IDictionary`2<string, string> value);
    internal void SetNumFields(int numFields);
    public long SizeInBytes(IState state);
    public bool HasDeletions(IState state);
    internal void AdvanceDelGen();
    internal void ClearDelGen();
    public sealed virtual object Clone();
    public string GetDelFileName();
    public bool HasSeparateNorms(int fieldNumber, IState state);
    public bool HasSeparateNorms(IState state);
    internal void AdvanceNormGen(int fieldIndex);
    public string GetNormFileName(int number, IState state);
    internal void SetUseCompoundFile(bool value);
    public bool GetUseCompoundFile(IState state);
    public int GetDelCount(IState state);
    internal void SetDelCount(int delCount);
    public int get_DocStoreOffset();
    internal void set_DocStoreOffset(int value);
    public bool get_DocStoreIsCompoundFile();
    internal void set_DocStoreIsCompoundFile(bool value);
    public string get_DocStoreSegment();
    internal void SetDocStore(int offset, string segment, bool isCompoundFile);
    internal void Write(IndexOutput output);
    public bool get_HasProx();
    internal void set_HasProx(bool value);
    private void AddIfExists(IList`1<string> files, string fileName, IState state);
    public IList`1<string> Files(IState state);
    private void ClearFiles();
    public string SegString(Directory dir, IState state);
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
}
public class Lucene.Net.Index.SegmentInfos : List`1<SegmentInfo> {
    public static int FORMAT;
    public static int FORMAT_LOCKLESS;
    public static int FORMAT_SINGLE_NORM_FILE;
    public static int FORMAT_SHARED_DOC_STORE;
    public static int FORMAT_CHECKSUM;
    public static int FORMAT_DEL_COUNT;
    public static int FORMAT_HAS_PROX;
    public static int FORMAT_USER_DATA;
    public static int FORMAT_DIAGNOSTICS;
    internal static int CURRENT_FORMAT;
    public int counter;
    private long version;
    private long generation;
    private long lastGeneration;
    private IDictionary`2<string, string> userData;
    private static StreamWriter infoStream;
    internal ChecksumIndexOutput pendingSegnOutput;
    private static int defaultGenFileRetryCount;
    private static int defaultGenFileRetryPauseMsec;
    private static int defaultGenLookaheadCount;
    public long Version { get; }
    public long Generation { get; }
    public long LastGeneration { get; }
    public static int DefaultGenFileRetryCount { get; public set; }
    public static int DefaultGenFileRetryPauseMsec { get; public set; }
    public static int DefaultGenLookaheadCount { get; public set; }
    public static StreamWriter InfoStream { get; }
    public IDictionary`2<string, string> UserData { get; internal set; }
    private static SegmentInfos();
    public SegmentInfo Info(int i);
    public static long GetCurrentSegmentGeneration(String[] files);
    public static long GetCurrentSegmentGeneration(Directory directory, IState state);
    public static string GetCurrentSegmentFileName(String[] files);
    public static string GetCurrentSegmentFileName(Directory directory, IState state);
    public string GetCurrentSegmentFileName();
    public static long GenerationFromSegmentsFileName(string fileName);
    public string GetNextSegmentFileName();
    public void Read(Directory directory, string segmentFileName, IState state);
    public void Read(Directory directory, IState state);
    private void Write(Directory directory, IState state);
    public sealed virtual object Clone();
    public long get_Version();
    public long get_Generation();
    public long get_LastGeneration();
    public static long ReadCurrentVersion(Directory directory, IState state);
    public static IDictionary`2<string, string> ReadCurrentUserData(Directory directory, IState state);
    public static void SetInfoStream(StreamWriter infoStream);
    public static int get_DefaultGenFileRetryCount();
    public static void set_DefaultGenFileRetryCount(int value);
    public static void set_DefaultGenFileRetryPauseMsec(int value);
    public static int get_DefaultGenFileRetryPauseMsec();
    public static void set_DefaultGenLookaheadCount(int value);
    public static int get_DefaultGenLookaheadCount();
    public static StreamWriter get_InfoStream();
    private static void Message(string message);
    public SegmentInfos Range(int first, int last);
    internal void UpdateGeneration(SegmentInfos other);
    internal void RollbackCommit(Directory dir, IState state);
    internal void PrepareCommit(Directory dir, IState state);
    public ICollection`1<string> Files(Directory dir, bool includeSegmentsFile, IState state);
    internal void FinishCommit(Directory dir, IState state);
    public void Commit(Directory dir, IState state);
    public string SegString(Directory directory, IState state);
    public IDictionary`2<string, string> get_UserData();
    internal void set_UserData(IDictionary`2<string, string> value);
    internal void Replace(SegmentInfos other);
    public bool HasExternalSegments(Directory dir);
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
}
internal class Lucene.Net.Index.SegmentMergeInfo : object {
    internal Term term;
    internal int base_Renamed;
    internal int ord;
    internal TermEnum termEnum;
    internal IndexReader reader;
    internal int delCount;
    private TermPositions postings;
    private Int32[] docMap;
    private bool isDisposed;
    internal SegmentMergeInfo(int b, TermEnum te, IndexReader r);
    internal Int32[] GetDocMap();
    internal TermPositions GetPositions(IState state);
    internal bool Next(IState state);
    public sealed virtual void Dispose();
}
internal class Lucene.Net.Index.SegmentMergeQueue : PriorityQueue`1<SegmentMergeInfo> {
    internal SegmentMergeQueue(int size);
    public virtual bool LessThan(SegmentMergeInfo stiA, SegmentMergeInfo stiB);
    public sealed virtual void Dispose();
}
public class Lucene.Net.Index.SegmentMerger : object {
    internal static Byte[] NORMS_HEADER;
    private Directory directory;
    private string segment;
    private int termIndexInterval;
    private IList`1<IndexReader> readers;
    private FieldInfos fieldInfos;
    private int mergedDocs;
    private CheckAbort checkAbort;
    private bool mergeDocStores;
    private static int MAX_RAW_MERGE_DOCS;
    private SegmentReader[] matchingSegmentReaders;
    private Int32[] rawDocLengths;
    private Int32[] rawDocLengths2;
    private SegmentMergeQueue queue;
    internal bool omitTermFreqAndPositions;
    private Byte[] payloadBuffer;
    private Int32[][] docMaps;
    private Int32[] delCounts;
    public SegmentMerger(Directory dir, string name);
    internal SegmentMerger(IndexWriter writer, string name, OneMerge merge);
    private static SegmentMerger();
    private void InitBlock();
    internal bool HasProx();
    public void Add(IndexReader reader);
    internal IndexReader SegmentReader(int i);
    public int Merge(IState state);
    internal int Merge(bool mergeDocStores, IState state);
    internal void CloseReaders();
    internal ICollection`1<string> GetMergedFiles();
    public ICollection`1<string> CreateCompoundFile(string fileName);
    private void AddIndexed(IndexReader reader, FieldInfos fInfos, ICollection`1<string> names, bool storeTermVectors, bool storePositionWithTermVector, bool storeOffsetWithTermVector, bool storePayloads, bool omitTFAndPositions, IState state);
    private void SetMatchingSegmentReaders();
    private int MergeFields(IState state);
    private int CopyFieldsWithDeletions(FieldsWriter fieldsWriter, IndexReader reader, FieldsReader matchingFieldsReader, IState state);
    private int CopyFieldsNoDeletions(FieldsWriter fieldsWriter, IndexReader reader, FieldsReader matchingFieldsReader, IState state);
    private void MergeVectors(IState state);
    private void CopyVectorsWithDeletions(TermVectorsWriter termVectorsWriter, TermVectorsReader matchingVectorsReader, IndexReader reader, IState state);
    private void CopyVectorsNoDeletions(TermVectorsWriter termVectorsWriter, TermVectorsReader matchingVectorsReader, IndexReader reader, IState state);
    private void MergeTerms(IState s);
    private void MergeTermInfos(FormatPostingsFieldsConsumer consumer, IState state);
    internal Int32[][] GetDocMaps();
    internal Int32[] GetDelCounts();
    private int AppendPostings(FormatPostingsTermsConsumer termsConsumer, SegmentMergeInfo[] smis, int n, IState state);
    private void MergeNorms(IState state);
}
public class Lucene.Net.Index.SegmentReader : IndexReader {
    protected internal bool readOnly;
    private SegmentInfo si;
    private int readBufferSize;
    internal LightWeightThreadLocal`1<FieldsReader> fieldsReaderLocal;
    internal LightWeightThreadLocal`1<TermVectorsReader> termVectorsLocal;
    internal BitVector deletedDocs;
    internal Ref deletedDocsRef;
    private bool deletedDocsDirty;
    private bool normsDirty;
    private int pendingDeleteCount;
    private bool rollbackHasChanges;
    private bool rollbackDeletedDocsDirty;
    private bool rollbackNormsDirty;
    private SegmentInfo rollbackSegmentInfo;
    private int rollbackPendingDeleteCount;
    private IndexInput singleNormStream;
    private Ref singleNormRef;
    internal CoreReaders core;
    internal HashMap`2<string, Norm> norms;
    public bool HasDeletions { get; }
    public int MaxDoc { get; }
    public string SegmentName { get; }
    internal SegmentInfo SegmentInfo { get; internal set; }
    public object FieldCacheKey { get; }
    public object DeletesCacheKey { get; }
    public long UniqueTermCount { get; }
    public int TermInfosIndexDivisor { get; }
    public IDictionary`2<string, Norm> norms_ForNUnit { get; }
    public BitVector deletedDocs_ForNUnit { get; }
    public CoreReaders core_ForNUnit { get; }
    public Ref deletedDocsRef_ForNUnit { get; }
    private void InitBlock();
    public static SegmentReader Get(bool readOnly, SegmentInfo si, int termInfosIndexDivisor, IState state);
    public static SegmentReader Get(bool readOnly, Directory dir, SegmentInfo si, int readBufferSize, bool doOpenStores, int termInfosIndexDivisor, IState state);
    internal virtual void OpenDocStores(IState state);
    private bool CheckDeletedCounts(IState state);
    private void LoadDeletedDocs(IState state);
    protected internal virtual Byte[] CloneNormBytes(Byte[] bytes);
    protected internal virtual BitVector CloneDeletedDocs(BitVector bv);
    public virtual string GetStringValueFor(string field, int doc, IState state);
    public virtual long GetLongValueFor(string field, LongParser parser, int doc, IState state);
    public virtual double GetDoubleValueFor(string field, DoubleParser parser, int doc, IState state);
    public virtual object Clone(IState state);
    public virtual IndexReader Clone(bool openReadOnly, IState state);
    internal virtual SegmentReader ReopenSegment(SegmentInfo si, bool doClone, bool openReadOnly, IState state);
    protected internal virtual void DoCommit(IDictionary`2<string, string> commitUserData, IState state);
    private void CommitChanges(IDictionary`2<string, string> commitUserData, IState state);
    internal virtual FieldsReader GetFieldsReader(IState state);
    protected internal virtual void DoClose(IState state);
    public virtual bool get_HasDeletions();
    internal static bool UsesCompoundFile(SegmentInfo si, IState state);
    internal static bool HasSeparateNorms(SegmentInfo si, IState state);
    protected internal virtual void DoDelete(int docNum, IState state);
    protected internal virtual void DoUndeleteAll(IState state);
    internal virtual IList`1<string> Files(IState state);
    public virtual TermEnum Terms(IState state);
    public virtual TermEnum Terms(Term t, IState state);
    public virtual FieldInfos FieldInfos();
    public virtual Document Document(int n, FieldSelector fieldSelector, IState state);
    public virtual bool IsDeleted(int n);
    public virtual TermDocs TermDocs(Term term, IState state);
    public virtual TermDocs TermDocs(IState state);
    public virtual TermPositions TermPositions(IState state);
    public virtual int DocFreq(Term t, IState state);
    public virtual int NumDocs();
    public virtual int get_MaxDoc();
    public virtual ICollection`1<string> GetFieldNames(FieldOption fieldOption);
    public virtual bool HasNorms(string field, IState state);
    protected internal virtual Byte[] GetNorms(string field, IState state);
    public virtual Byte[] Norms(string field, IState state);
    protected internal virtual void DoSetNorm(int doc, string field, byte value_Renamed, IState state);
    public virtual void Norms(string field, Byte[] bytes, int offset, IState state);
    private void OpenNorms(Directory cfsDir, int readBufferSize, IState state);
    public virtual bool TermsIndexLoaded();
    internal virtual void LoadTermsIndex(int termsIndexDivisor, IState state);
    public virtual bool NormsClosed();
    public virtual bool NormsClosed(string field);
    internal virtual TermVectorsReader GetTermVectorsReader(IState state);
    internal virtual TermVectorsReader GetTermVectorsReaderOrig();
    public virtual ITermFreqVector GetTermFreqVector(int docNumber, string field, IState state);
    public virtual void GetTermFreqVector(int docNumber, string field, TermVectorMapper mapper, IState state);
    public virtual void GetTermFreqVector(int docNumber, TermVectorMapper mapper, IState state);
    public virtual ITermFreqVector[] GetTermFreqVectors(int docNumber, IState state);
    public virtual string get_SegmentName();
    internal virtual SegmentInfo get_SegmentInfo();
    internal virtual void set_SegmentInfo(SegmentInfo value);
    internal virtual void StartCommit();
    internal virtual void RollbackCommit();
    public virtual Directory Directory();
    public virtual object get_FieldCacheKey();
    public virtual object get_DeletesCacheKey();
    public virtual long get_UniqueTermCount();
    [ObsoleteAttribute("Remove this when tests are fixed!")]
public static SegmentReader GetOnlySegmentReader(Directory dir, IState state);
    public static SegmentReader GetOnlySegmentReader(IndexReader reader);
    public virtual int get_TermInfosIndexDivisor();
    public IDictionary`2<string, Norm> get_norms_ForNUnit();
    public BitVector get_deletedDocs_ForNUnit();
    public CoreReaders get_core_ForNUnit();
    public Ref get_deletedDocsRef_ForNUnit();
    [CompilerGeneratedAttribute]
private FieldsReader <InitBlock>b__1_0(IState state);
}
internal class Lucene.Net.Index.SegmentTermDocs : object {
    protected internal SegmentReader parent;
    protected internal IndexInput freqStream;
    protected internal int count;
    protected internal int df;
    protected internal BitVector deletedDocs;
    internal int doc;
    internal int freq;
    private int skipInterval;
    private int maxSkipLevels;
    private DefaultSkipListReader skipListReader;
    private long freqBasePointer;
    private long proxBasePointer;
    private long skipPointer;
    private bool haveSkipped;
    protected internal bool currentFieldStoresPayloads;
    protected internal bool currentFieldOmitTermFreqAndPositions;
    private bool isDisposed;
    public int Doc { get; }
    public int Freq { get; }
    public SegmentTermDocs(SegmentReader parent, IState state);
    public virtual void Seek(Term term, IState state);
    public virtual void Seek(TermEnum termEnum, IState state);
    internal virtual void Seek(TermInfo ti, Term term, IState state);
    public sealed virtual void Dispose();
    [ObsoleteAttribute("Use Dispose() instead")]
public sealed virtual void Close();
    protected virtual void Dispose(bool disposing);
    public sealed virtual int get_Doc();
    public sealed virtual int get_Freq();
    protected internal virtual void SkippingDoc();
    public virtual bool Next(IState state);
    public virtual int Read(Int32[] docs, Int32[] freqs, IState state);
    private int ReadNoTf(Int32[] docs, Int32[] freqs, int length, IState state);
    protected internal virtual void SkipProx(long proxPointer, int payloadLength);
    public virtual bool SkipTo(int target, IState state);
}
internal class Lucene.Net.Index.SegmentTermEnum : TermEnum {
    private IndexInput input;
    internal FieldInfos fieldInfos;
    internal long size;
    internal long position;
    internal TermBuffer termBuffer;
    private TermBuffer prevBuffer;
    private TermBuffer scanBuffer;
    private TermInfo termInfo;
    private int format;
    private bool isIndex;
    internal long indexPointer;
    internal int indexInterval;
    internal int skipInterval;
    internal int maxSkipLevels;
    private int formatM1SkipInterval;
    public Term Term { get; }
    internal SegmentTermEnum(IndexInput i, FieldInfos fis, bool isi, IState state);
    public sealed virtual object Clone(IState state);
    internal void Seek(long pointer, long p, Term t, TermInfo ti, IState state);
    public virtual bool Next(IState state);
    internal int ScanTo(Term term, IState state);
    public virtual Term get_Term();
    public Term Prev();
    internal TermInfo TermInfo();
    internal void TermInfo(TermInfo ti);
    public virtual int DocFreq();
    internal long FreqPointer();
    internal long ProxPointer();
    protected virtual void Dispose(bool disposing);
}
internal class Lucene.Net.Index.SegmentTermPositions : SegmentTermDocs {
    private IndexInput proxStream;
    private int proxCount;
    private int position;
    private int payloadLength;
    private bool needToLoadPayload;
    private long lazySkipPointer;
    private int lazySkipProxCount;
    public int PayloadLength { get; }
    public bool IsPayloadAvailable { get; }
    internal SegmentTermPositions(SegmentReader p, IState state);
    internal virtual void Seek(TermInfo ti, Term term, IState state);
    protected virtual void Dispose(bool disposing);
    public sealed virtual int NextPosition(IState state);
    private int ReadDeltaPosition(IState state);
    protected internal virtual void SkippingDoc();
    public virtual bool Next(IState state);
    public virtual int Read(Int32[] docs, Int32[] freqs, IState state);
    protected internal virtual void SkipProx(long proxPointer, int payloadLength);
    private void SkipPositions(int n, IState state);
    private void SkipPayload(IState state);
    private void LazySkip(IState state);
    public sealed virtual int get_PayloadLength();
    public sealed virtual Byte[] GetPayload(Byte[] data, int offset, IState state);
    public sealed virtual bool get_IsPayloadAvailable();
}
internal class Lucene.Net.Index.SegmentTermPositionVector : SegmentTermVector {
    protected internal Int32[][] positions;
    protected internal TermVectorOffsetInfo[][] offsets;
    public static Int32[] EMPTY_TERM_POS;
    public SegmentTermPositionVector(string field, String[] terms, Int32[] termFreqs, Int32[][] positions, TermVectorOffsetInfo[][] offsets);
    private static SegmentTermPositionVector();
    public virtual TermVectorOffsetInfo[] GetOffsets(int index);
    public virtual Int32[] GetTermPositions(int index);
}
internal class Lucene.Net.Index.SegmentTermVector : object {
    private string field;
    private String[] terms;
    private Int32[] termFreqs;
    public string Field { get; }
    public int Size { get; }
    internal SegmentTermVector(string field, String[] terms, Int32[] termFreqs);
    public virtual string get_Field();
    public virtual string ToString();
    public virtual int get_Size();
    public virtual String[] GetTerms();
    public virtual Int32[] GetTermFrequencies();
    public virtual int IndexOf(string termText);
    public virtual Int32[] IndexesOf(String[] termNumbers, int start, int len);
}
internal class Lucene.Net.Index.SegmentWriteState : object {
    internal DocumentsWriter docWriter;
    internal Directory directory;
    internal string segmentName;
    internal string docStoreSegmentName;
    internal int numDocs;
    internal int termIndexInterval;
    internal int numDocsInStore;
    internal ICollection`1<string> flushedFiles;
    public SegmentWriteState(DocumentsWriter docWriter, Directory directory, string segmentName, string docStoreSegmentName, int numDocs, int numDocsInStore, int termIndexInterval);
    public virtual string SegmentFileName(string ext);
}
public class Lucene.Net.Index.SerialMergeScheduler : MergeScheduler {
    public virtual void Merge(IndexWriter writer, IState state);
    protected virtual void Dispose(bool disposing);
}
public class Lucene.Net.Index.SnapshotDeletionPolicy : object {
    private IndexCommit lastCommit;
    private IndexDeletionPolicy primary;
    private string snapshot;
    public SnapshotDeletionPolicy(IndexDeletionPolicy primary);
    public virtual void OnInit(IList`1<T> commits);
    public virtual void OnCommit(IList`1<T> commits);
    public virtual IndexCommit Snapshot();
    public virtual void Release();
    private IList`1<IndexCommit> WrapCommits(IList`1<T> commits);
}
internal class Lucene.Net.Index.SortedBufferedDeletes : object {
    internal int numTerms;
    internal FastList`1<DeleteTerm> terms;
    internal HashMap`2<Query, int> queries;
    internal List`1<int> docIDs;
    internal long bytesUsed;
    internal static bool doTermSort;
    private static Sorter`2<DeleteTerm, DeleteComparer> sorter;
    internal virtual int Size();
    internal void Update(SortedBufferedDeletes in);
    internal void Update(UnsortedBufferedDeletes in);
    internal void Clear();
    internal void AddBytesUsed(long b);
    internal bool Any();
    internal void Remap(MergeDocIDRemapper mapper, SegmentInfos infos, Int32[][] docMaps, Int32[] delCounts, OneMerge merge, int mergeDocCount);
}
public class Lucene.Net.Index.SortedTermVectorMapper : TermVectorMapper {
    private SortedSet`1<TermVectorEntry> currentSet;
    private HashMap`2<string, TermVectorEntry> termToTVE;
    private bool storeOffsets;
    private bool storePositions;
    public static string ALL;
    public SortedSet`1<TermVectorEntry> TermVectorEntrySet { get; }
    public SortedTermVectorMapper(IComparer`1<TermVectorEntry> comparator);
    public SortedTermVectorMapper(bool ignoringPositions, bool ignoringOffsets, IComparer`1<TermVectorEntry> comparator);
    public virtual void Map(string term, int frequency, TermVectorOffsetInfo[] offsets, Int32[] positions);
    public virtual void SetExpectations(string field, int numTerms, bool storeOffsets, bool storePositions);
    public virtual SortedSet`1<TermVectorEntry> get_TermVectorEntrySet();
}
public class Lucene.Net.Index.StaleReaderException : IOException {
    public StaleReaderException(string message);
    public StaleReaderException(string message, Exception innerException);
    public StaleReaderException(SerializationInfo info, StreamingContext context);
}
internal class Lucene.Net.Index.StoredFieldsWriter : object {
    internal FieldsWriter fieldsWriter;
    internal DocumentsWriter docWriter;
    internal FieldInfos fieldInfos;
    internal int lastDocID;
    internal PerDoc[] docFreeList;
    internal int freeCount;
    internal int allocCount;
    public StoredFieldsWriter(DocumentsWriter docWriter, FieldInfos fieldInfos);
    private void InitBlock();
    public StoredFieldsWriterPerThread AddThread(DocState docState);
    public void Flush(SegmentWriteState state, IState s);
    private void InitFieldsWriter(IState state);
    public void CloseDocStore(SegmentWriteState state, IState s);
    internal PerDoc GetPerDoc();
    internal void Abort();
    internal void Fill(int docID);
    internal void FinishDocument(PerDoc perDoc, IState state);
    public bool FreeRAM();
    internal void Free(PerDoc perDoc);
}
internal class Lucene.Net.Index.StoredFieldsWriterPerThread : object {
    internal FieldsWriter localFieldsWriter;
    internal StoredFieldsWriter storedFieldsWriter;
    internal DocState docState;
    internal PerDoc doc;
    public StoredFieldsWriterPerThread(DocState docState, StoredFieldsWriter storedFieldsWriter);
    public void StartDocument();
    public void AddField(IFieldable field, FieldInfo fieldInfo, IState state);
    public DocWriter FinishDocument();
    public void Abort();
}
public class Lucene.Net.Index.Term : object {
    internal string field;
    internal string text;
    public string Field { get; }
    public string Text { get; }
    public Term(string fld, string txt);
    public Term(string fld);
    internal Term(string fld, string txt, bool intern);
    public string get_Field();
    public string get_Text();
    public Term CreateTerm(string text);
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
    public sealed virtual int CompareTo(Term other);
    public virtual string ToString();
    [OnDeserializedAttribute]
internal void OnDeserialized(StreamingContext context);
}
public class Lucene.Net.Index.TermBuffer : object {
    private string field;
    private Term term;
    private bool preUTF8Strings;
    private bool dirty;
    private UTF16Result text;
    private UTF8Result bytes;
    public Span`1<char> TextAsSpan { get; }
    public string Field { get; }
    public Span`1<char> get_TextAsSpan();
    public string get_Field();
    public int CompareTo(TermBuffer other);
    private static int CompareChars(Char[] chars1, int len1, Char[] chars2, int len2);
    internal void SetPreUTF8Strings();
    public void Read(IndexInput input, FieldInfos fieldInfos, IState state);
    public void Set(Term term);
    public void Set(TermBuffer other);
    public void Reset();
    public Term ToTerm();
    public sealed virtual object Clone();
}
public interface Lucene.Net.Index.TermDocs {
    public int Doc { get; }
    public int Freq { get; }
    public abstract virtual void Seek(Term term, IState state);
    public abstract virtual void Seek(TermEnum termEnum, IState state);
    public abstract virtual int get_Doc();
    public abstract virtual int get_Freq();
    public abstract virtual bool Next(IState state);
    public abstract virtual int Read(Int32[] docs, Int32[] freqs, IState state);
    public abstract virtual bool SkipTo(int target, IState state);
    [ObsoleteAttribute("Use Dispose() instead")]
public abstract virtual void Close();
}
public abstract class Lucene.Net.Index.TermEnum : object {
    public Term Term { get; }
    public abstract virtual bool Next(IState state);
    public abstract virtual Term get_Term();
    public abstract virtual int DocFreq();
    [ObsoleteAttribute("Use Dispose() instead")]
public void Close();
    public sealed virtual void Dispose();
    protected abstract virtual void Dispose(bool disposing);
}
public class Lucene.Net.Index.TermInfo : ValueType {
    internal int docFreq;
    internal long freqPointer;
    internal long proxPointer;
    internal int skipOffset;
    public bool IsEmpty { get; }
    internal TermInfo(int df, long fp, long pp);
    internal TermInfo(TermInfo ti);
    public bool get_IsEmpty();
    internal void Set(int docFreq, long freqPointer, long proxPointer, int skipOffset);
    internal void Set(TermInfo ti);
}
internal class Lucene.Net.Index.TermInfosReader : object {
    private Directory directory;
    private string segment;
    private FieldInfos fieldInfos;
    private bool isDisposed;
    private LightWeightThreadLocal`1<ThreadResources> threadResources;
    private SegmentTermEnum origEnum;
    private long size;
    private int totalIndexInterval;
    private static int DEFAULT_CACHE_SIZE;
    private ArrayHolder _termsIndexCache;
    private DoubleBarrelLRUCache`2<CloneableTerm, TermInfo> termInfoCache;
    private Span`1<Term> indexTerms { get; }
    private Span`1<TermInfo> indexInfos { get; }
    private Span`1<long> indexPointers { get; }
    public int SkipInterval { get; }
    public int MaxSkipLevels { get; }
    internal TermInfosReader(Directory dir, string seg, FieldInfos fis, int readBufferSize, int indexDivisor, IState state);
    private Span`1<Term> get_indexTerms();
    private Span`1<TermInfo> get_indexInfos();
    private Span`1<long> get_indexPointers();
    public int get_SkipInterval();
    public int get_MaxSkipLevels();
    public sealed virtual void Dispose();
    protected virtual override void Finalize();
    internal long Size();
    private ThreadResources GetThreadResources(IState state);
    private int GetIndexOffset(Term term);
    internal static Term DeepCopyOf(Term other);
    private void SeekEnum(SegmentTermEnum enumerator, int indexOffset, IState state);
    internal TermInfo Get(Term term, IState state);
    private TermInfo Get(Term term, bool useCache, IState state);
    private void EnsureIndexIsRead();
    internal long GetPosition(Term term, IState state);
    public SegmentTermEnum Terms(IState state);
    public SegmentTermEnum Terms(Term term, IState state);
}
internal class Lucene.Net.Index.TermInfosWriter : object {
    public static int FORMAT;
    public static int FORMAT_VERSION_UTF8_LENGTH_IN_BYTES;
    public static int FORMAT_CURRENT;
    private bool isDisposed;
    private FieldInfos fieldInfos;
    private IndexOutput output;
    private TermInfo lastTi;
    private long size;
    internal int indexInterval;
    internal int skipInterval;
    internal int maxSkipLevels;
    private long lastIndexPointer;
    private bool isIndex;
    private Byte[] lastTermBytes;
    private int lastTermBytesLength;
    private int lastFieldNumber;
    private TermInfosWriter other;
    private UTF8Result utf8Result;
    internal UTF16Result utf16Result1;
    internal UTF16Result utf16Result2;
    internal TermInfosWriter(Directory directory, string segment, FieldInfos fis, int interval, IState state);
    private TermInfosWriter(Directory directory, string segment, FieldInfos fis, int interval, bool isIndex, IState state);
    private static TermInfosWriter();
    private void Initialize(Directory directory, string segment, FieldInfos fis, int interval, bool isi, IState state);
    internal void Add(Term term, TermInfo ti);
    private bool InitUTF16Results();
    private int CompareToLastTerm(int fieldNumber, Byte[] termBytes, int termBytesLength);
    internal void Add(int fieldNumber, Byte[] termBytes, int termBytesLength, TermInfo ti);
    private void WriteTerm(int fieldNumber, Byte[] termBytes, int termBytesLength);
    public sealed virtual void Dispose();
}
public interface Lucene.Net.Index.TermPositions {
    public int PayloadLength { get; }
    public bool IsPayloadAvailable { get; }
    public abstract virtual int NextPosition(IState state);
    public abstract virtual int get_PayloadLength();
    public abstract virtual Byte[] GetPayload(Byte[] data, int offset, IState state);
    public abstract virtual bool get_IsPayloadAvailable();
}
public interface Lucene.Net.Index.TermPositionVector {
    public abstract virtual Int32[] GetTermPositions(int index);
    public abstract virtual TermVectorOffsetInfo[] GetOffsets(int index);
}
internal class Lucene.Net.Index.TermsHash : InvertedDocConsumer {
    internal TermsHashConsumer consumer;
    internal TermsHash nextTermsHash;
    internal int bytesPerPosting;
    internal int postingsFreeChunk;
    internal DocumentsWriter docWriter;
    private RawPostingList[] postingsFreeList;
    private int postingsFreeCount;
    private int postingsAllocCount;
    internal bool trackAllocations;
    public TermsHash(DocumentsWriter docWriter, bool trackAllocations, TermsHashConsumer consumer, TermsHash nextTermsHash);
    internal virtual InvertedDocConsumerPerThread AddThread(DocInverterPerThread docInverterPerThread);
    internal TermsHashPerThread AddThread(DocInverterPerThread docInverterPerThread, TermsHashPerThread primaryPerThread);
    internal virtual void SetFieldInfos(FieldInfos fieldInfos);
    public virtual void Abort();
    internal void ShrinkFreePostings(IDictionary`2<InvertedDocConsumerPerThread, ICollection`1<InvertedDocConsumerPerField>> threadsAndFields, SegmentWriteState state);
    internal virtual void CloseDocStore(SegmentWriteState state, IState s);
    internal virtual void Flush(IDictionary`2<InvertedDocConsumerPerThread, ICollection`1<InvertedDocConsumerPerField>> threadsAndFields, SegmentWriteState state, IState s);
    public virtual bool FreeRAM();
    public void RecyclePostings(RawPostingList[] postings, int numPostings);
    public void GetPostings(RawPostingList[] postings);
}
internal abstract class Lucene.Net.Index.TermsHashConsumer : object {
    internal FieldInfos fieldInfos;
    internal abstract virtual int BytesPerPosting();
    internal abstract virtual void CreatePostings(RawPostingList[] postings, int start, int count);
    public abstract virtual TermsHashConsumerPerThread AddThread(TermsHashPerThread perThread);
    public abstract virtual void Flush(IDictionary`2<TermsHashConsumerPerThread, ICollection`1<TermsHashConsumerPerField>> threadsAndFields, SegmentWriteState state, IState s);
    public abstract virtual void Abort();
    internal abstract virtual void CloseDocStore(SegmentWriteState state, IState s);
    internal virtual void SetFieldInfos(FieldInfos fieldInfos);
}
internal abstract class Lucene.Net.Index.TermsHashConsumerPerField : object {
    internal abstract virtual bool Start(IFieldable[] fields, int count);
    internal abstract virtual void Finish();
    internal abstract virtual void SkippingLongTerm();
    internal abstract virtual void Start(IFieldable field);
    internal abstract virtual void NewTerm(RawPostingList p);
    internal abstract virtual void AddTerm(RawPostingList p);
    internal abstract virtual int GetStreamCount();
}
internal abstract class Lucene.Net.Index.TermsHashConsumerPerThread : object {
    public abstract virtual void StartDocument();
    public abstract virtual DocWriter FinishDocument();
    public abstract virtual TermsHashConsumerPerField AddField(TermsHashPerField termsHashPerField, FieldInfo fieldInfo);
    public abstract virtual void Abort();
}
internal class Lucene.Net.Index.TermsHashPerField : InvertedDocConsumerPerField {
    internal TermsHashConsumerPerField consumer;
    internal TermsHashPerField nextPerField;
    internal TermsHashPerThread perThread;
    internal DocState docState;
    internal FieldInvertState fieldState;
    internal ITermAttribute termAtt;
    internal CharBlockPool charPool;
    internal IntBlockPool intPool;
    internal ByteBlockPool bytePool;
    internal int streamCount;
    internal int numPostingInt;
    internal FieldInfo fieldInfo;
    internal bool postingsCompacted;
    internal int numPostings;
    private int postingsHashSize;
    private int postingsHashHalfSize;
    private int postingsHashMask;
    private RawPostingList[] postingsHash;
    private RawPostingList p;
    private Sorter`2<RawPostingList, PostingComparer> _sorter;
    private bool doCall;
    private bool doNextCall;
    internal Int32[] intUptos;
    internal int intUptoStart;
    public TermsHashPerField(DocInverterPerField docInverterPerField, TermsHashPerThread perThread, TermsHashPerThread nextPerThread, FieldInfo fieldInfo);
    private void InitBlock();
    internal void ShrinkHash(int targetSize);
    public void Reset();
    public virtual void Abort();
    public void InitReader(ByteSliceReader reader, RawPostingList p, int stream);
    private void CompactPostings();
    public RawPostingList[] SortPostings();
    private bool PostingEquals(RawPostingList& currentP, Char[] tokenText, int tokenTextLen);
    internal virtual void Start(IFieldable f);
    internal virtual bool Start(IFieldable[] fields, int count);
    public void Add(int textStart);
    internal virtual void Add();
    internal void WriteByte(int stream, byte b);
    internal void WriteByteUnlikely(Byte[] bytes, int offset, int stream, byte b);
    public void WriteBytes(int stream, Byte[] b, int offset, int len);
    internal void WriteVInt(int stream, int i);
    internal virtual void Finish();
    internal void RehashPostings(int newSize);
}
internal class Lucene.Net.Index.TermsHashPerThread : InvertedDocConsumerPerThread {
    internal TermsHash termsHash;
    internal TermsHashConsumerPerThread consumer;
    internal TermsHashPerThread nextPerThread;
    internal CharBlockPool charPool;
    internal IntBlockPool intPool;
    internal ByteBlockPool bytePool;
    internal bool primary;
    internal DocState docState;
    internal RawPostingList[] freePostings;
    internal int freePostingsCount;
    public TermsHashPerThread(DocInverterPerThread docInverterPerThread, TermsHash termsHash, TermsHash nextTermsHash, TermsHashPerThread primaryPerThread);
    internal virtual InvertedDocConsumerPerField AddField(DocInverterPerField docInverterPerField, FieldInfo fieldInfo);
    public virtual void Abort();
    internal void MorePostings();
    private static bool noNullPostings(RawPostingList[] postings, int count, string details);
    public virtual void StartDocument();
    public virtual DocWriter FinishDocument();
    internal void Reset(bool recyclePostings);
}
public class Lucene.Net.Index.TermVectorEntry : object {
    private string field;
    private string term;
    private int frequency;
    private TermVectorOffsetInfo[] offsets;
    private Int32[] positions;
    public string Field { get; }
    public int Frequency { get; internal set; }
    public string Term { get; }
    public TermVectorEntry(string field, string term, int frequency, TermVectorOffsetInfo[] offsets, Int32[] positions);
    public virtual string get_Field();
    public virtual int get_Frequency();
    internal virtual void set_Frequency(int value);
    internal virtual void SetOffsets(TermVectorOffsetInfo[] value);
    public virtual TermVectorOffsetInfo[] GetOffsets();
    internal virtual void SetPositions(Int32[] value);
    public virtual Int32[] GetPositions();
    public virtual string get_Term();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    public virtual string ToString();
}
public class Lucene.Net.Index.TermVectorEntryFreqSortedComparator : object {
    public virtual int Compare(TermVectorEntry entry, TermVectorEntry entry1);
}
public abstract class Lucene.Net.Index.TermVectorMapper : object {
    private bool ignoringPositions;
    private bool ignoringOffsets;
    public bool IsIgnoringPositions { get; }
    public bool IsIgnoringOffsets { get; }
    protected internal TermVectorMapper(bool ignoringPositions, bool ignoringOffsets);
    public abstract virtual void SetExpectations(string field, int numTerms, bool storeOffsets, bool storePositions);
    public abstract virtual void Map(string term, int frequency, TermVectorOffsetInfo[] offsets, Int32[] positions);
    public virtual bool get_IsIgnoringPositions();
    public virtual bool get_IsIgnoringOffsets();
    public virtual void SetDocumentNumber(int documentNumber);
}
public class Lucene.Net.Index.TermVectorOffsetInfo : ValueType {
    public static TermVectorOffsetInfo[] EMPTY_OFFSET_INFO;
    public static TermVectorOffsetInfo Null;
    private int startOffset;
    private int endOffset;
    public int EndOffset { get; public set; }
    public int StartOffset { get; public set; }
    public TermVectorOffsetInfo(int startOffset, int endOffset);
    private static TermVectorOffsetInfo();
    public int get_EndOffset();
    public void set_EndOffset(int value);
    public int get_StartOffset();
    public void set_StartOffset(int value);
    public sealed virtual bool Equals(TermVectorOffsetInfo other);
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
    public static bool op_Equality(TermVectorOffsetInfo left, object right);
    public static bool op_Inequality(TermVectorOffsetInfo left, object right);
}
internal class Lucene.Net.Index.TermVectorsReader : object {
    internal static int FORMAT_VERSION;
    internal static int FORMAT_VERSION2;
    internal static int FORMAT_UTF8_LENGTH_IN_BYTES;
    internal static int FORMAT_CURRENT;
    internal static int FORMAT_SIZE;
    internal static byte STORE_POSITIONS_WITH_TERMVECTOR;
    internal static byte STORE_OFFSET_WITH_TERMVECTOR;
    private FieldInfos fieldInfos;
    private IndexInput tvx;
    private IndexInput tvd;
    private IndexInput tvf;
    private int size;
    private int numTotalDocs;
    private int docStoreOffset;
    private int format;
    private bool isDisposed;
    internal TermVectorsReader(Directory d, string segment, FieldInfos fieldInfos, IState state);
    internal TermVectorsReader(Directory d, string segment, FieldInfos fieldInfos, int readBufferSize, IState state);
    internal TermVectorsReader(Directory d, string segment, FieldInfos fieldInfos, int readBufferSize, int docStoreOffset, int size, IState state);
    private static TermVectorsReader();
    internal virtual IndexInput GetTvdStream();
    internal virtual IndexInput GetTvfStream();
    private void SeekTvx(int docNum, IState state);
    internal virtual bool CanReadRawDocs();
    internal void RawDocs(Int32[] tvdLengths, Int32[] tvfLengths, int startDocID, int numDocs, IState state);
    private int CheckValidFormat(IndexInput in_Renamed, IState state);
    public sealed virtual void Dispose();
    protected virtual void Dispose(bool disposing);
    internal virtual int Size();
    public virtual void Get(int docNum, string field, TermVectorMapper mapper, IState state);
    public virtual ITermFreqVector Get(int docNum, string field, IState state);
    private String[] ReadFields(int fieldCount, IState state);
    private Int64[] ReadTvfPointers(int fieldCount, IState state);
    public virtual ITermFreqVector[] Get(int docNum, IState state);
    public virtual void Get(int docNumber, TermVectorMapper mapper, IState state);
    private SegmentTermVector[] ReadTermVectors(int docNum, String[] fields, Int64[] tvfPointers, IState state);
    private void ReadTermVectors(String[] fields, Int64[] tvfPointers, TermVectorMapper mapper, IState state);
    private void ReadTermVector(string field, long tvfPointer, TermVectorMapper mapper, IState state);
    public virtual object Clone(IState state);
}
internal class Lucene.Net.Index.TermVectorsTermsWriter : TermsHashConsumer {
    internal DocumentsWriter docWriter;
    internal TermVectorsWriter termVectorsWriter;
    internal PerDoc[] docFreeList;
    internal int freeCount;
    internal IndexOutput tvx;
    internal IndexOutput tvd;
    internal IndexOutput tvf;
    internal int lastDocID;
    internal int allocCount;
    public TermVectorsTermsWriter(DocumentsWriter docWriter);
    private void InitBlock();
    public virtual TermsHashConsumerPerThread AddThread(TermsHashPerThread termsHashPerThread);
    internal virtual void CreatePostings(RawPostingList[] postings, int start, int count);
    public virtual void Flush(IDictionary`2<TermsHashConsumerPerThread, ICollection`1<TermsHashConsumerPerField>> threadsAndFields, SegmentWriteState state, IState s);
    internal virtual void CloseDocStore(SegmentWriteState state, IState s);
    internal PerDoc GetPerDoc();
    internal void Fill(int docID);
    internal void InitTermVectorsWriter(IState state);
    internal void FinishDocument(PerDoc perDoc, IState state);
    public bool FreeRAM();
    public virtual void Abort();
    internal void Free(PerDoc doc);
    internal virtual int BytesPerPosting();
}
internal class Lucene.Net.Index.TermVectorsTermsWriterPerField : TermsHashConsumerPerField {
    internal TermVectorsTermsWriterPerThread perThread;
    internal TermsHashPerField termsHashPerField;
    internal TermVectorsTermsWriter termsWriter;
    internal FieldInfo fieldInfo;
    internal DocState docState;
    internal FieldInvertState fieldState;
    internal bool doVectors;
    internal bool doVectorPositions;
    internal bool doVectorOffsets;
    internal int maxNumPostings;
    internal IOffsetAttribute offsetAttribute;
    public TermVectorsTermsWriterPerField(TermsHashPerField termsHashPerField, TermVectorsTermsWriterPerThread perThread, FieldInfo fieldInfo);
    internal virtual int GetStreamCount();
    internal virtual bool Start(IFieldable[] fields, int count);
    public void Abort();
    internal virtual void Finish();
    internal void ShrinkHash();
    internal virtual void Start(IFieldable f);
    internal virtual void NewTerm(RawPostingList p0);
    internal virtual void AddTerm(RawPostingList p0);
    internal virtual void SkippingLongTerm();
}
internal class Lucene.Net.Index.TermVectorsTermsWriterPerThread : TermsHashConsumerPerThread {
    internal TermVectorsTermsWriter termsWriter;
    internal TermsHashPerThread termsHashPerThread;
    internal DocState docState;
    internal PerDoc doc;
    internal ByteSliceReader vectorSliceReader;
    internal UTF8Result[] utf8Results;
    internal string lastVectorFieldName;
    public TermVectorsTermsWriterPerThread(TermsHashPerThread termsHashPerThread, TermVectorsTermsWriter termsWriter);
    public virtual void StartDocument();
    public virtual DocWriter FinishDocument();
    public virtual TermsHashConsumerPerField AddField(TermsHashPerField termsHashPerField, FieldInfo fieldInfo);
    public virtual void Abort();
    internal bool ClearLastVectorFieldName();
    internal bool VectorFieldsInOrder(FieldInfo fi);
}
internal class Lucene.Net.Index.TermVectorsWriter : object {
    private IndexOutput tvx;
    private IndexOutput tvd;
    private IndexOutput tvf;
    private FieldInfos fieldInfos;
    internal UTF8Result[] utf8Results;
    public TermVectorsWriter(Directory directory, string segment, FieldInfos fieldInfos, IState state);
    public void AddAllDocVectors(ITermFreqVector[] vectors);
    internal void AddRawDocuments(TermVectorsReader reader, Int32[] tvdLengths, Int32[] tvfLengths, int numDocs, IState state);
    public sealed virtual void Dispose();
}
internal class Lucene.Net.Index.UnsortedBufferedDeletes : object {
    internal int numTerms;
    internal HashMap`2<Term, DeleteTermNum> terms;
    internal HashMap`2<Query, int> queries;
    internal List`1<int> docIDs;
    internal long bytesUsed;
    internal static bool doTermSort;
    internal int Size();
    internal void Update(UnsortedBufferedDeletes in);
    internal void Clear();
    internal void AddBytesUsed(long b);
    internal bool Any();
    internal virtual void Remap(MergeDocIDRemapper mapper, SegmentInfos infos, Int32[][] docMaps, Int32[] delCounts, OneMerge merge, int mergeDocCount);
}
public class Lucene.Net.LucenePackage : object {
}
public interface Lucene.Net.Messages.INLSException {
    public Message MessageObject { get; }
    public abstract virtual Message get_MessageObject();
}
public interface Lucene.Net.Messages.Message {
    public string Key { get; }
    public abstract virtual string get_Key();
    public abstract virtual Object[] GetArguments();
    public abstract virtual string GetLocalizedMessage();
    public abstract virtual string GetLocalizedMessage(CultureInfo locale);
}
public class Lucene.Net.Messages.MessageImpl : object {
    private static long serialVersionUID;
    private string key;
    private Object[] arguments;
    public string Key { get; }
    public MessageImpl(string key);
    public MessageImpl(string key, Object[] args);
    public virtual Object[] GetArguments();
    public virtual string get_Key();
    public virtual string GetLocalizedMessage();
    public virtual string GetLocalizedMessage(CultureInfo locale);
    public virtual string ToString();
}
public class Lucene.Net.Messages.NLS : object {
    private static HashMap`2<string, Type> bundles;
    protected static string ResourceDirectory;
    private static NLS();
    public static string GetLocalizedMessage(string key);
    public static string GetLocalizedMessage(string key, CultureInfo locale);
    public static string GetLocalizedMessage(string key, CultureInfo locale, Object[] args);
    public static string GetLocalizedMessage(string key, Object[] args);
    protected internal static void InitializeMessages(string bundleName);
    private static object GetResourceBundleObject(string messageKey, CultureInfo locale);
    private static void Load();
    private static void LoadfieldValue(FieldInfo field, bool isFieldAccessible);
    private static void ValidateMessage(string key);
    private static void MakeAccessible(FieldInfo field);
}
public class Lucene.Net.QueryParsers.FastCharStream : object {
    internal Char[] buffer;
    internal int bufferLength;
    internal int bufferPosition;
    internal int tokenStart;
    internal int bufferStart;
    internal TextReader input;
    public string Image { get; }
    public int Column { get; }
    public int Line { get; }
    public int EndColumn { get; }
    public int EndLine { get; }
    public int BeginColumn { get; }
    public int BeginLine { get; }
    public FastCharStream(TextReader r);
    public sealed virtual char ReadChar();
    private void Refill();
    public sealed virtual char BeginToken();
    public sealed virtual void Backup(int amount);
    public sealed virtual string get_Image();
    public sealed virtual Char[] GetSuffix(int len);
    public sealed virtual void Done();
    public sealed virtual int get_Column();
    public sealed virtual int get_Line();
    public sealed virtual int get_EndColumn();
    public sealed virtual int get_EndLine();
    public sealed virtual int get_BeginColumn();
    public sealed virtual int get_BeginLine();
}
public interface Lucene.Net.QueryParsers.ICharStream {
    [ObsoleteAttribute]
public int Column { get; }
    [ObsoleteAttribute]
public int Line { get; }
    public int EndColumn { get; }
    public int EndLine { get; }
    public int BeginColumn { get; }
    public int BeginLine { get; }
    public string Image { get; }
    public abstract virtual char ReadChar();
    public abstract virtual int get_Column();
    public abstract virtual int get_Line();
    public abstract virtual int get_EndColumn();
    public abstract virtual int get_EndLine();
    public abstract virtual int get_BeginColumn();
    public abstract virtual int get_BeginLine();
    public abstract virtual void Backup(int amount);
    public abstract virtual char BeginToken();
    public abstract virtual string get_Image();
    public abstract virtual Char[] GetSuffix(int len);
    public abstract virtual void Done();
}
public class Lucene.Net.QueryParsers.MultiFieldQueryParser : QueryParser {
    protected internal String[] fields;
    protected internal IDictionary`2<string, float> boosts;
    public MultiFieldQueryParser(Version matchVersion, String[] fields, Analyzer analyzer, IDictionary`2<string, float> boosts);
    public MultiFieldQueryParser(Version matchVersion, String[] fields, Analyzer analyzer);
    protected internal virtual Query GetFieldQuery(string field, string queryText, int slop);
    private void ApplySlop(Query q, int slop);
    protected internal virtual Query GetFieldQuery(string field, string queryText);
    protected internal virtual Query GetFuzzyQuery(string field, string termStr, float minSimilarity);
    protected internal virtual Query GetPrefixQuery(string field, string termStr);
    protected internal virtual Query GetWildcardQuery(string field, string termStr);
    protected internal virtual Query GetRangeQuery(string field, string part1, string part2, bool inclusive);
    public static Query Parse(Version matchVersion, String[] queries, String[] fields, Analyzer analyzer);
    public static Query Parse(Version matchVersion, string query, String[] fields, Occur[] flags, Analyzer analyzer);
    public static Query Parse(Version matchVersion, String[] queries, String[] fields, Occur[] flags, Analyzer analyzer);
}
public class Lucene.Net.QueryParsers.ParseException : Exception {
    protected internal bool specialConstructor;
    public Token currentToken;
    public Int32[][] expectedTokenSequences;
    public String[] tokenImage;
    protected internal string eol;
    public string Message { get; }
    public ParseException(Token currentTokenVal, Int32[][] expectedTokenSequencesVal, String[] tokenImageVal);
    public ParseException(string message);
    public ParseException(string message, Exception ex);
    public virtual string get_Message();
    protected internal virtual string Add_escapes(string str);
}
public class Lucene.Net.QueryParsers.QueryParser : QueryParserConstants {
    private static int CONJ_NONE;
    private static int CONJ_AND;
    private static int CONJ_OR;
    private static int MOD_NONE;
    private static int MOD_NOT;
    private static int MOD_REQ;
    public static Operator AND_OPERATOR;
    public static Operator OR_OPERATOR;
    private Operator operator_Renamed;
    private bool lowercaseExpandedTerms;
    private RewriteMethod multiTermRewriteMethod;
    private bool allowLeadingWildcard;
    private bool enablePositionIncrements;
    private bool _useJavaStyleDateRangeParsing;
    private Analyzer analyzer;
    private string field;
    private int phraseSlop;
    private float fuzzyMinSim;
    private int fuzzyPrefixLength;
    private CultureInfo locale;
    private Resolution dateResolution;
    private IDictionary`2<string, Resolution> fieldToDateResolution;
    private CompareInfo rangeCollator;
    public QueryParserTokenManager token_source;
    public Token token;
    public Token jj_nt;
    private int jj_ntk;
    private Token jj_scanpos;
    private Token jj_lastpos;
    private int jj_la;
    private int jj_gen;
    private Int32[] jj_la1;
    private static Int32[] jj_la1_0;
    private static Int32[] jj_la1_1;
    private JJCalls[] jj_2_rtns;
    private bool jj_rescan;
    private int jj_gc;
    private LookaheadSuccess jj_ls;
    private List`1<Int32[]> jj_expentries;
    private Int32[] jj_expentry;
    private int jj_kind;
    private Int32[] jj_lasttokens;
    private int jj_endpos;
    public Analyzer Analyzer { get; }
    public string Field { get; }
    public float FuzzyMinSim { get; public set; }
    public int FuzzyPrefixLength { get; public set; }
    public int PhraseSlop { get; public set; }
    public bool AllowLeadingWildcard { get; public set; }
    public bool EnablePositionIncrements { get; public set; }
    public Operator DefaultOperator { get; public set; }
    public bool LowercaseExpandedTerms { get; public set; }
    public RewriteMethod MultiTermRewriteMethod { get; public set; }
    public CultureInfo Locale { get; public set; }
    public CompareInfo RangeCollator { get; public set; }
    public QueryParser(Version matchVersion, string f, Analyzer a);
    protected internal QueryParser(ICharStream stream);
    protected QueryParser(QueryParserTokenManager tm);
    private static QueryParser();
    public virtual Query Parse(string query);
    public virtual Analyzer get_Analyzer();
    public virtual string get_Field();
    public virtual float get_FuzzyMinSim();
    public virtual void set_FuzzyMinSim(float value);
    public virtual int get_FuzzyPrefixLength();
    public virtual void set_FuzzyPrefixLength(int value);
    public virtual void set_PhraseSlop(int value);
    public virtual int get_PhraseSlop();
    public virtual void set_AllowLeadingWildcard(bool value);
    public virtual bool get_AllowLeadingWildcard();
    public virtual void set_EnablePositionIncrements(bool value);
    public virtual bool get_EnablePositionIncrements();
    public virtual void set_DefaultOperator(Operator value);
    public virtual Operator get_DefaultOperator();
    public virtual void set_LowercaseExpandedTerms(bool value);
    public virtual bool get_LowercaseExpandedTerms();
    public virtual void set_MultiTermRewriteMethod(RewriteMethod value);
    public virtual RewriteMethod get_MultiTermRewriteMethod();
    public virtual void set_Locale(CultureInfo value);
    public virtual CultureInfo get_Locale();
    public virtual void SetDateResolution(Resolution dateResolution);
    public virtual void SetDateResolution(string fieldName, Resolution dateResolution);
    public virtual Resolution getDateResolution(string fieldName);
    public virtual void set_RangeCollator(CompareInfo value);
    public virtual CompareInfo get_RangeCollator();
    protected internal virtual void AddClause(List`1<BooleanClause> clauses, int conj, int mods, Query q);
    protected internal virtual Query GetFieldQuery(string field, string queryText);
    protected internal virtual Query GetFieldQuery(string field, string queryText, int slop);
    protected internal virtual Query GetRangeQuery(string field, string part1, string part2, bool inclusive);
    protected internal virtual BooleanQuery NewBooleanQuery(bool disableCoord);
    protected internal virtual BooleanClause NewBooleanClause(Query q, Occur occur);
    protected internal virtual Query NewTermQuery(Term term);
    protected internal virtual PhraseQuery NewPhraseQuery();
    protected internal virtual MultiPhraseQuery NewMultiPhraseQuery();
    protected internal virtual Query NewPrefixQuery(Term prefix);
    protected internal virtual Query NewFuzzyQuery(Term term, float minimumSimilarity, int prefixLength);
    protected internal virtual Query NewRangeQuery(string field, string part1, string part2, bool inclusive);
    protected internal virtual Query NewMatchAllDocsQuery();
    protected internal virtual Query NewWildcardQuery(Term t);
    protected internal virtual Query GetBooleanQuery(IList`1<BooleanClause> clauses);
    protected internal virtual Query GetBooleanQuery(IList`1<BooleanClause> clauses, bool disableCoord);
    protected internal virtual Query GetWildcardQuery(string field, string termStr);
    protected internal virtual Query GetPrefixQuery(string field, string termStr);
    protected internal virtual Query GetFuzzyQuery(string field, string termStr, float minSimilarity);
    private string DiscardEscapeChar(string input);
    private static int HexToInt(char c);
    public static string Escape(string s);
    public int Conjunction();
    public int Modifiers();
    public Query TopLevelQuery(string field);
    public Query Query(string field);
    public Query Clause(string field);
    public Query Term(string field);
    private bool Jj_2_1(int xla);
    private bool Jj_3R_2();
    private bool Jj_3_1();
    private bool Jj_3R_3();
    private static void Jj_la1_init_0();
    private static void Jj_la1_init_1();
    public void ReInit(ICharStream stream);
    public void ReInit(QueryParserTokenManager tm);
    private Token Jj_consume_token(int kind);
    private bool jj_scan_token(int kind);
    public Token GetNextToken();
    public Token getToken(int index);
    private int Jj_ntk();
    private void Jj_add_error_token(int kind, int pos);
    public virtual ParseException GenerateParseException();
    public void Enable_tracing();
    public void Disable_tracing();
    private void Jj_rescan_token();
    private void Jj_save(int index, int xla);
}
public class Lucene.Net.QueryParsers.QueryParserConstants : object {
    protected internal static int EndOfFileToken;
    protected internal static int NumCharToken;
    protected internal static int EscapedCharToken;
    protected internal static int TermStartCharToken;
    protected internal static int TermCharToken;
    protected internal static int WhitespaceToken;
    protected internal static int QuotedCharToken;
    protected internal static int AndToken;
    protected internal static int OrToken;
    protected internal static int NotToken;
    protected internal static int PlusToken;
    protected internal static int MinusToken;
    protected internal static int LParanToken;
    protected internal static int RParenToken;
    protected internal static int ColonToken;
    protected internal static int StarToken;
    protected internal static int CaratToken;
    protected internal static int QuotedToken;
    protected internal static int TermToken;
    protected internal static int FuzzySlopToken;
    protected internal static int PrefixTermToken;
    protected internal static int WildTermToken;
    protected internal static int RangeInStartToken;
    protected internal static int RangeExStartToken;
    protected internal static int NumberToken;
    protected internal static int RangeInToToken;
    protected internal static int RangeInEndToken;
    protected internal static int RangeInQuotedToken;
    protected internal static int RangeInGoopToken;
    protected internal static int RangeExToToken;
    protected internal static int RangeExEndToken;
    protected internal static int RangeExQuotedToken;
    protected internal static int RangeExGoopToken;
    protected internal static int BoostToken;
    protected static int RangeExToken;
    protected internal static int RangeInToken;
    protected internal static int DefaultToken;
    protected internal static String[] tokenImage;
    private static QueryParserConstants();
}
public class Lucene.Net.QueryParsers.QueryParserTokenManager : QueryParserConstants {
    internal static UInt64[] jjbitVec0;
    internal static UInt64[] jjbitVec1;
    internal static UInt64[] jjbitVec3;
    internal static UInt64[] jjbitVec4;
    internal static Int32[] jjnextStates;
    public static String[] jjstrLiteralImages;
    public static String[] lexStateNames;
    public static Int32[] jjnewLexState;
    internal static UInt64[] jjtoToken;
    internal static Int64[] jjtoSkip;
    protected internal ICharStream input_stream;
    private UInt32[] jjrounds;
    private Int32[] jjstateSet;
    protected internal char curChar;
    internal int curLexState;
    internal int defaultLexState;
    internal int jjnewStateCnt;
    internal UInt32 jjround;
    internal int jjmatchedPos;
    internal int jjmatchedKind;
    public QueryParserTokenManager(ICharStream stream);
    public QueryParserTokenManager(ICharStream stream, int lexState);
    private static QueryParserTokenManager();
    private int JjStopStringLiteralDfa_3(int pos, long active0);
    private int JjStartNfa_3(int pos, long active0);
    private int JjStopAtPos(int pos, int kind);
    private int JjMoveStringLiteralDfa0_3();
    private int JjStartNfaWithStates_3(int pos, int kind, int state);
    private int JjMoveNfa_3(int startState, int curPos);
    private int JjStopStringLiteralDfa_1(int pos, long active0);
    private int JjStartNfa_1(int pos, long active0);
    private int JjMoveStringLiteralDfa0_1();
    private int JjMoveStringLiteralDfa1_1(long active0);
    private int JjStartNfaWithStates_1(int pos, int kind, int state);
    private int JjMoveNfa_1(int startState, int curPos);
    private int JjMoveStringLiteralDfa0_0();
    private int JjMoveNfa_0(int startState, int curPos);
    private int JjStopStringLiteralDfa_2(int pos, long active0);
    private int JjStartNfa_2(int pos, long active0);
    private int JjMoveStringLiteralDfa0_2();
    private int JjMoveStringLiteralDfa1_2(long active0);
    private int JjStartNfaWithStates_2(int pos, int kind, int state);
    private int JjMoveNfa_2(int startState, int curPos);
    private static bool JjCanMove_0(int hiByte, int i1, int i2, ulong l1, ulong l2);
    private static bool JjCanMove_1(int hiByte, int i1, int i2, ulong l1, ulong l2);
    private static bool JjCanMove_2(int hiByte, int i1, int i2, ulong l1, ulong l2);
    public virtual void ReInit(ICharStream stream);
    private void ReInitRounds();
    public virtual void ReInit(ICharStream stream, int lexState);
    public virtual void SwitchTo(int lexState);
    protected internal virtual Token JjFillToken();
    public virtual Token GetNextToken();
    private void JjCheckNAdd(int state);
    private void JjAddStates(int start, int end);
    private void JjCheckNAddTwoStates(int state1, int state2);
    private void JjCheckNAddStates(int start, int end);
}
public class Lucene.Net.QueryParsers.Token : object {
    public int kind;
    public int beginLine;
    public int beginColumn;
    public int endLine;
    public int endColumn;
    public string image;
    public Token next;
    public Token specialToken;
    public object Value { get; }
    public Token(int kind);
    public Token(int kind, string image);
    public virtual object get_Value();
    public virtual string ToString();
    public static Token NewToken(int ofKind, string image);
    public static Token NewToken(int ofKind);
}
public class Lucene.Net.QueryParsers.TokenMgrError : ApplicationException {
    internal static int LEXICAL_ERROR;
    internal static int STATIC_LEXER_ERROR;
    internal static int INVALID_LEXICAL_STATE;
    internal static int LOOP_DETECTED;
    internal int errorCode;
    public string Message { get; }
    public TokenMgrError(string message, int reason);
    public TokenMgrError(bool EOFSeen, int lexState, int errorLine, int errorColumn, string errorAfter, char curChar, int reason);
    public virtual string get_Message();
    protected internal static string addEscapes(string str);
    protected internal static string LexicalError(bool EOFSeen, int lexState, int errorLine, int errorColumn, string errorAfter, char curChar);
}
internal class Lucene.Net.Search.AnonymousClassByteParser : object {
    public virtual sbyte ParseByte(string value_Renamed);
    protected internal virtual object ReadResolve();
    public virtual string ToString();
}
internal class Lucene.Net.Search.AnonymousClassDoubleParser : object {
    public virtual double ParseDouble(string value_Renamed);
    protected internal virtual object ReadResolve();
    public virtual string ToString();
}
internal class Lucene.Net.Search.AnonymousClassDoubleParser1 : object {
    public virtual double ParseDouble(string val);
    protected internal virtual object ReadResolve();
    public virtual string ToString();
}
internal class Lucene.Net.Search.AnonymousClassFloatParser : object {
    public virtual float ParseFloat(string value_Renamed);
    protected internal virtual object ReadResolve();
    public virtual string ToString();
}
internal class Lucene.Net.Search.AnonymousClassFloatParser1 : object {
    public virtual float ParseFloat(string val);
    protected internal virtual object ReadResolve();
    public virtual string ToString();
}
internal class Lucene.Net.Search.AnonymousClassIntParser : object {
    public virtual int ParseInt(string value_Renamed);
    protected internal virtual object ReadResolve();
    public virtual string ToString();
}
internal class Lucene.Net.Search.AnonymousClassIntParser1 : object {
    public virtual int ParseInt(string val);
    protected internal virtual object ReadResolve();
    public virtual string ToString();
}
internal class Lucene.Net.Search.AnonymousClassLongParser : object {
    public virtual long ParseLong(string value_Renamed);
    protected internal virtual object ReadResolve();
    public virtual string ToString();
}
internal class Lucene.Net.Search.AnonymousClassLongParser1 : object {
    public virtual long ParseLong(string val);
    protected internal virtual object ReadResolve();
    public virtual string ToString();
}
internal class Lucene.Net.Search.AnonymousClassShortParser : object {
    public virtual short ParseShort(string value_Renamed);
    protected internal virtual object ReadResolve();
    public virtual string ToString();
}
public class Lucene.Net.Search.BooleanClause : object {
    private Occur occur;
    private Query _query;
    public Occur Occur { get; public set; }
    public Query Query { get; public set; }
    public bool IsProhibited { get; }
    public bool IsRequired { get; }
    public BooleanClause(Query query, Occur occur);
    public virtual Occur get_Occur();
    public virtual void set_Occur(Occur value);
    public virtual Query get_Query();
    public virtual void set_Query(Query value);
    public virtual bool get_IsProhibited();
    public virtual bool get_IsRequired();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    public virtual string ToString();
}
public class Lucene.Net.Search.BooleanQuery : Query {
    private static int _maxClauses;
    private EquatableList`1<BooleanClause> clauses;
    private bool disableCoord;
    protected internal int minNrShouldMatch;
    public static int MaxClauseCount { get; public set; }
    public int MinimumNumberShouldMatch { get; public set; }
    public List`1<BooleanClause> Clauses { get; }
    public BooleanQuery(bool disableCoord);
    private static BooleanQuery();
    public static int get_MaxClauseCount();
    public static void set_MaxClauseCount(int value);
    public virtual bool IsCoordDisabled();
    public virtual Similarity GetSimilarity(Searcher searcher);
    public virtual void set_MinimumNumberShouldMatch(int value);
    public virtual int get_MinimumNumberShouldMatch();
    public virtual void Add(Query query, Occur occur);
    public virtual void Add(BooleanClause clause);
    public virtual BooleanClause[] GetClauses();
    public virtual List`1<BooleanClause> get_Clauses();
    public sealed virtual IEnumerator`1<BooleanClause> GetEnumerator();
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual object Clone();
    public virtual string ToString(string field);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    private sealed virtual override IEnumerator System.Collections.IEnumerable.GetEnumerator();
}
public class Lucene.Net.Search.BooleanScorer : Scorer {
    private SubScorer scorers;
    private BucketTable bucketTable;
    private int maxCoord;
    private Single[] coordFactors;
    private int requiredMask;
    private int prohibitedMask;
    private int nextMask;
    private int minNrShouldMatch;
    private int end;
    private Bucket current;
    private int doc;
    public BooleanScorer(Similarity similarity, int minNrShouldMatch, List`1<Scorer> optionalScorers, List`1<Scorer> prohibitedScorers, IState state);
    private void InitBlock();
    public virtual bool Score(Collector collector, int max, int firstDocID, IState state);
    public virtual int Advance(int target, IState state);
    public virtual int DocID();
    public virtual int NextDoc(IState state);
    public virtual float Score(IState state);
    public virtual void Score(Collector collector, IState state);
    public virtual string ToString();
}
internal class Lucene.Net.Search.BooleanScorer2 : Scorer {
    private List`1<Scorer> requiredScorers;
    private List`1<Scorer> optionalScorers;
    private List`1<Scorer> prohibitedScorers;
    private Coordinator coordinator;
    private Scorer countingSumScorer;
    private int minNrShouldMatch;
    private int doc;
    private static Similarity defaultSimilarity;
    public BooleanScorer2(Similarity similarity, int minNrShouldMatch, List`1<Scorer> required, List`1<Scorer> prohibited, List`1<Scorer> optional, IState state);
    private static BooleanScorer2();
    private Scorer CountingDisjunctionSumScorer(List`1<Scorer> scorers, int minNrShouldMatch, IState state);
    private Scorer CountingConjunctionSumScorer(List`1<Scorer> requiredScorers, IState state);
    private Scorer DualConjunctionSumScorer(Scorer req1, Scorer req2, IState state);
    private Scorer MakeCountingSumScorer(IState state);
    private Scorer MakeCountingSumScorerNoReq(IState state);
    private Scorer MakeCountingSumScorerSomeReq(IState state);
    private Scorer AddProhibitedScorers(Scorer requiredCountingSumScorer, IState state);
    public virtual void Score(Collector collector, IState state);
    public virtual bool Score(Collector collector, int max, int firstDocID, IState state);
    public virtual int DocID();
    public virtual int NextDoc(IState state);
    public virtual float Score(IState state);
    public virtual int Advance(int target, IState state);
}
public interface Lucene.Net.Search.ByteParser {
    public abstract virtual sbyte ParseByte(string string_Renamed);
}
public abstract class Lucene.Net.Search.CacheEntry : object {
    [CompilerGeneratedAttribute]
private string <EstimatedSize>k__BackingField;
    public object ReaderKey { get; }
    public string FieldName { get; }
    public Type CacheType { get; }
    public object Custom { get; }
    public object Value { get; }
    public string EstimatedSize { get; protected internal set; }
    public abstract virtual object get_ReaderKey();
    public abstract virtual string get_FieldName();
    public abstract virtual Type get_CacheType();
    public abstract virtual object get_Custom();
    public abstract virtual object get_Value();
    public virtual void EstimateSize();
    public virtual void EstimateSize(RamUsageEstimator ramCalc);
    [CompilerGeneratedAttribute]
public string get_EstimatedSize();
    [CompilerGeneratedAttribute]
protected internal void set_EstimatedSize(string value);
    public virtual string ToString();
}
public class Lucene.Net.Search.CachingSpanFilter : SpanFilter {
    private SpanFilter filter;
    internal FilterCache`1<SpanFilterResult> cache;
    public int hitCount;
    public int missCount;
    public CachingSpanFilter(SpanFilter filter);
    public CachingSpanFilter(SpanFilter filter, DeletesMode deletesMode);
    public virtual DocIdSet GetDocIdSet(IndexReader reader, IState state);
    private SpanFilterResult GetCachedResult(IndexReader reader, IState state);
    public virtual SpanFilterResult BitSpans(IndexReader reader, IState state);
    public virtual string ToString();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.CachingWrapperFilter : Filter {
    protected internal Filter filter;
    internal FilterCache`1<DocIdSet> cache;
    public int hitCount;
    public int missCount;
    public CachingWrapperFilter(Filter filter);
    public CachingWrapperFilter(Filter filter, DeletesMode deletesMode);
    protected internal virtual DocIdSet DocIdSetToCache(DocIdSet docIdSet, IndexReader reader, IState state);
    public virtual DocIdSet GetDocIdSet(IndexReader reader, IState state);
    public virtual string ToString();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public abstract class Lucene.Net.Search.Collector : object {
    public bool AcceptsDocsOutOfOrder { get; }
    public abstract virtual void SetScorer(Scorer scorer);
    public abstract virtual void Collect(int doc, IState state);
    public abstract virtual void SetNextReader(IndexReader reader, int docBase, IState state);
    public abstract virtual bool get_AcceptsDocsOutOfOrder();
}
public class Lucene.Net.Search.ComplexExplanation : Explanation {
    private Nullable`1<bool> match;
    public Nullable`1<bool> Match { get; public set; }
    public bool IsMatch { get; }
    protected internal string Summary { get; }
    public ComplexExplanation(bool match, float value_Renamed, string description);
    public virtual Nullable`1<bool> get_Match();
    public virtual void set_Match(Nullable`1<bool> value);
    public virtual bool get_IsMatch();
    protected internal virtual string get_Summary();
}
internal class Lucene.Net.Search.ConjunctionScorer : Scorer {
    private Scorer[] scorers;
    private float coord;
    private int lastDoc;
    public ConjunctionScorer(Similarity similarity, IState state, ICollection`1<Scorer> scorers);
    public ConjunctionScorer(Similarity similarity, IState state, Scorer[] scorers);
    private int DoNext(IState state);
    public virtual int Advance(int target, IState state);
    public virtual int DocID();
    public virtual int NextDoc(IState state);
    public virtual float Score(IState state);
}
public class Lucene.Net.Search.ConstantScoreQuery : Query {
    protected internal Filter internalFilter;
    public Filter Filter { get; }
    public ConstantScoreQuery(Filter filter);
    public virtual Filter get_Filter();
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual string ToString(string field);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    public virtual object Clone();
}
public class Lucene.Net.Search.DefaultSimilarity : Similarity {
    protected internal bool internalDiscountOverlaps;
    public bool DiscountOverlaps { get; public set; }
    public virtual float ComputeNorm(string field, FieldInvertState state);
    public virtual float LengthNorm(string fieldName, int numTerms);
    public virtual float QueryNorm(float sumOfSquaredWeights);
    public virtual float Tf(float freq);
    public virtual float SloppyFreq(int distance);
    public virtual float Idf(int docFreq, int numDocs);
    public virtual float Coord(int overlap, int maxOverlap);
    public virtual bool get_DiscountOverlaps();
    public virtual void set_DiscountOverlaps(bool value);
}
public class Lucene.Net.Search.DisjunctionMaxQuery : Query {
    private EquatableList`1<Query> disjuncts;
    private float tieBreakerMultiplier;
    public DisjunctionMaxQuery(float tieBreakerMultiplier);
    public DisjunctionMaxQuery(ICollection`1<Query> disjuncts, float tieBreakerMultiplier);
    public virtual void Add(Query query);
    public virtual void Add(ICollection`1<Query> disjuncts);
    public virtual IEnumerator`1<Query> GetEnumerator();
    private sealed virtual override IEnumerator System.Collections.IEnumerable.GetEnumerator();
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual object Clone();
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual string ToString(string field);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.DisjunctionMaxScorer : Scorer {
    private Scorer[] subScorers;
    private int numScorers;
    private float tieBreakerMultiplier;
    private int doc;
    public DisjunctionMaxScorer(float tieBreakerMultiplier, Similarity similarity, Scorer[] subScorers, int numScorers);
    public virtual int NextDoc(IState state);
    public virtual int DocID();
    public virtual float Score(IState state);
    private void ScoreAll(int root, int size, int doc, Single[] sum, Single[] max, IState state);
    public virtual int Advance(int target, IState state);
    private void Heapify();
    private void HeapAdjust(int root);
    private void HeapRemoveRoot();
}
internal class Lucene.Net.Search.DisjunctionSumScorer : Scorer {
    private int nrScorers;
    protected internal IList`1<Scorer> subScorers;
    private int minimumNrMatchers;
    private ScorerDocQueue scorerDocQueue;
    private int currentDoc;
    protected internal int nrMatchers;
    private float currentScore;
    public DisjunctionSumScorer(IList`1<Scorer> subScorers, int minimumNrMatchers, IState state);
    public DisjunctionSumScorer(IList`1<Scorer> subScorers, IState state);
    private void InitScorerDocQueue(IState state);
    public virtual void Score(Collector collector, IState state);
    public virtual bool Score(Collector collector, int max, int firstDocID, IState state);
    public virtual int NextDoc(IState state);
    protected internal virtual bool AdvanceAfterCurrent(IState state);
    public virtual float Score(IState state);
    public virtual int DocID();
    public virtual int NrMatchers();
    public virtual int Advance(int target, IState state);
}
public abstract class Lucene.Net.Search.DocIdSet : object {
    public static DocIdSet EMPTY_DOCIDSET;
    public bool IsCacheable { get; }
    private static DocIdSet();
    public abstract virtual DocIdSetIterator Iterator(IState state);
    public virtual bool get_IsCacheable();
}
public abstract class Lucene.Net.Search.DocIdSetIterator : object {
    private int doc;
    public static int NO_MORE_DOCS;
    private static DocIdSetIterator();
    public abstract virtual int DocID();
    public abstract virtual int NextDoc(IState state);
    public abstract virtual int Advance(int target, IState state);
}
public interface Lucene.Net.Search.DoubleParser {
    public abstract virtual double ParseDouble(string string_Renamed);
}
internal class Lucene.Net.Search.ExactPhraseScorer : PhraseScorer {
    internal ExactPhraseScorer(Weight weight, TermPositions[] tps, Int32[] offsets, Similarity similarity, Byte[] norms);
    protected internal virtual float PhraseFreq(IState state);
}
public class Lucene.Net.Search.Explanation : object {
    private float value;
    private string description;
    private List`1<Explanation> details;
    public bool IsMatch { get; }
    public float Value { get; public set; }
    public string Description { get; public set; }
    protected internal string Summary { get; }
    public Explanation(float value, string description);
    public virtual bool get_IsMatch();
    public virtual float get_Value();
    public virtual void set_Value(float value);
    public virtual string get_Description();
    public virtual void set_Description(string value);
    protected internal virtual string get_Summary();
    public virtual Explanation[] GetDetails();
    public virtual void AddDetail(Explanation detail);
    public virtual string ToString();
    protected internal virtual string ToString(int depth);
    public virtual string ToHtml();
}
public interface Lucene.Net.Search.FieldCache {
    public StreamWriter InfoStream { get; public set; }
    public abstract virtual SByte[] GetBytes(IndexReader reader, string field, IState state);
    public abstract virtual SByte[] GetBytes(IndexReader reader, string field, ByteParser parser, IState state);
    public abstract virtual Int16[] GetShorts(IndexReader reader, string field, IState state);
    public abstract virtual Int16[] GetShorts(IndexReader reader, string field, ShortParser parser, IState state);
    public abstract virtual Int32[] GetInts(IndexReader reader, string field, IState state);
    public abstract virtual Int32[] GetInts(IndexReader reader, string field, IntParser parser, IState state);
    public abstract virtual Single[] GetFloats(IndexReader reader, string field, IState state);
    public abstract virtual Single[] GetFloats(IndexReader reader, string field, FloatParser parser, IState state);
    public abstract virtual Int64[] GetLongs(IndexReader reader, string field, IState state);
    public abstract virtual Int64[] GetLongs(IndexReader reader, string field, LongParser parser, IState state);
    public abstract virtual Double[] GetDoubles(IndexReader reader, string field, IState state);
    public abstract virtual Double[] GetDoubles(IndexReader reader, string field, DoubleParser parser, IState state);
    public abstract virtual String[] GetStrings(IndexReader reader, string field, IState state);
    public abstract virtual StringIndex GetStringIndex(IndexReader reader, string field, IState state);
    public abstract virtual CacheEntry[] GetCacheEntries();
    public abstract virtual IDisposable PurgeAllCaches();
    public abstract virtual void Purge(IndexReader r);
    public abstract virtual StreamWriter get_InfoStream();
    public abstract virtual void set_InfoStream(StreamWriter value);
}
public class Lucene.Net.Search.FieldCache_Fields : ValueType {
    public static int STRING_INDEX;
    public static FieldCache DEFAULT;
    public static ByteParser DEFAULT_BYTE_PARSER;
    public static ShortParser DEFAULT_SHORT_PARSER;
    public static IntParser DEFAULT_INT_PARSER;
    public static FloatParser DEFAULT_FLOAT_PARSER;
    public static LongParser DEFAULT_LONG_PARSER;
    public static DoubleParser DEFAULT_DOUBLE_PARSER;
    public static IntParser NUMERIC_UTILS_INT_PARSER;
    public static FloatParser NUMERIC_UTILS_FLOAT_PARSER;
    public static LongParser NUMERIC_UTILS_LONG_PARSER;
    public static DoubleParser NUMERIC_UTILS_DOUBLE_PARSER;
    private static FieldCache_Fields();
}
internal class Lucene.Net.Search.FieldCacheImpl : object {
    private LongCache _longCache;
    private ByteCache _byteCache;
    private ShortCache _shortCache;
    private FloatCache _floatCache;
    private IntCache _intCache;
    private DoubleCache _doubleCache;
    private StringCache _stringCache;
    private StringIndexCache _stringIndexCache;
    private StreamWriter modreq(System.Runtime.CompilerServices.IsVolatile) infoStream;
    public StreamWriter InfoStream { get; public set; }
    private void Init();
    public virtual IDisposable PurgeAllCaches();
    public sealed virtual void Purge(IndexReader r);
    public virtual CacheEntry[] GetCacheEntries();
    public virtual SByte[] GetBytes(IndexReader reader, string field, IState state);
    public virtual SByte[] GetBytes(IndexReader reader, string field, ByteParser parser, IState state);
    public virtual Int16[] GetShorts(IndexReader reader, string field, IState state);
    public virtual Int16[] GetShorts(IndexReader reader, string field, ShortParser parser, IState state);
    public virtual Int32[] GetInts(IndexReader reader, string field, IState state);
    public virtual Int32[] GetInts(IndexReader reader, string field, IntParser parser, IState state);
    public virtual Single[] GetFloats(IndexReader reader, string field, IState state);
    public virtual Single[] GetFloats(IndexReader reader, string field, FloatParser parser, IState state);
    public virtual Int64[] GetLongs(IndexReader reader, string field, IState state);
    public virtual Int64[] GetLongs(IndexReader reader, string field, LongParser parser, IState state);
    public virtual Double[] GetDoubles(IndexReader reader, string field, IState state);
    public virtual Double[] GetDoubles(IndexReader reader, string field, DoubleParser parser, IState state);
    public virtual String[] GetStrings(IndexReader reader, string field, IState state);
    public virtual StringIndex GetStringIndex(IndexReader reader, string field, IState state);
    public virtual StreamWriter get_InfoStream();
    public virtual void set_InfoStream(StreamWriter value);
}
public static class Lucene.Net.Search.FieldCacheRangeFilter : object {
    public static FieldCacheRangeFilter`1<string> NewStringRange(string field, string lowerVal, string upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<sbyte>> NewByteRange(string field, Nullable`1<sbyte> lowerVal, Nullable`1<sbyte> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<sbyte>> NewByteRange(string field, ByteParser parser, Nullable`1<sbyte> lowerVal, Nullable`1<sbyte> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<short>> NewShortRange(string field, Nullable`1<short> lowerVal, Nullable`1<short> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<short>> NewShortRange(string field, ShortParser parser, Nullable`1<short> lowerVal, Nullable`1<short> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<int>> NewIntRange(string field, Nullable`1<int> lowerVal, Nullable`1<int> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<int>> NewIntRange(string field, IntParser parser, Nullable`1<int> lowerVal, Nullable`1<int> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<long>> NewLongRange(string field, Nullable`1<long> lowerVal, Nullable`1<long> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<long>> NewLongRange(string field, LongParser parser, Nullable`1<long> lowerVal, Nullable`1<long> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<float>> NewFloatRange(string field, Nullable`1<float> lowerVal, Nullable`1<float> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<float>> NewFloatRange(string field, FloatParser parser, Nullable`1<float> lowerVal, Nullable`1<float> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<double>> NewDoubleRange(string field, Nullable`1<double> lowerVal, Nullable`1<double> upperVal, bool includeLower, bool includeUpper);
    public static FieldCacheRangeFilter`1<Nullable`1<double>> NewDoubleRange(string field, DoubleParser parser, Nullable`1<double> lowerVal, Nullable`1<double> upperVal, bool includeLower, bool includeUpper);
}
public abstract class Lucene.Net.Search.FieldCacheRangeFilter`1 : Filter {
    internal string field;
    internal Parser parser;
    internal T lowerVal;
    internal T upperVal;
    internal bool includeLower;
    internal bool includeUpper;
    public string GetField { get; }
    public bool IncludesLower { get; }
    public bool IncludesUpper { get; }
    public T LowerValue { get; }
    public T UpperValue { get; }
    public Parser Parser { get; }
    protected internal FieldCacheRangeFilter`1(string field, Parser parser, T lowerVal, T upperVal, bool includeLower, bool includeUpper);
    public abstract virtual DocIdSet GetDocIdSet(IndexReader reader, IState state);
    public virtual string ToString();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    public string get_GetField();
    public bool get_IncludesLower();
    public bool get_IncludesUpper();
    public T get_LowerValue();
    public T get_UpperValue();
    public Parser get_Parser();
}
public class Lucene.Net.Search.FieldCacheTermsFilter : Filter {
    private string field;
    private String[] terms;
    public FieldCache FieldCache { get; }
    public FieldCacheTermsFilter(string field, String[] terms);
    public virtual FieldCache get_FieldCache();
    public virtual DocIdSet GetDocIdSet(IndexReader reader, IState state);
}
[DefaultMemberAttribute("Item")]
public abstract class Lucene.Net.Search.FieldComparator : object {
    public IComparable Item { get; }
    public abstract virtual int Compare(int slot1, int slot2);
    public abstract virtual void SetBottom(int slot);
    public abstract virtual int CompareBottom(int doc, IState state);
    public abstract virtual void Copy(int slot, int doc, IState state);
    public abstract virtual void SetNextReader(IndexReader reader, int docBase, IState state);
    public virtual void SetScorer(Scorer scorer);
    public abstract virtual IComparable get_Item(int slot);
    protected internal static int BinarySearch(UnmanagedStringArray a, UnmanagedString key);
    protected internal static int BinarySearch(UnmanagedStringArray a, UnmanagedString key, int low, int high);
}
public abstract class Lucene.Net.Search.FieldComparatorSource : object {
    public abstract virtual FieldComparator NewComparator(string fieldname, int numHits, int sortPos, bool reversed);
}
public class Lucene.Net.Search.FieldDoc : ScoreDoc {
    public IComparable[] fields;
    internal Object[] fieldsClone;
    public FieldDoc(int doc, float score);
    public FieldDoc(int doc, float score, IComparable[] fields);
    public virtual string ToString();
    [OnSerializingAttribute]
private void OnSerializing(StreamingContext context);
    [OnDeserializedAttribute]
private void OnDeserialized(StreamingContext context);
}
internal class Lucene.Net.Search.FieldDocSortedHitQueue : PriorityQueue`1<FieldDoc> {
    internal ArraySegment`1<SortField> fields;
    internal CompareInfo[] modreq(System.Runtime.CompilerServices.IsVolatile) collators;
    internal FieldDocSortedHitQueue(int size);
    internal virtual void SetFields(ArraySegment`1<SortField> fields);
    internal virtual ArraySegment`1<SortField> GetFields();
    private CompareInfo[] HasCollators(ArraySegment`1<SortField> fields);
    private bool IsNull(object obj);
    public virtual bool LessThan(FieldDoc docA, FieldDoc docB);
}
public abstract class Lucene.Net.Search.FieldValueHitQueue : PriorityQueue`1<Entry> {
    protected internal ArraySegment`1<SortField> fields;
    protected internal FieldComparator[] comparators;
    protected internal Int32[] reverseMul;
    private FieldValueHitQueue(ArraySegment`1<SortField> fields);
    public static FieldValueHitQueue Create(ArraySegment`1<SortField> fields, int size);
    internal virtual FieldComparator[] GetComparators();
    internal virtual Int32[] GetReverseMul();
    public abstract virtual bool LessThan(Entry a, Entry b);
    internal virtual FieldDoc FillFields(Entry entry);
    internal virtual ArraySegment`1<SortField> GetFields();
}
public abstract class Lucene.Net.Search.Filter : object {
    public abstract virtual DocIdSet GetDocIdSet(IndexReader reader, IState state);
}
public abstract class Lucene.Net.Search.FilteredDocIdSet : DocIdSet {
    private DocIdSet _innerSet;
    public bool IsCacheable { get; }
    protected FilteredDocIdSet(DocIdSet innerSet);
    public virtual bool get_IsCacheable();
    public abstract virtual bool Match(int docid);
    public virtual DocIdSetIterator Iterator(IState state);
}
public abstract class Lucene.Net.Search.FilteredDocIdSetIterator : DocIdSetIterator {
    protected internal DocIdSetIterator internalInnerIter;
    private int doc;
    protected FilteredDocIdSetIterator(DocIdSetIterator innerIter);
    public abstract virtual bool Match(int doc);
    public virtual int DocID();
    public virtual int NextDoc(IState state);
    public virtual int Advance(int target, IState state);
}
public class Lucene.Net.Search.FilteredQuery : Query {
    internal Query query;
    internal Filter filter;
    public Query Query { get; }
    public Filter Filter { get; }
    public FilteredQuery(Query query, Filter filter);
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual Query get_Query();
    public virtual Filter get_Filter();
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual string ToString(string s);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public abstract class Lucene.Net.Search.FilteredTermEnum : TermEnum {
    protected internal Term currentTerm;
    protected internal TermEnum actualEnum;
    private bool isDisposed;
    public Term Term { get; }
    protected internal abstract virtual bool TermCompare(Term term);
    public abstract virtual float Difference();
    public abstract virtual bool EndEnum();
    protected internal virtual void SetEnum(TermEnum actualEnum, IState state);
    public virtual int DocFreq();
    public virtual bool Next(IState state);
    public virtual Term get_Term();
    protected virtual void Dispose(bool disposing);
}
public class Lucene.Net.Search.FilterManager : object {
    protected internal static FilterManager manager;
    protected internal static int DEFAULT_CACHE_CLEAN_SIZE;
    protected internal static long DEFAULT_CACHE_SLEEP_TIME;
    protected internal IDictionary`2<int, FilterItem> cache;
    protected internal int cacheCleanSize;
    protected internal long cleanSleepTime;
    protected internal FilterCleaner internalFilterCleaner;
    private static object _staticSyncObj;
    public static FilterManager Instance { get; }
    private static FilterManager();
    public static FilterManager get_Instance();
    public virtual void SetCacheSize(int value);
    public virtual void SetCleanThreadSleepTime(long value);
    public virtual Filter GetFilter(Filter filter);
}
public interface Lucene.Net.Search.FloatParser {
    public abstract virtual float ParseFloat(string string_Renamed);
}
public class Lucene.Net.Search.Function.ByteFieldSource : FieldCacheSource {
    private ByteParser parser;
    public ByteFieldSource(string field);
    public ByteFieldSource(string field, ByteParser parser);
    public virtual string Description();
    public virtual DocValues GetCachedFieldValues(FieldCache cache, string field, IndexReader reader, IState state);
    public virtual bool CachedFieldSourceEquals(FieldCacheSource o);
    public virtual int CachedFieldSourceHashCode();
}
public class Lucene.Net.Search.Function.CustomScoreProvider : object {
    protected IndexReader reader;
    public CustomScoreProvider(IndexReader reader);
    public virtual float CustomScore(int doc, float subQueryScore, Single[] valSrcScores);
    public virtual float CustomScore(int doc, float subQueryScore, float valSrcScore);
    public virtual Explanation CustomExplain(int doc, Explanation subQueryExpl, Explanation[] valSrcExpls);
    public virtual Explanation CustomExplain(int doc, Explanation subQueryExpl, Explanation valSrcExpl);
}
public class Lucene.Net.Search.Function.CustomScoreQuery : Query {
    private Query subQuery;
    private ValueSourceQuery[] valSrcQueries;
    private bool strict;
    public CustomScoreQuery(Query subQuery);
    public CustomScoreQuery(Query subQuery, ValueSourceQuery valSrcQuery);
    public CustomScoreQuery(Query subQuery, ValueSourceQuery[] valSrcQueries);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual object Clone();
    public virtual string ToString(string field);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    protected virtual CustomScoreProvider GetCustomScoreProvider(IndexReader reader);
    [ObsoleteAttribute("Will be removed in Lucene 3.1")]
public virtual float CustomScore(int doc, float subQueryScore, Single[] valSrcScores);
    [ObsoleteAttribute("Will be removed in Lucene 3.1")]
public virtual float CustomScore(int doc, float subQueryScore, float valSrcScore);
    [ObsoleteAttribute("Will be removed in Lucene 3.1")]
public virtual Explanation CustomExplain(int doc, Explanation subQueryExpl, Explanation[] valSrcExpls);
    [ObsoleteAttribute("Will be removed in Lucene 3.1")]
public virtual Explanation CustomExplain(int doc, Explanation subQueryExpl, Explanation valSrcExpl);
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual bool IsStrict();
    public virtual void SetStrict(bool strict);
    public virtual string Name();
}
public abstract class Lucene.Net.Search.Function.DocValues : object {
    private float minVal;
    private float maxVal;
    private float avgVal;
    private bool computed;
    protected internal object InnerArray { get; }
    public abstract virtual float FloatVal(int doc);
    public virtual int IntVal(int doc);
    public virtual long LongVal(int doc);
    public virtual double DoubleVal(int doc);
    public virtual string StrVal(int doc);
    public abstract virtual string ToString(int doc);
    public virtual Explanation Explain(int doc);
    protected internal virtual object get_InnerArray();
    private void Compute();
    public virtual float GetMinValue();
    public virtual float GetMaxValue();
    public virtual float GetAverageValue();
}
public abstract class Lucene.Net.Search.Function.FieldCacheSource : ValueSource {
    private string field;
    protected FieldCacheSource(string field);
    public virtual DocValues GetValues(IndexReader reader, IState state);
    public virtual string Description();
    public abstract virtual DocValues GetCachedFieldValues(FieldCache cache, string field, IndexReader reader, IState state);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    public abstract virtual bool CachedFieldSourceEquals(FieldCacheSource other);
    public abstract virtual int CachedFieldSourceHashCode();
}
public class Lucene.Net.Search.Function.FieldScoreQuery : ValueSourceQuery {
    public FieldScoreQuery(string field, Type type);
    private static ValueSource GetValueSource(string field, Type type);
}
public class Lucene.Net.Search.Function.FloatFieldSource : FieldCacheSource {
    private FloatParser parser;
    public FloatFieldSource(string field);
    public FloatFieldSource(string field, FloatParser parser);
    public virtual string Description();
    public virtual DocValues GetCachedFieldValues(FieldCache cache, string field, IndexReader reader, IState state);
    public virtual bool CachedFieldSourceEquals(FieldCacheSource o);
    public virtual int CachedFieldSourceHashCode();
}
public class Lucene.Net.Search.Function.IntFieldSource : FieldCacheSource {
    private IntParser parser;
    public IntFieldSource(string field);
    public IntFieldSource(string field, IntParser parser);
    public virtual string Description();
    public virtual DocValues GetCachedFieldValues(FieldCache cache, string field, IndexReader reader, IState state);
    public virtual bool CachedFieldSourceEquals(FieldCacheSource o);
    public virtual int CachedFieldSourceHashCode();
}
public class Lucene.Net.Search.Function.OrdFieldSource : ValueSource {
    protected internal string field;
    private static int hcode;
    public OrdFieldSource(string field);
    private static OrdFieldSource();
    public virtual string Description();
    public virtual DocValues GetValues(IndexReader reader, IState state);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.Function.ReverseOrdFieldSource : ValueSource {
    public string field;
    private static int hcode;
    public ReverseOrdFieldSource(string field);
    private static ReverseOrdFieldSource();
    public virtual string Description();
    public virtual DocValues GetValues(IndexReader reader, IState state);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.Function.ShortFieldSource : FieldCacheSource {
    private ShortParser parser;
    public ShortFieldSource(string field);
    public ShortFieldSource(string field, ShortParser parser);
    public virtual string Description();
    public virtual DocValues GetCachedFieldValues(FieldCache cache, string field, IndexReader reader, IState state);
    public virtual bool CachedFieldSourceEquals(FieldCacheSource o);
    public virtual int CachedFieldSourceHashCode();
}
public abstract class Lucene.Net.Search.Function.ValueSource : object {
    public abstract virtual DocValues GetValues(IndexReader reader, IState state);
    public abstract virtual string Description();
    public virtual string ToString();
    public abstract virtual bool Equals(object o);
    public abstract virtual int GetHashCode();
}
public class Lucene.Net.Search.Function.ValueSourceQuery : Query {
    internal ValueSource valSrc;
    public ValueSourceQuery(ValueSource valSrc);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual string ToString(string field);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    public virtual object Clone();
}
public class Lucene.Net.Search.FuzzyQuery : MultiTermQuery {
    public static float defaultMinSimilarity;
    public static int defaultPrefixLength;
    private float minimumSimilarity;
    private int prefixLength;
    private bool termLongEnough;
    [CompilerGeneratedAttribute]
private Term <Term>k__BackingField;
    public Term Term { get; protected internal set; }
    public float MinSimilarity { get; }
    public int PrefixLength { get; }
    unknown RewriteMethod RewriteMethod {public set; }
    public FuzzyQuery(Term term, float minimumSimilarity, int prefixLength);
    public FuzzyQuery(Term term, float minimumSimilarity);
    public FuzzyQuery(Term term);
    [CompilerGeneratedAttribute]
public Term get_Term();
    [CompilerGeneratedAttribute]
protected internal void set_Term(Term value);
    public virtual float get_MinSimilarity();
    public virtual int get_PrefixLength();
    protected internal virtual FilteredTermEnum GetEnum(IndexReader reader, IState state);
    public virtual void set_RewriteMethod(RewriteMethod value);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual string ToString(string field);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
public class Lucene.Net.Search.FuzzyTermEnum : FilteredTermEnum {
    private Int32[] p;
    private Int32[] d;
    private float similarity;
    private bool endEnum;
    private bool isDisposed;
    private Term searchTerm;
    private string field;
    private string text;
    private string prefix;
    private float minimumSimilarity;
    private float scale_factor;
    public FuzzyTermEnum(IndexReader reader, Term term, IState state);
    public FuzzyTermEnum(IndexReader reader, Term term, float minSimilarity, IState state);
    public FuzzyTermEnum(IndexReader reader, Term term, float minSimilarity, int prefixLength, IState state);
    protected internal virtual bool TermCompare(Term term);
    public virtual float Difference();
    public virtual bool EndEnum();
    private float Similarity(string target);
    private int CalculateMaxDistance(int m);
    protected virtual void Dispose(bool disposing);
}
public class Lucene.Net.Search.HitQueue : PriorityQueue`1<ScoreDoc> {
    private bool prePopulate;
    protected internal ScoreDoc SentinelObject { get; }
    public HitQueue(int size, bool prePopulate);
    protected internal virtual ScoreDoc get_SentinelObject();
    public virtual bool LessThan(ScoreDoc hitA, ScoreDoc hitB);
}
public class Lucene.Net.Search.IndexSearcher : Searcher {
    internal IndexReader reader;
    private bool closeReader;
    private bool isDisposed;
    private IndexReader[] subReaders;
    private Int32[] docStarts;
    private bool fieldSortDoTrackScores;
    private bool fieldSortDoMaxScore;
    public IndexReader IndexReader { get; }
    public int MaxDoc { get; }
    public IndexReader reader_ForNUnit { get; }
    public IndexSearcher(Directory path, IState state);
    public IndexSearcher(Directory path, bool readOnly, IState state);
    public IndexSearcher(IndexReader r);
    public IndexSearcher(IndexReader reader, IndexReader[] subReaders, Int32[] docStarts);
    private IndexSearcher(IndexReader r, bool closeReader);
    protected internal virtual void GatherSubReaders(IList`1<IndexReader> allSubReaders, IndexReader r);
    public virtual IndexReader get_IndexReader();
    protected virtual void Dispose(bool disposing);
    public virtual int DocFreq(Term term, IState state);
    public virtual Document Doc(int i, IState state);
    public virtual Document Doc(int i, FieldSelector fieldSelector, IState state);
    public virtual int get_MaxDoc();
    public virtual TopDocs Search(Weight weight, Filter filter, int nDocs, IState state);
    public virtual TopFieldDocs Search(Weight weight, Filter filter, int nDocs, Sort sort, IState state);
    public virtual TopFieldDocs Search(Weight weight, Filter filter, int nDocs, Sort sort, bool fillFields, IState state);
    public virtual void Search(Weight weight, Filter filter, Collector collector, IState state);
    private void SearchWithFilter(IndexReader reader, Weight weight, Filter filter, Collector collector, IState state);
    public virtual Query Rewrite(Query original, IState state);
    public virtual Explanation Explain(Weight weight, int doc, IState state);
    public virtual void SetDefaultFieldSortScoring(bool doTrackScores, bool doMaxScore);
    public IndexReader get_reader_ForNUnit();
}
public interface Lucene.Net.Search.IntParser {
    public abstract virtual int ParseInt(string string_Renamed);
}
public class Lucene.Net.Search.LightWeightSimilarity : DefaultSimilarity {
    public static LightWeightSimilarity Instance;
    private static IDFExplanation TheExplanation;
    private static LightWeightSimilarity();
    public virtual IDFExplanation IdfExplain(ICollection`1<Term> terms, Searcher searcher, IState state);
    public virtual IDFExplanation IdfExplain(Term term, Searcher searcher, IState state);
}
public interface Lucene.Net.Search.LongParser {
    public abstract virtual long ParseLong(string string_Renamed);
}
public class Lucene.Net.Search.MatchAllDocsQuery : Query {
    private string normsField;
    public MatchAllDocsQuery(string normsField);
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual string ToString(string field);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.MultiPhraseQuery : Query {
    private string field;
    private List`1<Term[]> termArrays;
    private List`1<int> positions;
    private int slop;
    public int Slop { get; public set; }
    public virtual int get_Slop();
    public virtual void set_Slop(int value);
    public virtual void Add(Term term);
    public virtual void Add(Term[] terms);
    public virtual void Add(Term[] terms, int position);
    public virtual IList`1<Term[]> GetTermArrays();
    public virtual Int32[] GetPositions();
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual string ToString(string f);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    private int TermArraysHashCode();
    private int ArraysHashCode(Term[] termArray);
    private bool TermArraysEquals(List`1<Term[]> termArrays1, List`1<Term[]> termArrays2);
    public static bool TermEquals(Array array1, Array array2);
}
public class Lucene.Net.Search.MultiSearcher : Searcher {
    private Searchable[] searchables;
    private Int32[] starts;
    private int maxDoc;
    private bool isDisposed;
    internal Func`11<ThreadLock, object, Searchable, Weight, Filter, int, HitQueue, int, Int32[], IState, TopDocs> MultiSearcherCallableNoSort;
    internal Func`12<ThreadLock, object, Searchable, Weight, Filter, int, FieldDocSortedHitQueue, Sort, int, Int32[], IState, TopFieldDocs> MultiSearcherCallableWithSort;
    public int MaxDoc { get; }
    public MultiSearcher(Searchable[] searchables);
    public virtual Searchable[] GetSearchables();
    protected internal virtual Int32[] GetStarts();
    protected virtual void Dispose(bool disposing);
    public virtual int DocFreq(Term term, IState state);
    public virtual Document Doc(int n, IState state);
    public virtual Document Doc(int n, FieldSelector fieldSelector, IState state);
    public virtual int SubSearcher(int n);
    public virtual int SubDoc(int n);
    public virtual int get_MaxDoc();
    public virtual TopDocs Search(Weight weight, Filter filter, int nDocs, IState state);
    public virtual TopFieldDocs Search(Weight weight, Filter filter, int n, Sort sort, IState state);
    public virtual void Search(Weight weight, Filter filter, Collector collector, IState state);
    public virtual Query Rewrite(Query original, IState state);
    public virtual Explanation Explain(Weight weight, int doc, IState state);
    public virtual Weight CreateWeight(Query original, IState state);
}
public abstract class Lucene.Net.Search.MultiTermQuery : Query {
    protected internal RewriteMethod internalRewriteMethod;
    internal int numberOfTerms;
    public static RewriteMethod CONSTANT_SCORE_FILTER_REWRITE;
    public static RewriteMethod SCORING_BOOLEAN_QUERY_REWRITE;
    public static RewriteMethod CONSTANT_SCORE_BOOLEAN_QUERY_REWRITE;
    public static RewriteMethod CONSTANT_SCORE_AUTO_REWRITE_DEFAULT;
    public int TotalNumberOfTerms { get; }
    public RewriteMethod RewriteMethod { get; public set; }
    private static MultiTermQuery();
    protected internal abstract virtual FilteredTermEnum GetEnum(IndexReader reader, IState state);
    public virtual int get_TotalNumberOfTerms();
    public virtual void ClearTotalNumberOfTerms();
    protected internal virtual void IncTotalNumberOfTerms(int inc);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual RewriteMethod get_RewriteMethod();
    public virtual void set_RewriteMethod(RewriteMethod value);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
public class Lucene.Net.Search.MultiTermQueryWrapperFilter`1 : Filter {
    protected internal T query;
    public int TotalNumberOfTerms { get; }
    protected internal MultiTermQueryWrapperFilter`1(T query);
    public virtual string ToString();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    public virtual int get_TotalNumberOfTerms();
    public virtual void ClearTotalNumberOfTerms();
    public virtual DocIdSet GetDocIdSet(IndexReader reader, IState state);
}
public static class Lucene.Net.Search.NumericRangeFilter : object {
    public static NumericRangeFilter`1<long> NewLongRange(string field, int precisionStep, Nullable`1<long> min, Nullable`1<long> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeFilter`1<long> NewLongRange(string field, Nullable`1<long> min, Nullable`1<long> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeFilter`1<int> NewIntRange(string field, int precisionStep, Nullable`1<int> min, Nullable`1<int> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeFilter`1<int> NewIntRange(string field, Nullable`1<int> min, Nullable`1<int> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeFilter`1<double> NewDoubleRange(string field, int precisionStep, Nullable`1<double> min, Nullable`1<double> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeFilter`1<double> NewDoubleRange(string field, Nullable`1<double> min, Nullable`1<double> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeFilter`1<float> NewFloatRange(string field, int precisionStep, Nullable`1<float> min, Nullable`1<float> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeFilter`1<float> NewFloatRange(string field, Nullable`1<float> min, Nullable`1<float> max, bool minInclusive, bool maxInclusive);
}
public class Lucene.Net.Search.NumericRangeFilter`1 : MultiTermQueryWrapperFilter`1<NumericRangeQuery`1<T>> {
    public string Field { get; }
    public bool IncludesMin { get; }
    public bool IncludesMax { get; }
    public Nullable`1<T> Min { get; }
    public Nullable`1<T> Max { get; }
    internal NumericRangeFilter`1(NumericRangeQuery`1<T> query);
    public string get_Field();
    public bool get_IncludesMin();
    public bool get_IncludesMax();
    public Nullable`1<T> get_Min();
    public Nullable`1<T> get_Max();
}
public static class Lucene.Net.Search.NumericRangeQuery : object {
    public static NumericRangeQuery`1<long> NewLongRange(string field, int precisionStep, Nullable`1<long> min, Nullable`1<long> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeQuery`1<long> NewLongRange(string field, Nullable`1<long> min, Nullable`1<long> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeQuery`1<int> NewIntRange(string field, int precisionStep, Nullable`1<int> min, Nullable`1<int> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeQuery`1<int> NewIntRange(string field, Nullable`1<int> min, Nullable`1<int> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeQuery`1<double> NewDoubleRange(string field, int precisionStep, Nullable`1<double> min, Nullable`1<double> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeQuery`1<double> NewDoubleRange(string field, Nullable`1<double> min, Nullable`1<double> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeQuery`1<float> NewFloatRange(string field, int precisionStep, Nullable`1<float> min, Nullable`1<float> max, bool minInclusive, bool maxInclusive);
    public static NumericRangeQuery`1<float> NewFloatRange(string field, Nullable`1<float> min, Nullable`1<float> max, bool minInclusive, bool maxInclusive);
}
public class Lucene.Net.Search.NumericRangeQuery`1 : MultiTermQuery {
    internal string field;
    internal int precisionStep;
    internal int valSize;
    internal Nullable`1<T> min;
    internal Nullable`1<T> max;
    internal bool minInclusive;
    internal bool maxInclusive;
    public string Field { get; }
    public bool IncludesMin { get; }
    public bool IncludesMax { get; }
    public Nullable`1<T> Min { get; }
    public Nullable`1<T> Max { get; }
    internal NumericRangeQuery`1(string field, int precisionStep, int valSize, Nullable`1<T> min, Nullable`1<T> max, bool minInclusive, bool maxInclusive);
    protected internal virtual FilteredTermEnum GetEnum(IndexReader reader, IState state);
    public string get_Field();
    public bool get_IncludesMin();
    public bool get_IncludesMax();
    public Nullable`1<T> get_Min();
    public Nullable`1<T> get_Max();
    public virtual string ToString(string field);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    [OnDeserializedAttribute]
internal void OnDeserialized(StreamingContext context);
}
public enum Lucene.Net.Search.Occur : Enum {
    public int value__;
    public static Occur MUST;
    public static Occur SHOULD;
    public static Occur MUST_NOT;
}
[ExtensionAttribute]
public static class Lucene.Net.Search.OccurExtensions : object {
    [ExtensionAttribute]
public static string ToString(Occur occur);
}
public class Lucene.Net.Search.ParallelMultiSearcher : MultiSearcher {
    private Searchable[] searchables;
    private Int32[] starts;
    public ParallelMultiSearcher(Searchable[] searchables);
    public virtual int DocFreq(Term term, IState state);
    public virtual TopDocs Search(Weight weight, Filter filter, int nDocs, IState state);
    public virtual TopFieldDocs Search(Weight weight, Filter filter, int nDocs, Sort sort, IState state);
    public virtual void Search(Weight weight, Filter filter, Collector collector, IState state);
}
public interface Lucene.Net.Search.Parser {
}
public class Lucene.Net.Search.Payloads.AveragePayloadFunction : PayloadFunction {
    public virtual float CurrentScore(int docId, string field, int start, int end, int numPayloadsSeen, float currentScore, float currentPayloadScore);
    public virtual float DocScore(int docId, string field, int numPayloadsSeen, float payloadScore);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
public class Lucene.Net.Search.Payloads.MaxPayloadFunction : PayloadFunction {
    public virtual float CurrentScore(int docId, string field, int start, int end, int numPayloadsSeen, float currentScore, float currentPayloadScore);
    public virtual float DocScore(int docId, string field, int numPayloadsSeen, float payloadScore);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
public class Lucene.Net.Search.Payloads.MinPayloadFunction : PayloadFunction {
    public virtual float CurrentScore(int docId, string field, int start, int end, int numPayloadsSeen, float currentScore, float currentPayloadScore);
    public virtual float DocScore(int docId, string field, int numPayloadsSeen, float payloadScore);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
public abstract class Lucene.Net.Search.Payloads.PayloadFunction : object {
    public abstract virtual float CurrentScore(int docId, string field, int start, int end, int numPayloadsSeen, float currentScore, float currentPayloadScore);
    public abstract virtual float DocScore(int docId, string field, int numPayloadsSeen, float payloadScore);
    public abstract virtual int GetHashCode();
    public abstract virtual bool Equals(object o);
}
public class Lucene.Net.Search.Payloads.PayloadNearQuery : SpanNearQuery {
    protected internal string fieldName;
    protected internal PayloadFunction function;
    public PayloadNearQuery(SpanQuery[] clauses, int slop, bool inOrder);
    public PayloadNearQuery(SpanQuery[] clauses, int slop, bool inOrder, PayloadFunction function);
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual object Clone();
    public virtual string ToString(string field);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
public class Lucene.Net.Search.Payloads.PayloadSpanUtil : object {
    private IndexReader reader;
    public PayloadSpanUtil(IndexReader reader);
    public virtual ICollection`1<Byte[]> GetPayloadsForQuery(Query query, IState state);
    private void QueryToSpanQuery(Query query, ICollection`1<Byte[]> payloads, IState state);
    private void GetPayloads(ICollection`1<Byte[]> payloads, SpanQuery query, IState state);
}
public class Lucene.Net.Search.Payloads.PayloadTermQuery : SpanTermQuery {
    protected internal PayloadFunction function;
    private bool includeSpanScore;
    public PayloadTermQuery(Term term, PayloadFunction function);
    public PayloadTermQuery(Term term, PayloadFunction function, bool includeSpanScore);
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
internal class Lucene.Net.Search.PhrasePositions : object {
    internal int doc;
    internal int position;
    internal int count;
    internal int offset;
    internal TermPositions tp;
    internal PhrasePositions next;
    internal bool repeats;
    internal PhrasePositions(TermPositions t, int o);
    internal bool Next(IState state);
    internal bool SkipTo(int target, IState state);
    internal void FirstPosition(IState state);
    internal bool NextPosition(IState state);
}
public class Lucene.Net.Search.PhraseQuery : Query {
    private string field;
    private EquatableList`1<Term> terms;
    private EquatableList`1<int> positions;
    private int maxPosition;
    private int slop;
    public int Slop { get; public set; }
    public virtual int get_Slop();
    public virtual void set_Slop(int value);
    public virtual void Add(Term term);
    public virtual void Add(Term term, int position);
    public virtual Term[] GetTerms();
    public virtual Int32[] GetPositions();
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual void ExtractTerms(ISet`1<Term> queryTerms);
    public virtual string ToString(string f);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
internal class Lucene.Net.Search.PhraseQueue : PriorityQueue`1<PhrasePositions> {
    internal PhraseQueue(int size);
    public virtual bool LessThan(PhrasePositions pp1, PhrasePositions pp2);
}
internal abstract class Lucene.Net.Search.PhraseScorer : Scorer {
    private Weight weight;
    protected internal Byte[] norms;
    protected internal float value_Renamed;
    private bool firstTime;
    private bool more;
    protected internal PhraseQueue pq;
    protected internal PhrasePositions first;
    protected internal PhrasePositions last;
    private float freq;
    internal PhraseScorer(Weight weight, TermPositions[] tps, Int32[] offsets, Similarity similarity, Byte[] norms);
    public virtual int DocID();
    public virtual int NextDoc(IState state);
    private bool DoNext(IState state);
    public virtual float Score(IState state);
    public virtual int Advance(int target, IState state);
    public float CurrentFreq();
    protected internal abstract virtual float PhraseFreq(IState state);
    private void Init(IState state);
    private void Sort();
    protected internal void PqToList();
    protected internal void FirstToLast();
    public virtual string ToString();
}
public class Lucene.Net.Search.PositiveScoresOnlyCollector : Collector {
    private Collector c;
    private Scorer scorer;
    public bool AcceptsDocsOutOfOrder { get; }
    public PositiveScoresOnlyCollector(Collector c);
    public virtual void Collect(int doc, IState state);
    public virtual void SetNextReader(IndexReader reader, int docBase, IState state);
    public virtual void SetScorer(Scorer scorer);
    public virtual bool get_AcceptsDocsOutOfOrder();
}
public class Lucene.Net.Search.PrefixFilter : MultiTermQueryWrapperFilter`1<PrefixQuery> {
    public Term Prefix { get; }
    public PrefixFilter(Term prefix);
    public virtual Term get_Prefix();
    public virtual string ToString();
}
public class Lucene.Net.Search.PrefixQuery : MultiTermQuery {
    private Term prefix;
    public Term Prefix { get; }
    public PrefixQuery(Term prefix);
    public virtual Term get_Prefix();
    protected internal virtual FilteredTermEnum GetEnum(IndexReader reader, IState state);
    public virtual string ToString(string field);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
public class Lucene.Net.Search.PrefixTermEnum : FilteredTermEnum {
    private Term prefix;
    private bool endEnum;
    protected internal Term PrefixTerm { get; }
    public PrefixTermEnum(IndexReader reader, Term prefix, IState state);
    public virtual float Difference();
    public virtual bool EndEnum();
    protected internal virtual Term get_PrefixTerm();
    protected internal virtual bool TermCompare(Term term);
}
public abstract class Lucene.Net.Search.Query : object {
    private float boost;
    public float Boost { get; public set; }
    public virtual float get_Boost();
    public virtual void set_Boost(float value);
    public abstract virtual string ToString(string field);
    public virtual string ToString();
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual Weight Weight(Searcher searcher, IState state);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual Query Combine(Query[] queries);
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public static Query MergeBooleanQueries(BooleanQuery[] queries);
    public virtual Similarity GetSimilarity(Searcher searcher);
    public virtual object Clone();
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
public class Lucene.Net.Search.QueryTermVector : object {
    private String[] terms;
    private Int32[] termFreqs;
    public string Field { get; }
    public int Size { get; }
    public QueryTermVector(String[] queryTerms);
    public QueryTermVector(string queryString, Analyzer analyzer);
    public virtual string get_Field();
    private void ProcessTerms(String[] queryTerms);
    public virtual string ToString();
    public virtual int get_Size();
    public virtual String[] GetTerms();
    public virtual Int32[] GetTermFrequencies();
    public virtual int IndexOf(string term);
    public virtual Int32[] IndexesOf(String[] terms, int start, int len);
}
public class Lucene.Net.Search.QueryWrapperFilter : Filter {
    private Query query;
    public QueryWrapperFilter(Query query);
    public virtual DocIdSet GetDocIdSet(IndexReader reader, IState state);
    public virtual string ToString();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
internal class Lucene.Net.Search.ReqExclScorer : Scorer {
    private Scorer reqScorer;
    private DocIdSetIterator exclDisi;
    private int doc;
    public ReqExclScorer(Scorer reqScorer, DocIdSetIterator exclDisi);
    public virtual int NextDoc(IState state);
    private int ToNonExcluded(IState state);
    public virtual int DocID();
    public virtual float Score(IState state);
    public virtual int Advance(int target, IState state);
}
internal class Lucene.Net.Search.ReqOptSumScorer : Scorer {
    private Scorer reqScorer;
    private Scorer optScorer;
    public ReqOptSumScorer(Scorer reqScorer, Scorer optScorer);
    public virtual int NextDoc(IState state);
    public virtual int Advance(int target, IState state);
    public virtual int DocID();
    public virtual float Score(IState state);
}
public abstract class Lucene.Net.Search.RewriteMethod : object {
    public abstract virtual Query Rewrite(IndexReader reader, MultiTermQuery query, IState state);
}
public class Lucene.Net.Search.ScoreCachingWrappingScorer : Scorer {
    private Scorer scorer;
    private int curDoc;
    private float curScore;
    public Similarity Similarity { get; }
    public ScoreCachingWrappingScorer(Scorer scorer);
    public virtual bool Score(Collector collector, int max, int firstDocID, IState state);
    public virtual Similarity get_Similarity();
    public virtual float Score(IState state);
    public virtual int DocID();
    public virtual int NextDoc(IState state);
    public virtual void Score(Collector collector, IState state);
    public virtual int Advance(int target, IState state);
}
public class Lucene.Net.Search.ScoreDoc : object {
    [CompilerGeneratedAttribute]
private float <Score>k__BackingField;
    [CompilerGeneratedAttribute]
private int <Doc>k__BackingField;
    public float Score { get; public set; }
    public int Doc { get; public set; }
    public ScoreDoc(int doc, float score);
    [CompilerGeneratedAttribute]
public float get_Score();
    [CompilerGeneratedAttribute]
public void set_Score(float value);
    [CompilerGeneratedAttribute]
public int get_Doc();
    [CompilerGeneratedAttribute]
public void set_Doc(int value);
    public virtual string ToString();
}
public abstract class Lucene.Net.Search.Scorer : DocIdSetIterator {
    private Similarity similarity;
    public Similarity Similarity { get; }
    protected internal Scorer(Similarity similarity);
    public virtual Similarity get_Similarity();
    public virtual void Score(Collector collector, IState state);
    public virtual bool Score(Collector collector, int max, int firstDocID, IState state);
    public abstract virtual float Score(IState state);
}
public interface Lucene.Net.Search.Searchable {
    public int MaxDoc { get; }
    public abstract virtual void Search(Weight weight, Filter filter, Collector collector, IState state);
    public abstract virtual void Close();
    public abstract virtual int DocFreq(Term term, IState state);
    public abstract virtual Int32[] DocFreqs(Term[] terms, IState state);
    public abstract virtual int get_MaxDoc();
    public abstract virtual TopDocs Search(Weight weight, Filter filter, int n, IState state);
    public abstract virtual Document Doc(int i, IState state);
    public abstract virtual Document Doc(int n, FieldSelector fieldSelector, IState state);
    public abstract virtual Query Rewrite(Query query, IState state);
    public abstract virtual Explanation Explain(Weight weight, int doc, IState state);
    public abstract virtual TopFieldDocs Search(Weight weight, Filter filter, int n, Sort sort, IState state);
}
public abstract class Lucene.Net.Search.Searcher : MarshalByRefObject {
    private Similarity similarity;
    [ThreadStaticAttribute]
protected static bool usingLightWeightSimilarity;
    public Similarity Similarity { get; public set; }
    public int MaxDoc { get; }
    private void InitBlock();
    public virtual TopFieldDocs Search(Query query, Filter filter, int n, Sort sort, IState state);
    public virtual void Search(Query query, Collector results, IState state);
    public virtual void Search(Query query, Filter filter, Collector results, IState state);
    public virtual TopDocs Search(Query query, Filter filter, int n, IState state);
    public virtual TopDocs Search(Query query, int n, IState state);
    public virtual Explanation Explain(Query query, int doc, IState state);
    public virtual Similarity get_Similarity();
    public virtual void set_Similarity(Similarity value);
    public static LightWeightSimilarityScope EnableLightWeightSimilarity();
    public virtual Weight CreateWeight(Query query, IState state);
    public virtual Int32[] DocFreqs(Term[] terms, IState state);
    public abstract virtual void Search(Weight weight, Filter filter, Collector results, IState state);
    [ObsoleteAttribute("Use Dispose() instead")]
public sealed virtual void Close();
    public sealed virtual void Dispose();
    protected abstract virtual void Dispose(bool disposing);
    public abstract virtual int DocFreq(Term term, IState state);
    public abstract virtual int get_MaxDoc();
    public abstract virtual TopDocs Search(Weight weight, Filter filter, int n, IState state);
    public abstract virtual Document Doc(int i, IState state);
    public abstract virtual Document Doc(int docid, FieldSelector fieldSelector, IState state);
    public abstract virtual Query Rewrite(Query query, IState state);
    public abstract virtual Explanation Explain(Weight weight, int doc, IState state);
    public abstract virtual TopFieldDocs Search(Weight weight, Filter filter, int n, Sort sort, IState state);
}
public interface Lucene.Net.Search.ShortParser {
    public abstract virtual short ParseShort(string string_Renamed);
}
public abstract class Lucene.Net.Search.Similarity : object {
    private static Similarity defaultImpl;
    public static int NO_DOC_ID_PROVIDED;
    private static Single[] NORM_TABLE;
    public static Similarity Default { get; public set; }
    private static Similarity();
    private void InitBlock();
    public static Similarity get_Default();
    public static void set_Default(Similarity value);
    public static float DecodeNorm(byte b);
    public static Single[] GetNormDecoder();
    public virtual float ComputeNorm(string field, FieldInvertState state);
    public abstract virtual float LengthNorm(string fieldName, int numTokens);
    public abstract virtual float QueryNorm(float sumOfSquaredWeights);
    public static byte EncodeNorm(float f);
    public virtual float Tf(int freq);
    public abstract virtual float SloppyFreq(int distance);
    public abstract virtual float Tf(float freq);
    public virtual IDFExplanation IdfExplain(Term term, Searcher searcher, IState state);
    public virtual IDFExplanation IdfExplain(ICollection`1<Term> terms, Searcher searcher, IState state);
    public abstract virtual float Idf(int docFreq, int numDocs);
    public abstract virtual float Coord(int overlap, int maxOverlap);
    public virtual float ScorePayload(int docId, string fieldName, int start, int end, Byte[] payload, int offset, int length);
}
public class Lucene.Net.Search.SimilarityDelegator : Similarity {
    private Similarity delegee;
    public SimilarityDelegator(Similarity delegee);
    public virtual float ComputeNorm(string fieldName, FieldInvertState state);
    public virtual float LengthNorm(string fieldName, int numTerms);
    public virtual float QueryNorm(float sumOfSquaredWeights);
    public virtual float Tf(float freq);
    public virtual float SloppyFreq(int distance);
    public virtual float Idf(int docFreq, int numDocs);
    public virtual float Coord(int overlap, int maxOverlap);
    public virtual float ScorePayload(int docId, string fieldName, int start, int end, Byte[] payload, int offset, int length);
}
public class Lucene.Net.Search.SingleTermEnum : FilteredTermEnum {
    private Term singleTerm;
    private bool _endEnum;
    public SingleTermEnum(IndexReader reader, Term singleTerm, IState state);
    public virtual float Difference();
    public virtual bool EndEnum();
    protected internal virtual bool TermCompare(Term term);
}
internal class Lucene.Net.Search.SloppyPhraseScorer : PhraseScorer {
    private int slop;
    private PhrasePositions[] repeats;
    private PhrasePositions[] tmpPos;
    private bool checkedRepeats;
    internal SloppyPhraseScorer(Weight weight, TermPositions[] tps, Int32[] offsets, Similarity similarity, int slop, Byte[] norms);
    protected internal virtual float PhraseFreq(IState state);
    private PhrasePositions Flip(PhrasePositions pp, PhrasePositions pp2);
    private int InitPhrasePositions(IState state);
    private PhrasePositions TermPositionsDiffer(PhrasePositions pp);
}
public class Lucene.Net.Search.Sort : object {
    public static Sort RELEVANCE;
    public static Sort INDEXORDER;
    internal ArraySegment`1<SortField> fields;
    public Sort(SortField field);
    public Sort(SortField[] fields);
    public Sort(ArraySegment`1<SortField> fields);
    private static Sort();
    public virtual void SetSort(SortField field);
    public virtual void SetSort(SortField[] fields);
    public virtual void SetSort(ArraySegment`1<SortField> fields);
    public virtual ArraySegment`1<SortField> GetSort();
    public virtual string ToString();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.SortField : object {
    public static int SCORE;
    public static int DOC;
    public static int STRING;
    public static int INT;
    public static int FLOAT;
    public static int LONG;
    public static int DOUBLE;
    public static int SHORT;
    public static int CUSTOM;
    public static int BYTE;
    public static int STRING_VAL;
    public static SortField FIELD_SCORE;
    public static SortField FIELD_DOC;
    private string field;
    private int type;
    private CultureInfo locale;
    internal bool reverse;
    private Parser parser;
    private FieldComparatorSource comparatorSource;
    public string Field { get; }
    public int Type { get; }
    public CultureInfo Locale { get; }
    public Parser Parser { get; }
    public bool Reverse { get; }
    public FieldComparatorSource ComparatorSource { get; }
    public SortField(string field, int type);
    public SortField(string field, int type, bool reverse);
    public SortField(string field, Parser parser);
    public SortField(string field, Parser parser, bool reverse);
    public SortField(string field, CultureInfo locale);
    public SortField(string field, CultureInfo locale, bool reverse);
    public SortField(string field, FieldComparatorSource comparator);
    public SortField(string field, FieldComparatorSource comparator, bool reverse);
    private static SortField();
    private void InitFieldType(string field, int type);
    public virtual string get_Field();
    public virtual int get_Type();
    public virtual CultureInfo get_Locale();
    public virtual Parser get_Parser();
    public virtual bool get_Reverse();
    public virtual FieldComparatorSource get_ComparatorSource();
    public virtual string ToString();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    [OnDeserializedAttribute]
internal void OnDeserialized(StreamingContext context);
    public virtual FieldComparator GetComparator(int numHits, int sortPos);
}
public abstract class Lucene.Net.Search.SpanFilter : Filter {
    public abstract virtual SpanFilterResult BitSpans(IndexReader reader, IState state);
}
public class Lucene.Net.Search.SpanFilterResult : object {
    private DocIdSet docIdSet;
    private IList`1<PositionInfo> positions;
    public IList`1<PositionInfo> Positions { get; }
    public DocIdSet DocIdSet { get; }
    public SpanFilterResult(DocIdSet docIdSet, IList`1<PositionInfo> positions);
    public virtual IList`1<PositionInfo> get_Positions();
    public virtual DocIdSet get_DocIdSet();
}
public class Lucene.Net.Search.SpanQueryFilter : SpanFilter {
    protected internal SpanQuery internalQuery;
    public SpanQuery Query { get; }
    public SpanQueryFilter(SpanQuery query);
    public virtual DocIdSet GetDocIdSet(IndexReader reader, IState state);
    public virtual SpanFilterResult BitSpans(IndexReader reader, IState state);
    public virtual SpanQuery get_Query();
    public virtual string ToString();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.Spans.FieldMaskingSpanQuery : SpanQuery {
    private SpanQuery maskedQuery;
    private string field;
    public string Field { get; }
    public SpanQuery MaskedQuery { get; }
    public FieldMaskingSpanQuery(SpanQuery maskedQuery, string maskedField);
    public virtual string get_Field();
    public virtual SpanQuery get_MaskedQuery();
    public virtual Spans GetSpans(IndexReader reader, IState state);
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual Similarity GetSimilarity(Searcher searcher);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual string ToString(string field);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.Spans.NearSpansOrdered : Spans {
    private int allowedSlop;
    private bool firstTime;
    private bool more;
    private Spans[] subSpans;
    private bool inSameDoc;
    private int matchDoc;
    private int matchStart;
    private int matchEnd;
    private List`1<Byte[]> matchPayload;
    private Spans[] subSpansByDoc;
    private IComparer spanDocComparator;
    private SpanNearQuery query;
    private bool collectPayloads;
    public NearSpansOrdered(SpanNearQuery spanNearQuery, IndexReader reader, IState state);
    public NearSpansOrdered(SpanNearQuery spanNearQuery, IndexReader reader, bool collectPayloads, IState state);
    private void InitBlock();
    public virtual int Doc();
    public virtual int Start();
    public virtual int End();
    public virtual Spans[] GetSubSpans();
    public virtual ICollection`1<Byte[]> GetPayload(IState state);
    public virtual bool IsPayloadAvailable();
    public virtual bool Next(IState state);
    public virtual bool SkipTo(int target, IState state);
    private bool AdvanceAfterOrdered(IState state);
    private bool ToSameDoc(IState state);
    internal static bool DocSpansOrdered(Spans spans1, Spans spans2);
    private static bool DocSpansOrdered(int start1, int end1, int start2, int end2);
    private bool StretchToOrder(IState state);
    private bool ShrinkToAfterShortestMatch(IState state);
    public virtual string ToString();
}
public class Lucene.Net.Search.Spans.NearSpansUnordered : Spans {
    private SpanNearQuery query;
    private IList`1<SpansCell> ordered;
    private Spans[] subSpans;
    private int slop;
    private SpansCell first;
    private SpansCell last;
    private int totalLength;
    private CellQueue queue;
    private SpansCell max;
    private bool more;
    private bool firstTime;
    public NearSpansUnordered(SpanNearQuery query, IndexReader reader, IState state);
    public virtual Spans[] GetSubSpans();
    public virtual bool Next(IState state);
    public virtual bool SkipTo(int target, IState state);
    private SpansCell Min();
    public virtual int Doc();
    public virtual int Start();
    public virtual int End();
    public virtual ICollection`1<Byte[]> GetPayload(IState state);
    public virtual bool IsPayloadAvailable();
    public virtual string ToString();
    private void InitList(bool next, IState state);
    private void AddToList(SpansCell cell);
    private void FirstToLast();
    private void QueueToList();
    private void ListToQueue();
    private bool AtMatch();
}
public class Lucene.Net.Search.Spans.SpanFirstQuery : SpanQuery {
    private SpanQuery match;
    private int end;
    public SpanQuery Match { get; }
    public int End { get; }
    public string Field { get; }
    public SpanFirstQuery(SpanQuery match, int end);
    public virtual SpanQuery get_Match();
    public virtual int get_End();
    public virtual string get_Field();
    public virtual string ToString(string field);
    public virtual object Clone();
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual Spans GetSpans(IndexReader reader, IState state);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.Spans.SpanNearQuery : SpanQuery {
    protected internal IList`1<SpanQuery> clauses;
    protected internal int internalSlop;
    protected internal bool inOrder;
    protected internal string internalField;
    private bool collectPayloads;
    public int Slop { get; }
    public bool IsInOrder { get; }
    public string Field { get; }
    public SpanNearQuery(SpanQuery[] clauses, int slop, bool inOrder);
    public SpanNearQuery(SpanQuery[] clauses, int slop, bool inOrder, bool collectPayloads);
    public virtual SpanQuery[] GetClauses();
    public virtual int get_Slop();
    public virtual bool get_IsInOrder();
    public virtual string get_Field();
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual string ToString(string field);
    public virtual Spans GetSpans(IndexReader reader, IState state);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual object Clone();
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.Spans.SpanNotQuery : SpanQuery {
    private SpanQuery include;
    private SpanQuery exclude;
    public SpanQuery Include { get; }
    public SpanQuery Exclude { get; }
    public string Field { get; }
    public SpanNotQuery(SpanQuery include, SpanQuery exclude);
    public virtual SpanQuery get_Include();
    public virtual SpanQuery get_Exclude();
    public virtual string get_Field();
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual string ToString(string field);
    public virtual object Clone();
    public virtual Spans GetSpans(IndexReader reader, IState state);
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.Spans.SpanOrQuery : SpanQuery {
    private EquatableList`1<SpanQuery> clauses;
    private string field;
    public string Field { get; }
    public SpanOrQuery(SpanQuery[] clauses);
    public virtual SpanQuery[] GetClauses();
    public virtual string get_Field();
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual object Clone();
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual string ToString(string field);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
    public virtual Spans GetSpans(IndexReader reader, IState state);
}
public abstract class Lucene.Net.Search.Spans.SpanQuery : Query {
    public string Field { get; }
    public abstract virtual Spans GetSpans(IndexReader reader, IState state);
    public abstract virtual string get_Field();
    public virtual Weight CreateWeight(Searcher searcher, IState state);
}
public abstract class Lucene.Net.Search.Spans.Spans : object {
    public abstract virtual bool Next(IState state);
    public abstract virtual bool SkipTo(int target, IState state);
    public abstract virtual int Doc();
    public abstract virtual int Start();
    public abstract virtual int End();
    public abstract virtual ICollection`1<Byte[]> GetPayload(IState state);
    public abstract virtual bool IsPayloadAvailable();
}
public class Lucene.Net.Search.Spans.SpanScorer : Scorer {
    protected internal Spans spans;
    protected internal Weight weight;
    protected internal Byte[] norms;
    protected internal float value_Renamed;
    protected internal bool more;
    protected internal int doc;
    protected internal float freq;
    protected internal SpanScorer(Spans spans, Weight weight, Similarity similarity, Byte[] norms, IState state);
    public virtual int NextDoc(IState state);
    public virtual int Advance(int target, IState state);
    public virtual bool SetFreqCurrentDoc(IState state);
    public virtual int DocID();
    public virtual float Score(IState state);
    protected internal virtual Explanation Explain(int doc, IState state);
}
public class Lucene.Net.Search.Spans.SpanTermQuery : SpanQuery {
    protected internal Term internalTerm;
    public Term Term { get; }
    public string Field { get; }
    public SpanTermQuery(Term term);
    public virtual Term get_Term();
    public virtual string get_Field();
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual string ToString(string field);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
    public virtual Spans GetSpans(IndexReader reader, IState state);
}
public class Lucene.Net.Search.Spans.SpanWeight : Weight {
    protected internal Similarity similarity;
    protected internal float value_Renamed;
    protected internal float idf;
    protected internal float queryNorm;
    protected internal float queryWeight;
    protected internal ISet`1<Term> terms;
    protected internal SpanQuery internalQuery;
    private IDFExplanation idfExp;
    public Query Query { get; }
    public float Value { get; }
    public SpanWeight(SpanQuery query, Searcher searcher, IState state);
    public virtual Query get_Query();
    public virtual float get_Value();
    public virtual float GetSumOfSquaredWeights();
    public virtual void Normalize(float queryNorm);
    public virtual Scorer Scorer(IndexReader reader, bool scoreDocsInOrder, bool topScorer, IState state);
    public virtual Explanation Explain(IndexReader reader, int doc, IState state);
}
public class Lucene.Net.Search.Spans.TermSpans : Spans {
    protected internal TermPositions internalPositions;
    protected internal Term term;
    protected internal int internalDoc;
    protected internal int freq;
    protected internal int count;
    protected internal int position;
    public TermPositions Positions { get; }
    public TermSpans(TermPositions positions, Term term);
    public virtual bool Next(IState state);
    public virtual bool SkipTo(int target, IState state);
    public virtual int Doc();
    public virtual int Start();
    public virtual int End();
    public virtual ICollection`1<Byte[]> GetPayload(IState state);
    public virtual bool IsPayloadAvailable();
    public virtual string ToString();
    public virtual TermPositions get_Positions();
}
public class Lucene.Net.Search.StringIndex : object {
    public UnmanagedStringArray lookup;
    public Int32[] order;
    public Int32[] reverseOrder;
    public StringIndex(Int32[] values, Int32[] reverseOrder, UnmanagedStringArray lookup);
    public virtual int BinarySearchLookup(string key);
}
public class Lucene.Net.Search.TermQuery : Query {
    private Term term;
    public Term Term { get; }
    public TermQuery(Term t);
    public virtual Term get_Term();
    public virtual Weight CreateWeight(Searcher searcher, IState state);
    public virtual void ExtractTerms(ISet`1<Term> terms);
    public virtual string ToString(string field);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Search.TermRangeFilter : MultiTermQueryWrapperFilter`1<TermRangeQuery> {
    public string Field { get; }
    public string LowerTerm { get; }
    public string UpperTerm { get; }
    public bool IncludesLower { get; }
    public bool IncludesUpper { get; }
    public CompareInfo Collator { get; }
    public TermRangeFilter(string fieldName, string lowerTerm, string upperTerm, bool includeLower, bool includeUpper);
    public TermRangeFilter(string fieldName, string lowerTerm, string upperTerm, bool includeLower, bool includeUpper, CompareInfo collator);
    public static TermRangeFilter Less(string fieldName, string upperTerm);
    public static TermRangeFilter More(string fieldName, string lowerTerm);
    public virtual string get_Field();
    public virtual string get_LowerTerm();
    public virtual string get_UpperTerm();
    public virtual bool get_IncludesLower();
    public virtual bool get_IncludesUpper();
    public virtual CompareInfo get_Collator();
}
public class Lucene.Net.Search.TermRangeQuery : MultiTermQuery {
    private string lowerTerm;
    private string upperTerm;
    private CompareInfo collator;
    private string field;
    private bool includeLower;
    private bool includeUpper;
    public string Field { get; }
    public string LowerTerm { get; }
    public string UpperTerm { get; }
    public bool IncludesLower { get; }
    public bool IncludesUpper { get; }
    public CompareInfo Collator { get; }
    public TermRangeQuery(string field, string lowerTerm, string upperTerm, bool includeLower, bool includeUpper);
    public TermRangeQuery(string field, string lowerTerm, string upperTerm, bool includeLower, bool includeUpper, CompareInfo collator);
    public virtual string get_Field();
    public virtual string get_LowerTerm();
    public virtual string get_UpperTerm();
    public virtual bool get_IncludesLower();
    public virtual bool get_IncludesUpper();
    public virtual CompareInfo get_Collator();
    protected internal virtual FilteredTermEnum GetEnum(IndexReader reader, IState state);
    public virtual string ToString(string field);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
public class Lucene.Net.Search.TermRangeTermEnum : FilteredTermEnum {
    private CompareInfo collator;
    private bool endEnum;
    private string field;
    private string upperTermText;
    private string lowerTermText;
    private bool includeLower;
    private bool includeUpper;
    public TermRangeTermEnum(IndexReader reader, string field, string lowerTermText, string upperTermText, bool includeLower, bool includeUpper, CompareInfo collator, IState state);
    public virtual float Difference();
    public virtual bool EndEnum();
    protected internal virtual bool TermCompare(Term term);
}
public class Lucene.Net.Search.TermScorer : Scorer {
    private static Single[] SIM_NORM_DECODER;
    private Weight weight;
    private TermDocs termDocs;
    private Byte[] norms;
    private float weightValue;
    private int doc;
    private Int32[] docs;
    private Int32[] freqs;
    private int pointer;
    private int pointerMax;
    private static int SCORE_CACHE_SIZE;
    private Single[] scoreCache;
    public TermScorer(Weight weight, TermDocs td, Similarity similarity, Byte[] norms);
    private static TermScorer();
    public virtual void Score(Collector c, IState state);
    public virtual bool Score(Collector c, int end, int firstDocID, IState state);
    public virtual int DocID();
    public virtual int NextDoc(IState state);
    public virtual float Score(IState state);
    public virtual int Advance(int target, IState state);
    public virtual string ToString();
}
public class Lucene.Net.Search.TimeLimitingCollector : Collector {
    public static int DEFAULT_RESOLUTION;
    public bool DEFAULT_GREEDY;
    private static UInt32 resolution;
    private bool greedy;
    private static TimerThread TIMER_THREAD;
    private long t0;
    private long timeout;
    private Collector collector;
    private int docBase;
    public static long Resolution { get; public set; }
    public bool IsGreedy { get; public set; }
    public bool AcceptsDocsOutOfOrder { get; }
    public TimeLimitingCollector(Collector collector, long timeAllowed);
    private static TimeLimitingCollector();
    private void InitBlock();
    public static long get_Resolution();
    public static void set_Resolution(long value);
    public virtual bool get_IsGreedy();
    public virtual void set_IsGreedy(bool value);
    public virtual void Collect(int doc, IState state);
    public virtual void SetNextReader(IndexReader reader, int base_Renamed, IState state);
    public virtual void SetScorer(Scorer scorer);
    public virtual bool get_AcceptsDocsOutOfOrder();
}
public class Lucene.Net.Search.TopDocs : object {
    private int _totalHits;
    private ScoreDoc[] _scoreDocs;
    private float _maxScore;
    public int TotalHits { get; public set; }
    public ScoreDoc[] ScoreDocs { get; public set; }
    public float MaxScore { get; public set; }
    internal TopDocs(int totalHits, ScoreDoc[] scoreDocs);
    public TopDocs(int totalHits, ScoreDoc[] scoreDocs, float maxScore);
    public int get_TotalHits();
    public void set_TotalHits(int value);
    public ScoreDoc[] get_ScoreDocs();
    public void set_ScoreDocs(ScoreDoc[] value);
    public float get_MaxScore();
    public void set_MaxScore(float value);
}
public abstract class Lucene.Net.Search.TopDocsCollector`1 : Collector {
    protected internal static TopDocs EMPTY_TOPDOCS;
    protected internal PriorityQueue`1<T> pq;
    protected internal int internalTotalHits;
    public int TotalHits { get; }
    protected internal TopDocsCollector`1(PriorityQueue`1<T> pq);
    private static TopDocsCollector`1();
    protected internal virtual void PopulateResults(ScoreDoc[] results, int howMany);
    public virtual TopDocs NewTopDocs(ScoreDoc[] results, int start);
    public virtual int get_TotalHits();
    public TopDocs TopDocs();
    public TopDocs TopDocs(int start);
    public TopDocs TopDocs(int start, int howMany);
}
public abstract class Lucene.Net.Search.TopFieldCollector : TopDocsCollector`1<Entry> {
    private static ScoreDoc[] EMPTY_SCOREDOCS;
    private bool fillFields;
    internal float maxScore;
    internal int numHits;
    internal Entry bottom;
    internal bool queueFull;
    internal int docBase;
    public bool AcceptsDocsOutOfOrder { get; }
    private TopFieldCollector(PriorityQueue`1<Entry> pq, int numHits, bool fillFields);
    private static TopFieldCollector();
    public static TopFieldCollector Create(Sort sort, int numHits, bool fillFields, bool trackDocScores, bool trackMaxScore, bool docsScoredInOrder);
    internal void Add(int slot, int doc, float score);
    protected internal virtual void PopulateResults(ScoreDoc[] results, int howMany);
    public virtual TopDocs NewTopDocs(ScoreDoc[] results, int start);
    public virtual bool get_AcceptsDocsOutOfOrder();
}
public class Lucene.Net.Search.TopFieldDocs : TopDocs {
    public ArraySegment`1<SortField> fields;
    public TopFieldDocs(int totalHits, ScoreDoc[] scoreDocs, ArraySegment`1<SortField> fields, float maxScore);
}
public abstract class Lucene.Net.Search.TopScoreDocCollector : TopDocsCollector`1<ScoreDoc> {
    internal ScoreDoc pqTop;
    internal int docBase;
    internal Scorer scorer;
    private TopScoreDocCollector(int numHits);
    public static TopScoreDocCollector Create(int numHits, bool docsScoredInOrder);
    public virtual TopDocs NewTopDocs(ScoreDoc[] results, int start);
    public virtual void SetNextReader(IndexReader reader, int base_Renamed, IState state);
    public virtual void SetScorer(Scorer scorer);
}
public abstract class Lucene.Net.Search.Weight : object {
    public Query Query { get; }
    public float Value { get; }
    public abstract virtual Explanation Explain(IndexReader reader, int doc, IState state);
    public abstract virtual Query get_Query();
    public abstract virtual float get_Value();
    public abstract virtual void Normalize(float norm);
    public abstract virtual Scorer Scorer(IndexReader reader, bool scoreDocsInOrder, bool topScorer, IState state);
    public abstract virtual float GetSumOfSquaredWeights();
    public virtual bool GetScoresDocsOutOfOrder();
}
public class Lucene.Net.Search.WildcardQuery : MultiTermQuery {
    private bool _termContainsWildcard;
    private bool _termIsPrefix;
    protected internal Term internalTerm;
    public Term Term { get; }
    public WildcardQuery(Term term);
    protected internal virtual FilteredTermEnum GetEnum(IndexReader reader, IState state);
    public Term get_Term();
    public virtual Query Rewrite(IndexReader reader, IState state);
    public virtual string ToString(string field);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
}
public class Lucene.Net.Search.WildcardTermEnum : FilteredTermEnum {
    internal Term searchTerm;
    internal string field;
    internal string text;
    internal string pre;
    internal int preLen;
    internal bool endEnum;
    public static char WILDCARD_STRING;
    public static char WILDCARD_CHAR;
    public WildcardTermEnum(IndexReader reader, Term term, IState state);
    protected internal virtual bool TermCompare(Term term);
    public virtual float Difference();
    public virtual bool EndEnum();
    public static bool WildcardEquals(string pattern, int patternIdx, string string_Renamed, int stringIdx);
}
public class Lucene.Net.Store.AlreadyClosedException : SystemException {
    public AlreadyClosedException(string message);
    public AlreadyClosedException(string message, Exception inner);
    protected AlreadyClosedException(SerializationInfo info, StreamingContext context);
}
public abstract class Lucene.Net.Store.BufferedIndexInput : IndexInput {
    public static int BUFFER_SIZE;
    private int _bufferSize;
    protected internal Byte[] buffer;
    protected long bufferStart;
    protected int bufferLength;
    protected int bufferPosition;
    public int BufferSize { get; }
    protected BufferedIndexInput(int bufferSize);
    public virtual byte ReadByte(IState state);
    public virtual void SetBufferSize(int newSize);
    protected virtual void NewBuffer(int newBufferSize);
    public virtual int get_BufferSize();
    private void CheckBufferSize(int bufferSize);
    public virtual void ReadBytes(Byte[] b, int offset, int len, IState state);
    public virtual void ReadBytes(Byte[] b, int offset, int len, bool useBuffer, IState state);
    protected void Refill(IState state);
    public abstract virtual void ReadInternal(Byte[] b, int offset, int length, IState state);
    public virtual long FilePointer(IState state);
    public virtual void Seek(long pos, IState state);
    public abstract virtual void SeekInternal(long pos, IState state);
    public virtual object Clone(IState state);
}
public abstract class Lucene.Net.Store.BufferedIndexOutput : IndexOutput {
    internal static int BUFFER_SIZE;
    private Byte[] buffer;
    private long bufferStart;
    private int bufferPosition;
    private bool isDisposed;
    public long FilePointer { get; }
    public long Length { get; }
    public virtual void WriteByte(byte b);
    public virtual void WriteBytes(Byte[] b, int offset, int length);
    public virtual void Flush();
    private void FlushBuffer(Byte[] b, int len);
    public abstract virtual void FlushBuffer(Byte[] b, int offset, int len);
    protected virtual void Dispose(bool disposing);
    public virtual long get_FilePointer();
    public virtual void Seek(long pos);
    public abstract virtual long get_Length();
}
public class Lucene.Net.Store.ChecksumIndexInput : IndexInput {
    internal IndexInput main;
    internal IChecksum digest;
    private bool isDisposed;
    public long Checksum { get; }
    public ChecksumIndexInput(IndexInput main);
    public virtual byte ReadByte(IState state);
    public virtual void ReadBytes(Byte[] b, int offset, int len, IState state);
    public virtual long get_Checksum();
    protected virtual void Dispose(bool disposing);
    public virtual long FilePointer(IState state);
    public virtual void Seek(long pos, IState state);
    public virtual long Length(IState state);
}
public class Lucene.Net.Store.ChecksumIndexOutput : IndexOutput {
    internal IndexOutput main;
    internal IChecksum digest;
    private bool isDisposed;
    public long Checksum { get; }
    public long FilePointer { get; }
    public long Length { get; }
    public ChecksumIndexOutput(IndexOutput main);
    public virtual void WriteByte(byte b);
    public virtual void WriteBytes(Byte[] b, int offset, int length);
    public virtual long get_Checksum();
    public virtual void Flush();
    protected virtual void Dispose(bool disposing);
    public virtual long get_FilePointer();
    public virtual void Seek(long pos);
    public virtual void PrepareCommit();
    public virtual void FinishCommit();
    public virtual long get_Length();
}
public abstract class Lucene.Net.Store.Directory : object {
    private ConcurrentDictionary`2<string, Lazy`1<ArrayHolder>> _termsIndexCachePerSegment;
    protected internal Boolean modreq(System.Runtime.CompilerServices.IsVolatile) isOpen;
    protected internal LockFactory interalLockFactory;
    internal ArrayPool`1<byte> ByteBlockPool;
    public LockFactory LockFactory { get; }
    public bool isOpen_ForNUnit { get; }
    public abstract virtual String[] ListAll(IState state);
    public abstract virtual bool FileExists(string name, IState state);
    public abstract virtual long FileModified(string name, IState state);
    public abstract virtual void TouchFile(string name, IState state);
    public abstract virtual void DeleteFile(string name, IState state);
    public abstract virtual long FileLength(string name, IState state);
    public abstract virtual IndexOutput CreateOutput(string name, IState state);
    public virtual void Sync(string name);
    public abstract virtual IndexInput OpenInput(string name, IState state);
    public virtual IndexInput OpenInput(string name, int bufferSize, IState state);
    public virtual ArrayHolder GetCache(string name, FieldInfos fieldInfos, int readBufferSize, int indexDivisor, IState state);
    public ArrayHolder GetCache(Directory directory, string name, FieldInfos fieldInfos, int readBufferSize, int indexDivisor, IState state);
    public virtual void RemoveFromTermsIndexCache(string name);
    public virtual Lock MakeLock(string name);
    public virtual void ClearLock(string name);
    [ObsoleteAttribute("Use Dispose() instead")]
public void Close();
    public sealed virtual void Dispose();
    protected virtual void Dispose(bool disposing);
    public virtual void SetLockFactory(LockFactory lockFactory);
    public virtual LockFactory get_LockFactory();
    public virtual string GetLockId();
    public virtual string ToString();
    public static void Copy(Directory src, Directory dest, bool closeDirSrc, IState state);
    public void EnsureOpen();
    public bool get_isOpen_ForNUnit();
    [OnDeserializedAttribute]
public void OnDeserialized(StreamingContext _);
}
public class Lucene.Net.Store.FileSwitchDirectory : Directory {
    private Directory secondaryDir;
    private Directory primaryDir;
    private HashSet`1<string> primaryExtensions;
    private bool doClose;
    private bool isDisposed;
    public Directory PrimaryDir { get; }
    public Directory SecondaryDir { get; }
    public FileSwitchDirectory(HashSet`1<string> primaryExtensions, Directory primaryDir, Directory secondaryDir, bool doClose);
    public virtual Directory get_PrimaryDir();
    public virtual Directory get_SecondaryDir();
    protected virtual void Dispose(bool disposing);
    public virtual String[] ListAll(IState state);
    public static string GetExtension(string name);
    private Directory GetDirectory(string name);
    public virtual bool FileExists(string name, IState state);
    public virtual long FileModified(string name, IState state);
    public virtual void TouchFile(string name, IState state);
    public virtual void DeleteFile(string name, IState state);
    public virtual long FileLength(string name, IState state);
    public virtual IndexOutput CreateOutput(string name, IState state);
    public virtual void Sync(string name);
    public virtual IndexInput OpenInput(string name, IState state);
}
public abstract class Lucene.Net.Store.FSDirectory : Directory {
    private static HashAlgorithm DIGESTER;
    private bool checked_Renamed;
    protected internal DirectoryInfo internalDirectory;
    private static Char[] HEX_DIGITS;
    public static int DEFAULT_READ_CHUNK_SIZE;
    private int chunkSize;
    public DirectoryInfo Directory { get; }
    public int ReadChunkSize { get; public set; }
    private static FSDirectory();
    protected internal FSDirectory(DirectoryInfo path, LockFactory lockFactory);
    internal void CreateDir();
    protected internal void InitOutput(string name);
    public static FSDirectory Open(string path);
    public static FSDirectory Open(DirectoryInfo path);
    public static FSDirectory Open(DirectoryInfo path, LockFactory lockFactory);
    public static String[] ListAll(DirectoryInfo dir);
    public virtual String[] ListAll(IState state);
    public virtual bool FileExists(string name, IState state);
    public virtual long FileModified(string name, IState state);
    public static long FileModified(FileInfo directory, string name);
    public virtual void TouchFile(string name, IState state);
    public virtual long FileLength(string name, IState state);
    public virtual void DeleteFile(string name, IState state);
    public virtual void Sync(string name);
    public virtual IndexInput OpenInput(string name, IState state);
    public virtual string GetLockId();
    protected virtual void Dispose(bool disposing);
    public virtual DirectoryInfo get_Directory();
    public virtual string ToString();
    public int get_ReadChunkSize();
    public void set_ReadChunkSize(int value);
}
public abstract class Lucene.Net.Store.FSLockFactory : LockFactory {
    protected internal DirectoryInfo internalLockDir;
    public DirectoryInfo LockDir { get; protected internal set; }
    public virtual DirectoryInfo get_LockDir();
    protected internal virtual void set_LockDir(DirectoryInfo value);
}
public abstract class Lucene.Net.Store.IndexInput : object {
    private bool preUTF8Strings;
    public abstract virtual byte ReadByte(IState state);
    public abstract virtual void ReadBytes(Byte[] b, int offset, int len, IState state);
    public virtual void ReadBytes(Byte[] b, int offset, int len, bool useBuffer, IState state);
    public virtual int ReadInt(IState state);
    public virtual int ReadVInt(IState state);
    public virtual long ReadLong(IState state);
    public virtual long ReadVLong(IState state);
    public virtual void SetModifiedUTF8StringsMode();
    public virtual string ReadString(IState state);
    private string ReadModifiedUTF8String(IState state);
    [ObsoleteAttribute("-- please use ReadString or ReadBytes instead, and construct the string from those utf8 bytes")]
public virtual void ReadChars(Char[] buffer, int start, int length, IState state);
    [ObsoleteAttribute("this method operates on old "modified utf8" encoded strings")]
public virtual void SkipChars(int length, IState state);
    [ObsoleteAttribute("Use Dispose() instead.")]
public void Close();
    public sealed virtual void Dispose();
    protected abstract virtual void Dispose(bool disposing);
    public abstract virtual long FilePointer(IState state);
    public abstract virtual void Seek(long pos, IState state);
    public abstract virtual long Length(IState state);
    public virtual object Clone(IState state);
    public virtual IDictionary`2<string, string> ReadStringStringMap(IState state);
}
public abstract class Lucene.Net.Store.IndexOutput : object {
    private static int COPY_BUFFER_SIZE;
    private Byte[] copyBuffer;
    public long FilePointer { get; }
    public long Length { get; }
    private static IndexOutput();
    public abstract virtual void WriteByte(byte b);
    public virtual void WriteBytes(Byte[] b, int length);
    public abstract virtual void WriteBytes(Byte[] b, int offset, int length);
    public virtual void WriteInt(int i);
    public virtual void WriteVInt(int i);
    public virtual void WriteLong(long i);
    public virtual void WriteVLong(long i);
    public virtual void WriteString(string s);
    [ObsoleteAttribute("-- please pre-convert to utf8 bytes instead or use WriteString")]
public virtual void WriteChars(string s, int start, int length);
    [ObsoleteAttribute("-- please pre-convert to utf8 bytes instead or use WriteString")]
public virtual void WriteChars(Char[] s, int start, int length);
    public virtual void CopyBytes(IndexInput input, long numBytes, IState state);
    public abstract virtual void Flush();
    [ObsoleteAttribute("Use Dispose() instead.")]
public void Close();
    public sealed virtual void Dispose();
    protected abstract virtual void Dispose(bool disposing);
    public abstract virtual long get_FilePointer();
    public abstract virtual void Seek(long pos);
    public abstract virtual long get_Length();
    public virtual void SetLength(long length);
    public virtual void WriteStringStringMap(IDictionary`2<string, string> map);
}
public interface Lucene.Net.Store.IState {
}
public abstract class Lucene.Net.Store.Lock : object {
    public static long LOCK_POLL_INTERVAL;
    public static long LOCK_OBTAIN_WAIT_FOREVER;
    protected internal Exception failureReason;
    private static Lock();
    public abstract virtual bool Obtain();
    public virtual bool Obtain(long lockWaitTimeout);
    public abstract virtual void Release();
    public abstract virtual bool IsLocked();
}
public abstract class Lucene.Net.Store.LockFactory : object {
    protected internal string internalLockPrefix;
    public string LockPrefix { get; public set; }
    public virtual string get_LockPrefix();
    public virtual void set_LockPrefix(string value);
    public abstract virtual Lock MakeLock(string lockName);
    public abstract virtual void ClearLock(string lockName);
}
public class Lucene.Net.Store.LockObtainFailedException : IOException {
    public LockObtainFailedException(string message);
    public LockObtainFailedException(string message, Exception ex);
    public LockObtainFailedException(SerializationInfo info, StreamingContext context);
}
public class Lucene.Net.Store.LockReleaseFailedException : IOException {
    public LockReleaseFailedException(string message);
    public LockReleaseFailedException(string message, Exception innerException);
    public LockReleaseFailedException(SerializationInfo info, StreamingContext context);
}
public class Lucene.Net.Store.LockStressTest : object {
}
public class Lucene.Net.Store.LockVerifyServer : object {
    private static string GetTime(long startTime);
}
public class Lucene.Net.Store.MMapDirectory : FSDirectory {
    private bool useUnmapHack;
    private int maxBBuf;
    public static bool UNMAP_SUPPORTED;
    public bool UseUnmap { get; public set; }
    public int MaxChunkSize { get; public set; }
    public MMapDirectory(DirectoryInfo path, LockFactory lockFactory);
    public MMapDirectory(DirectoryInfo path);
    private static MMapDirectory();
    private void InitBlock();
    public virtual bool get_UseUnmap();
    public virtual void set_UseUnmap(bool value);
    internal void CleanMapping(MemoryStream buffer);
    public virtual int get_MaxChunkSize();
    public virtual void set_MaxChunkSize(int value);
    public virtual IndexInput OpenInput(string name, int bufferSize, IState state);
    public virtual IndexOutput CreateOutput(string name, IState state);
}
internal class Lucene.Net.Store.NativeFSLock : Lock {
    private FileStream f;
    private FileStream channel;
    private bool lock_Renamed;
    private FileInfo path;
    private DirectoryInfo lockDir;
    private static HashSet`1<string> LOCK_HELD;
    public NativeFSLock(DirectoryInfo lockDir, string lockFileName);
    private static NativeFSLock();
    private bool LockExists();
    public virtual bool Obtain();
    public virtual void Release();
    public virtual bool IsLocked();
    public virtual string ToString();
}
public class Lucene.Net.Store.NativeFSLockFactory : FSLockFactory {
    public NativeFSLockFactory(string lockDirName);
    public NativeFSLockFactory(DirectoryInfo lockDir);
    public virtual Lock MakeLock(string lockName);
    public virtual void ClearLock(string lockName);
}
public class Lucene.Net.Store.NIOFSDirectory : FSDirectory {
    public NIOFSDirectory(DirectoryInfo dir, LockFactory lockFactory);
    public virtual IndexOutput CreateOutput(string name, IState state);
}
internal class Lucene.Net.Store.NoLock : Lock {
    public virtual bool Obtain();
    public virtual void Release();
    public virtual bool IsLocked();
    public virtual string ToString();
}
public class Lucene.Net.Store.NoLockFactory : LockFactory {
    private static NoLock singletonLock;
    private static NoLockFactory singleton;
    public static NoLockFactory Instance { get; }
    private static NoLockFactory();
    public static NoLockFactory get_Instance();
    public virtual Lock MakeLock(string lockName);
    public virtual void ClearLock(string lockName);
}
public class Lucene.Net.Store.NoSuchDirectoryException : FileNotFoundException {
    public NoSuchDirectoryException(string message);
    public NoSuchDirectoryException(string message, Exception innerException);
    public NoSuchDirectoryException(SerializationInfo info, StreamingContext context);
}
public class Lucene.Net.Store.RAMDirectory : Directory {
    private static long serialVersionUID;
    protected internal HashMap`2<string, RAMFile> fileMap;
    protected internal long internalSizeInBytes;
    public RAMDirectory(Directory dir, IState state);
    private RAMDirectory(Directory dir, bool closeDir, IState state);
    [OnDeserializedAttribute]
private void OnDeserialized(StreamingContext context);
    public virtual String[] ListAll(IState state);
    public virtual bool FileExists(string name, IState state);
    public virtual long FileModified(string name, IState state);
    public virtual void TouchFile(string name, IState state);
    public virtual long FileLength(string name, IState state);
    public long SizeInBytes();
    public virtual void DeleteFile(string name, IState state);
    public virtual IndexOutput CreateOutput(string name, IState state);
    public virtual IndexInput OpenInput(string name, IState state);
    protected virtual void Dispose(bool disposing);
}
public class Lucene.Net.Store.RAMFile : object {
    private static long serialVersionUID;
    protected List`1<Byte[]> buffers;
    internal long length;
    internal RAMDirectory directory;
    internal long sizeInBytes;
    private long lastModified;
    internal long Length { get; internal set; }
    internal long LastModified { get; internal set; }
    public long SizeInBytes { get; }
    public RAMFile(RAMDirectory directory);
    internal virtual long get_Length();
    internal virtual void set_Length(long value);
    internal virtual long get_LastModified();
    internal virtual void set_LastModified(long value);
    internal Byte[] AddBuffer(int size);
    public Byte[] GetBuffer(int index);
    public int NumBuffers();
    public virtual Byte[] NewBuffer(int size);
    public virtual long get_SizeInBytes();
}
public class Lucene.Net.Store.RAMInputStream : IndexInput {
    internal static int BUFFER_SIZE;
    private RAMFile file;
    private long length;
    private Byte[] currentBuffer;
    private int currentBufferIndex;
    private int bufferPosition;
    private long bufferStart;
    private int bufferLength;
    public RAMInputStream(RAMFile f);
    private static RAMInputStream();
    protected virtual void Dispose(bool disposing);
    public virtual long Length(IState state);
    public virtual byte ReadByte(IState state);
    public virtual void ReadBytes(Byte[] b, int offset, int len, IState state);
    private void SwitchCurrentBuffer(bool enforceEOF);
    public virtual long FilePointer(IState state);
    public virtual void Seek(long pos, IState state);
}
public class Lucene.Net.Store.RAMOutputStream : IndexOutput {
    internal static int BUFFER_SIZE;
    private RAMFile file;
    private Byte[] currentBuffer;
    private int currentBufferIndex;
    private bool isDisposed;
    private int bufferPosition;
    private long bufferStart;
    private int bufferLength;
    public long Length { get; }
    public long FilePointer { get; }
    internal RAMOutputStream(RAMFile f);
    public virtual void WriteTo(IndexOutput out_Renamed);
    public virtual void Reset();
    protected virtual void Dispose(bool disposing);
    public virtual void Seek(long pos);
    public virtual long get_Length();
    public virtual void WriteByte(byte b);
    public virtual void WriteBytes(Byte[] b, int offset, int len);
    private void SwitchCurrentBuffer();
    private void SetFileLength();
    public virtual void Flush();
    public virtual long get_FilePointer();
    public virtual long SizeInBytes();
}
public class Lucene.Net.Store.SimpleFSDirectory : FSDirectory {
    public SimpleFSDirectory(DirectoryInfo path, LockFactory lockFactory);
    public SimpleFSDirectory(DirectoryInfo path);
    public virtual IndexOutput CreateOutput(string name, IState state);
    public virtual IndexInput OpenInput(string name, int bufferSize, IState state);
}
internal class Lucene.Net.Store.SimpleFSLock : Lock {
    internal FileInfo lockFile;
    internal DirectoryInfo lockDir;
    [ObsoleteAttribute("Use the constructor that takes a DirectoryInfo, this will be removed in the 3.0 release")]
public SimpleFSLock(FileInfo lockDir, string lockFileName);
    public SimpleFSLock(DirectoryInfo lockDir, string lockFileName);
    public virtual bool Obtain();
    public virtual void Release();
    public virtual bool IsLocked();
    public virtual string ToString();
}
public class Lucene.Net.Store.SimpleFSLockFactory : FSLockFactory {
    public SimpleFSLockFactory(DirectoryInfo lockDir);
    public SimpleFSLockFactory(string lockDirName);
    public virtual Lock MakeLock(string lockName);
    public virtual void ClearLock(string lockName);
}
internal class Lucene.Net.Store.SingleInstanceLock : Lock {
    internal string lockName;
    private HashSet`1<string> locks;
    public SingleInstanceLock(HashSet`1<string> locks, string lockName);
    public virtual bool Obtain();
    public virtual void Release();
    public virtual bool IsLocked();
    public virtual string ToString();
}
public class Lucene.Net.Store.SingleInstanceLockFactory : LockFactory {
    private HashSet`1<string> locks;
    public virtual Lock MakeLock(string lockName);
    public virtual void ClearLock(string lockName);
}
public static class Lucene.Net.Store.StateHolder : object {
    public static AsyncLocal`1<IState> Current;
    private static StateHolder();
}
public class Lucene.Net.Store.VerifyingLockFactory : LockFactory {
    internal LockFactory lf;
    internal sbyte id;
    internal string host;
    internal int port;
    public VerifyingLockFactory(sbyte id, LockFactory lf, string host, int port);
    public virtual Lock MakeLock(string lockName);
    public virtual void ClearLock(string lockName);
}
public class Lucene.Net.Support.AppSettings : object {
    private static ListDictionary settings;
    private static AppSettings();
    public static void Set(string key, int defValue);
    public static void Set(string key, long defValue);
    public static void Set(string key, string defValue);
    public static void Set(string key, bool defValue);
    public static int Get(string key, int defValue);
    public static long Get(string key, long defValue);
    public static string Get(string key, string defValue);
    public static bool Get(string key, bool defValue);
}
internal class Lucene.Net.Support.AttributeImplItem : object {
    internal Type Key;
    internal Attribute Value;
    internal AttributeImplItem(Type key, Attribute value);
}
public class Lucene.Net.Support.BitSetSupport : object {
    public static int NextSetBit(BitArray bitArray, int index);
    public static int NextClearBit(BitArray bitArray, int index);
    public static int Cardinality(BitArray bits);
}
public class Lucene.Net.Support.BuildType : object {
    public static bool Debug;
}
public class Lucene.Net.Support.Character : object {
    private static char charNull;
    private static char charZero;
    private static char charA;
    public static int MAX_RADIX { get; }
    public static int MIN_RADIX { get; }
    public static int get_MAX_RADIX();
    public static int get_MIN_RADIX();
    public static char ForDigit(int digit, int radix);
}
public class Lucene.Net.Support.CloseableThreadLocalProfiler : object {
    private static bool _enableCloseableThreadLocalProfiler;
    public static List`1<WeakReference> Instances;
    public static bool EnableCloseableThreadLocalProfiler { get; public set; }
    private static CloseableThreadLocalProfiler();
    public static bool get_EnableCloseableThreadLocalProfiler();
    public static void set_EnableCloseableThreadLocalProfiler(bool value);
}
public class Lucene.Net.Support.CollectionsHelper : object {
    public static void Add(Hashtable hashtable, object item);
    public static void AddIfNotContains(Hashtable hashtable, object item);
    public static void AddIfNotContains(ArrayList hashtable, object item);
    public static void AddAll(Hashtable hashtable, ICollection items);
    public static void AddAllIfNotContains(Hashtable hashtable, IList items);
    public static void AddAllIfNotContains(Hashtable hashtable, ICollection items);
    public static void AddAllIfNotContains(IDictionary`2<string, string> hashtable, ICollection`1<string> items);
    public static void AddAll(IDictionary`2<string, string> hashtable, ICollection`1<string> items);
    public static bool Contains(ICollection`1<string> col, string item);
    public static bool Contains(ICollection col, object item);
    public static string CollectionToString(IDictionary`2<string, string> c);
    public static string CollectionToString(ICollection c);
    public static bool CompareStringArrays(String[] l1, String[] l2);
    public static void Sort(IList list, IComparer Comparator);
    public static void Fill(Array array, int fromindex, int toindex, object val);
    public static void Fill(Array array, object val);
    public static bool Equals(Array array1, Array array2);
}
public class Lucene.Net.Support.Compare : object {
    public static bool CompareTermArrays(Term[] t1, Term[] t2);
}
public static class Lucene.Net.Support.Compatibility.SetFactory : object {
    public static ISet`1<T> CreateHashSet();
    public static ISet`1<T> CreateHashSet(IEnumerable`1<T> other);
}
public class Lucene.Net.Support.CRC32 : object {
    private static UInt32[] crcTable;
    private UInt32 crc;
    public long Value { get; }
    private static CRC32();
    private static UInt32[] InitializeCRCTable();
    public sealed virtual long get_Value();
    public sealed virtual void Reset();
    public sealed virtual void Update(int bval);
    public sealed virtual void Update(Byte[] buf, int off, int len);
    public sealed virtual void Update(Byte[] buf);
}
public static class Lucene.Net.Support.Cryptography : object {
    public static bool FIPSCompliant;
    public static HashAlgorithm HashAlgorithm { get; }
    public static HashAlgorithm get_HashAlgorithm();
}
public class Lucene.Net.Support.Deflater : object {
    private SetLevelDelegate setLevelMethod;
    private SetInputDelegate setInputMethod;
    private FinishDelegate finishMethod;
    private GetIsFinishedDelegate getIsFinishedMethod;
    private DeflateDelegate deflateMethod;
    public static int BEST_COMPRESSION;
    public bool IsFinished { get; }
    internal Deflater(object deflaterInstance);
    public void SetLevel(int level);
    public void SetInput(Byte[] input, int offset, int count);
    public void Finish();
    public bool get_IsFinished();
    public int Deflate(Byte[] output);
}
public class Lucene.Net.Support.Double : object {
    public static double Parse(string s);
}
public class Lucene.Net.Support.EquatableList`1 : List`1<T> {
    public EquatableList`1(IEnumerable`1<T> collection);
    public EquatableList`1(int capacity);
    public void AddRange(ICollection c);
    private static Nullable`1<bool> EnumerableCountsEqual(IEnumerable`1<T> x, IEnumerable`1<T> y);
    private static bool Equals(IEnumerable`1<T> x, IEnumerable`1<T> y);
    public sealed virtual bool Equals(IEnumerable`1<T> other);
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
    public static int GetHashCode(IEnumerable`1<T> source);
    public sealed virtual object Clone();
}
public class Lucene.Net.Support.FileSupport : object {
    public static FileInfo[] GetFiles(FileInfo path);
    public static FileInfo[] GetFiles(DirectoryInfo path);
    public static String[] GetLuceneIndexFiles(string fullName, IndexFileNameFilter indexFileNameFilter);
    public static void Sync(FileStream fileStream);
}
public class Lucene.Net.Support.HashMap`2 : HashMap`3<TKey, TValue, IEqualityComparer`1<TKey>> {
    public HashMap`2(int initialCapacity);
    public HashMap`2(IEnumerable`1<KeyValuePair`2<TKey, TValue>> other);
}
[DefaultMemberAttribute("Item")]
public class Lucene.Net.Support.HashMap`3 : object {
    internal TComparer _comparer;
    internal Dictionary`2<TKey, TValue> _dict;
    private bool _isValueType;
    private bool _hasNullValue;
    private TValue _nullValue;
    public int Count { get; }
    public bool IsReadOnly { get; }
    public TValue Item { get; public set; }
    public ICollection`1<TKey> Keys { get; }
    public ICollection`1<TValue> Values { get; }
    public HashMap`3(TComparer comparer);
    public HashMap`3(int initialCapacity, TComparer comparer);
    public HashMap`3(IEnumerable`1<KeyValuePair`2<TKey, TValue>> other, TComparer comparer);
    public bool ContainsValue(TValue value);
    [IteratorStateMachineAttribute("Lucene.Net.Support.HashMap`3/<GetEnumerator>d__9")]
public sealed virtual IEnumerator`1<KeyValuePair`2<TKey, TValue>> GetEnumerator();
    private sealed virtual override IEnumerator System.Collections.IEnumerable.GetEnumerator();
    private sealed virtual override void System.Collections.Generic.ICollection<System.Collections.Generic.KeyValuePair<TKey,TValue>>.Add(KeyValuePair`2<TKey, TValue> item);
    public sealed virtual void Clear();
    private sealed virtual override bool System.Collections.Generic.ICollection<System.Collections.Generic.KeyValuePair<TKey,TValue>>.Contains(KeyValuePair`2<TKey, TValue> item);
    private sealed virtual override void System.Collections.Generic.ICollection<System.Collections.Generic.KeyValuePair<TKey,TValue>>.CopyTo(KeyValuePair`2[] array, int arrayIndex);
    public sealed virtual bool Remove(KeyValuePair`2<TKey, TValue> item);
    public sealed virtual int get_Count();
    public sealed virtual bool get_IsReadOnly();
    public sealed virtual bool ContainsKey(TKey key);
    public sealed virtual void Add(TKey key, TValue value);
    public sealed virtual bool Remove(TKey key);
    public sealed virtual bool TryGetValue(TKey key, TValue& value);
    public sealed virtual TValue get_Item(TKey key);
    public sealed virtual void set_Item(TKey key, TValue value);
    public sealed virtual ICollection`1<TKey> get_Keys();
    public sealed virtual ICollection`1<TValue> get_Values();
}
public static class Lucene.Net.Support.Helper : object {
    public static int MinBuckets;
}
public interface Lucene.Net.Support.IChecksum {
    public long Value { get; }
    public abstract virtual void Reset();
    public abstract virtual void Update(int b);
    public abstract virtual void Update(Byte[] b);
    public abstract virtual void Update(Byte[] b, int offset, int length);
    public abstract virtual long get_Value();
}
public class Lucene.Net.Support.Inflater : object {
    private SetInputDelegate setInputMethod;
    private GetIsFinishedDelegate getIsFinishedMethod;
    private InflateDelegate inflateMethod;
    public bool IsFinished { get; }
    internal Inflater(object inflaterInstance);
    public void SetInput(Byte[] buffer);
    public bool get_IsFinished();
    public int Inflate(Byte[] buffer);
}
public interface Lucene.Net.Support.IThreadRunnable {
    public abstract virtual void Run();
}
public class Lucene.Net.Support.Lucene4x.AtomicInt32 : object {
    private int value;
    public AtomicInt32(int value_);
    public int IncrementAndGet();
    public int GetAndIncrement();
    public int DecrementAndGet();
    public int GetAndDecrement();
    public void Set(int value);
    public int AddAndGet(int value);
    public int Get();
    public bool CompareAndSet(int expect, int update);
    public virtual string ToString();
}
public class Lucene.Net.Support.Number : object {
    public static int MIN_RADIX;
    public static int MAX_RADIX;
    private static string digits;
    public static string ToString(long number);
    public static string ToString(float f);
    public static string ToString(long i, int radix);
    public static long Parse(string s, int radix);
    public static int URShift(int number, int bits);
    public static long URShift(long number, int bits);
    public static int NextSetBit(BitArray bits, int fromIndex);
    public static long ToInt64(string s);
}
public class Lucene.Net.Support.SharpZipLib : object {
    private static Assembly asm;
    private static SharpZipLib();
    public static Deflater CreateDeflater();
    public static Inflater CreateInflater();
}
public class Lucene.Net.Support.Single : object {
    public static float Parse(string s, NumberStyles style, IFormatProvider provider);
    public static float Parse(string s, IFormatProvider provider);
    public static float Parse(string s, NumberStyles style);
    public static float Parse(string s);
    public static bool TryParse(string s, Single& f);
    public static string ToString(float f);
    public static string ToString(float f, string format);
    public static int FloatToIntBits(float value);
    public static float IntBitsToFloat(int value);
}
public class Lucene.Net.Support.TextSupport : object {
    public static void GetCharsFromString(string sourceString, int sourceStart, int sourceEnd, Char[] destinationArray, int destinationStart);
}
public class Lucene.Net.Support.ThreadClass : object {
    private Thread threadField;
    [ThreadStaticAttribute]
private static ThreadClass This;
    public Thread Instance { get; public set; }
    public string Name { get; public set; }
    public ThreadPriority Priority { get; public set; }
    public bool IsAlive { get; }
    public bool IsBackground { get; public set; }
    public ThreadClass(string Name);
    public ThreadClass(ThreadStart Start);
    public ThreadClass(ThreadStart Start, string Name);
    public virtual void Run();
    public virtual void Start();
    public virtual void Interrupt();
    public Thread get_Instance();
    public void set_Instance(Thread value);
    public string get_Name();
    public void set_Name(string value);
    public void SetDaemon(bool isDaemon);
    public ThreadPriority get_Priority();
    public void set_Priority(ThreadPriority value);
    public bool get_IsAlive();
    public bool get_IsBackground();
    public void set_IsBackground(bool value);
    public void Join();
    public void Join(long MiliSeconds);
    public void Join(long MiliSeconds, int NanoSeconds);
    public void Resume();
    public void Abort();
    public void Abort(object stateInfo);
    public void Suspend();
    public virtual string ToString();
    public static ThreadClass CurrentThread();
    public static void Sleep(long ms);
    public static ThreadClass Current();
    public static bool op_Equality(ThreadClass t1, object t2);
    public static bool op_Inequality(ThreadClass t1, object t2);
    public virtual bool Equals(object obj);
    public virtual int GetHashCode();
}
public abstract class Lucene.Net.Support.ThreadLock : object {
    private static ThreadLock _nullLock;
    private static ThreadLock _monitorLock;
    public static ThreadLock NullLock { get; }
    public static ThreadLock MonitorLock { get; }
    private static ThreadLock();
    public abstract virtual void Enter(object obj);
    public abstract virtual void Exit(object obj);
    public static ThreadLock get_NullLock();
    public static ThreadLock get_MonitorLock();
}
public class Lucene.Net.Util.ArrayUtil : object {
    private static int MaxShiftSize;
    public static int ParseInt(Char[] chars);
    public static int ParseInt(Char[] chars, int offset, int len);
    public static int ParseInt(Char[] chars, int offset, int len, int radix);
    private static int Parse(Char[] chars, int offset, int len, int radix, bool negative);
    public static int GetNextSize(int v);
    public static int GetShrinkSize(int currentSize, int targetSize);
    public static Int32[] Grow(Int32[] array, int minSize);
    public static Int32[] Grow(Int32[] array);
    public static Int32[] Shrink(Int32[] array, int targetSize);
    public static Int64[] Grow(Int64[] array, int minSize);
    public static Int64[] Grow(Int64[] array);
    public static Int64[] Shrink(Int64[] array, int targetSize);
    public static Byte[] Grow(Byte[] array, int minSize);
    public static Byte[] Grow(Byte[] array);
    public static Byte[] Shrink(Byte[] array, int targetSize);
    public static int HashCode(Char[] array, int start, int end);
    public static int HashCode(Byte[] array, int start, int end);
}
public abstract class Lucene.Net.Util.Attribute : object {
    public abstract virtual void Clear();
    public virtual string ToString();
    public abstract virtual int GetHashCode();
    public abstract virtual bool Equals(object other);
    public abstract virtual void CopyTo(Attribute target);
    public virtual object Clone();
}
public class Lucene.Net.Util.AttributeSource : object {
    private Dictionary`2<Type, AttributeImplItem> attributes;
    private Dictionary`2<Type, AttributeImplItem> attributeImpls;
    private State[] currentState;
    private AttributeFactory factory;
    private static ConditionalWeakTable`2<Type, LinkedList`1<WeakReference>> knownImplClasses;
    public AttributeFactory Factory { get; }
    public bool HasAttributes { get; }
    public AttributeSource(AttributeSource input);
    public AttributeSource(AttributeFactory factory);
    private static AttributeSource();
    public virtual AttributeFactory get_Factory();
    public virtual IEnumerable`1<Type> GetAttributeTypesIterator();
    [IteratorStateMachineAttribute("Lucene.Net.Util.AttributeSource/<GetAttributeImplsIterator>d__11")]
public virtual IEnumerable`1<Attribute> GetAttributeImplsIterator();
    public void AddAttributeImpl(Attribute att);
    public T AddAttribute();
    private T AddAttributeUnlikely(Type attClass);
    public bool get_HasAttributes();
    public bool HasAttribute();
    public T GetAttribute();
    private static T ThrowArgumentException(Type attClass);
    private State GetCurrentState();
    public void ClearAttributes();
    public State CaptureState();
    public void RestoreState(State state);
    public virtual int GetHashCode();
    public virtual bool Equals(object obj);
    public virtual string ToString();
    public AttributeSource CloneAttributes();
}
public class Lucene.Net.Util.AverageGuessMemoryModel : MemoryModel {
    private Dictionary`2<Type, int> sizes;
    public int ArraySize { get; }
    public int ClassSize { get; }
    public int ReferenceSize { get; }
    private void InitBlock();
    public virtual int get_ArraySize();
    public virtual int get_ClassSize();
    public virtual int GetPrimitiveSize(Type clazz);
    public virtual int get_ReferenceSize();
}
public class Lucene.Net.Util.BitUtil : object {
    public static Byte[] ntzTable;
    private static Byte[] MultiplyDeBruijnBitPosition;
    private static BitUtil();
    public static int Pop(long x);
    public static long Pop_array(Int64[] A, int wordOffset, int numWords);
    public static long Pop_intersect(Int64[] A, Int64[] B, int wordOffset, int numWords);
    public static long Pop_union(Int64[] A, Int64[] B, int wordOffset, int numWords);
    public static long Pop_andnot(Int64[] A, Int64[] B, int wordOffset, int numWords);
    public static long Pop_xor(Int64[] A, Int64[] B, int wordOffset, int numWords);
    public static int Ntz(long val);
    public static int Ntz(int val);
    public static int Ntz2(long x);
    public static int Ntz3(long x);
    public static bool IsPowerOfTwo(int v);
    public static bool IsPowerOfTwo(long v);
    public static int NextHighestPowerOfTwo(int v);
    public static long NextHighestPowerOfTwo(long v);
    public static int FloorLog2(int n);
}
public class Lucene.Net.Util.BitVector : object {
    private Byte[] bits;
    private int size;
    private int count;
    private static Byte[] BYTE_COUNTS;
    public BitVector(int n);
    internal BitVector(Byte[] bits, int size);
    public BitVector(Directory d, string name, IState state);
    private static BitVector();
    public sealed virtual object Clone();
    public void Set(int bit);
    public bool GetAndSet(int bit);
    public void Clear(int bit);
    public bool Get(int bit);
    public int Size();
    public int Count();
    public int GetRecomputedCount();
    public void Write(Directory d, string name, IState state);
    private void WriteBits(IndexOutput output);
    private void WriteDgaps(IndexOutput output);
    private bool IsSparse();
    private void ReadBits(IndexInput input, IState state);
    private void ReadDgaps(IndexInput input, IState state);
    public BitVector Subset(int start, int end);
}
public abstract class Lucene.Net.Util.Cache.Cache`2 : object {
    public static Cache`2<TKey, TValue> SynchronizedCache(Cache`2<TKey, TValue> cache);
    internal virtual Cache`2<TKey, TValue> GetSynchronizedCache();
    public abstract virtual void Put(TKey key, TValue value_Renamed);
    public abstract virtual TValue Get(object key);
    public abstract virtual bool ContainsKey(object key);
    [ObsoleteAttribute("Use Dispose() instead")]
public void Close();
    public sealed virtual void Dispose();
    protected abstract virtual void Dispose(bool disposing);
}
public class Lucene.Net.Util.Cache.SimpleLRUCache`2 : SimpleMapCache`2<TKey, TValue> {
    private int capacity;
    private LinkedList`1<ListValueEntry`2<TKey, TValue, TKey, TValue>> list;
    private Dictionary`2<TKey, LinkedListNode`1<ListValueEntry`2<TKey, TValue, TKey, TValue>>> lookup;
    private LinkedListNode`1<ListValueEntry`2<TKey, TValue, TKey, TValue>> openNode;
    public SimpleLRUCache`2(int Capacity);
    public virtual void Put(TKey Key, TValue Value);
    public virtual TValue Get(object Key);
}
public class Lucene.Net.Util.Cache.SimpleMapCache`2 : Cache`2<TKey, TValue> {
    internal Dictionary`2<TKey, TValue> map;
    public SimpleMapCache`2(Dictionary`2<TKey, TValue> map);
    public virtual TValue Get(object key);
    public virtual void Put(TKey key, TValue value_Renamed);
    public virtual bool ContainsKey(object key);
    protected virtual void Dispose(bool disposing);
    public virtual HashSet`1<TKey> KeySet();
    internal virtual Cache`2<TKey, TValue> GetSynchronizedCache();
}
internal static class Lucene.Net.Util.ConfigurationManager : object {
    private static IConfigurationRoot configuration;
    private static ConfigurationManager();
    public static string GetAppSetting(string key);
}
public class Lucene.Net.Util.Constants : object {
    public static string JAVA_VERSION;
    public static bool JAVA_1_1;
    public static bool JAVA_1_2;
    public static bool JAVA_1_3;
    public static string OS_NAME;
    public static bool LINUX;
    public static bool WINDOWS;
    public static bool SUN_OS;
    public static string OS_ARCH;
    public static string OS_VERSION;
    public static string JAVA_VENDOR;
    public static bool JRE_IS_64BIT;
    public static string LUCENE_MAIN_VERSION;
    public static string LUCENE_VERSION;
    private static Constants();
    private static string Ident(string s);
    private static string GetEnvironmentVariable(string variable, string defaultValueOnSecurityException);
}
public class Lucene.Net.Util.DocIdBitSet : DocIdSet {
    private BitArray bitSet;
    public bool IsCacheable { get; }
    public BitArray BitSet { get; }
    public DocIdBitSet(BitArray bitSet);
    public virtual DocIdSetIterator Iterator(IState state);
    public virtual bool get_IsCacheable();
    public virtual BitArray get_BitSet();
}
[DefaultMemberAttribute("Item")]
public class Lucene.Net.Util.FastList`1 : object {
    private UInt32 _version;
    private UInt32 _size;
    private static T[] EmptyArray;
    private T[] _items;
    private static int DefaultCapacity;
    private static int MaxArrayLength;
    public T Item { get; public set; }
    public T Item { get; public set; }
    public int Capacity { get; public set; }
    public int Count { get; }
    public bool IsReadOnly { get; }
    public FastList`1(int capacity);
    private static FastList`1();
    public sealed virtual T get_Item(int index);
    public sealed virtual void set_Item(int index, T value);
    public T get_Item(UInt32 index);
    public void set_Item(UInt32 index, T value);
    public int get_Capacity();
    public void set_Capacity(int value);
    public sealed virtual int get_Count();
    public sealed virtual bool get_IsReadOnly();
    public sealed virtual void Add(T item);
    public void CopyTo(FastList`1<T> dest);
    private void AddUnlikely(T item, int size);
    private void EnsureCapacity(int min);
    public sealed virtual void Clear();
    public void WeakClear();
    public sealed virtual bool Contains(T item);
    public sealed virtual void CopyTo(T[] array, int arrayIndex);
    public sealed virtual int IndexOf(T item);
    public sealed virtual void Insert(int index, T item);
    public sealed virtual bool Remove(T item);
    public sealed virtual void RemoveAt(int index);
    public void ThrowWhenIndexIsOutOfRange(int index);
    public void RemoveRange(int index, int count);
    public Enumerator<T> GetEnumerator();
    private sealed virtual override IEnumerator System.Collections.IEnumerable.GetEnumerator();
    private sealed virtual override IEnumerator`1<T> System.Collections.Generic.IEnumerable<T>.GetEnumerator();
    public void Sort(IComparer`1<T> comparer);
    public void Sort(Sorter`2& sorter);
    public T[] ToArray();
    public void AddRange(FastList`1<T> src);
}
public class Lucene.Net.Util.FieldCacheSanityChecker : object {
    private RamUsageEstimator ramCalc;
    public void SetRamUsageEstimator(RamUsageEstimator r);
    public static Insanity[] CheckSanity(FieldCache cache);
    public static Insanity[] CheckSanity(CacheEntry[] cacheEntries);
    public Insanity[] Check(CacheEntry[] cacheEntries);
    private List`1<Insanity> CheckValueMismatch(MapOfSets`2<int, CacheEntry> valIdToItems, MapOfSets`2<ReaderField, int> readerFieldToValIds, HashSet`1<ReaderField> valMismatchKeys);
    private List`1<Insanity> CheckSubreaders(MapOfSets`2<int, CacheEntry> valIdToItems, MapOfSets`2<ReaderField, int> readerFieldToValIds);
    private IList GetAllDecendentReaderKeys(object seed);
}
public interface Lucene.Net.Util.IAttribute {
}
internal class Lucene.Net.Util.IdentityStructComparer`1 : ValueType {
    public static IdentityStructComparer`1<TKey> Default;
    public sealed virtual bool Equals(TKey x, TKey y);
    public sealed virtual int GetHashCode(TKey obj);
}
public interface Lucene.Net.Util.ILuceneCloneable {
    public abstract virtual object Clone(IState state);
}
public class Lucene.Net.Util.IndexableBinaryStringTools : object {
    private static CodingCase[] CODING_CASES;
    private static IndexableBinaryStringTools();
    public static int GetEncodedLength(List`1<byte> original);
    public static int GetDecodedLength(List`1<char> encoded);
    public static void Encode(List`1<byte> input, List`1<char> output);
    public static void Decode(List`1<char> input, List`1<byte> output);
    public static List`1<byte> Decode(List`1<char> input);
    public static List`1<char> Encode(List`1<byte> input);
}
internal class Lucene.Net.Util.LightWeightThreadLocal`1 : object {
    [ThreadStaticAttribute]
private static CurrentThreadState<T> _state;
    private WeakReferenceCompareValue`1<T, LightWeightThreadLocal`1<T>> SelfReference;
    private ConcurrentDictionary`2<WeakReferenceCompareValue`1<T, CurrentThreadState<T>>, T> _values;
    private Func`2<IState, T> _generator;
    private bool _disposed;
    private static int GlobalVersion;
    public ICollection`1<T> Values { get; }
    public bool IsValueCreated { get; }
    public LightWeightThreadLocal`1(Func`2<IState, T> generator);
    public ICollection`1<T> get_Values();
    public bool get_IsValueCreated();
    public void Set(T value);
    public T Get(IState state);
    public sealed virtual void Dispose();
}
public abstract class Lucene.Net.Util.Lucene4x.DoubleBarrelLRUCache : object {
}
public class Lucene.Net.Util.Lucene4x.DoubleBarrelLRUCache`2 : DoubleBarrelLRUCache {
    private IDictionary`2<TKey, TValue> cache1;
    private IDictionary`2<TKey, TValue> cache2;
    private AtomicInt32 countdown;
    private Boolean modreq(System.Runtime.CompilerServices.IsVolatile) swapped;
    private int maxSize;
    public DoubleBarrelLRUCache`2(int maxCount);
    public TValue Get(TKey key);
    public void Put(TKey key, TValue value);
}
public class Lucene.Net.Util.MapOfSets`2 : object {
    private IDictionary`2<TKey, HashSet`1<TValue>> theMap;
    public IDictionary`2<TKey, HashSet`1<TValue>> Map { get; }
    public MapOfSets`2(IDictionary`2<TKey, HashSet`1<TValue>> m);
    public virtual IDictionary`2<TKey, HashSet`1<TValue>> get_Map();
    public virtual int Put(TKey key, TValue val);
    public virtual int PutAll(TKey key, IEnumerable`1<TValue> vals);
}
public abstract class Lucene.Net.Util.MemoryModel : object {
    public int ArraySize { get; }
    public int ClassSize { get; }
    public int ReferenceSize { get; }
    public abstract virtual int get_ArraySize();
    public abstract virtual int get_ClassSize();
    public abstract virtual int GetPrimitiveSize(Type clazz);
    public abstract virtual int get_ReferenceSize();
}
public class Lucene.Net.Util.NumericUtils : object {
    public static int PRECISION_STEP_DEFAULT;
    public static char SHIFT_START_LONG;
    public static int BUF_SIZE_LONG;
    public static char SHIFT_START_INT;
    public static int BUF_SIZE_INT;
    private static NumericUtils();
    public static int LongToPrefixCoded(long val, int shift, Span`1<char> buffer);
    private static int ThrowIllegalShift();
    public static string LongToPrefixCoded(long val, int shift);
    public static string LongToPrefixCoded(long val);
    public static int IntToPrefixCoded(int val, int shift, Span`1<char> buffer);
    public static string IntToPrefixCoded(int val, int shift);
    public static string IntToPrefixCoded(int val);
    public static long PrefixCodedToLong(string prefixCoded);
    public static int PrefixCodedToInt(string prefixCoded);
    public static long DoubleToSortableLong(double val);
    public static string DoubleToPrefixCoded(double val);
    public static double SortableLongToDouble(long val);
    public static double PrefixCodedToDouble(string val);
    public static int FloatToSortableInt(float val);
    public static string FloatToPrefixCoded(float val);
    public static float SortableIntToFloat(int val);
    public static float PrefixCodedToFloat(string val);
    public static void SplitLongRange(LongRangeBuilder builder, int precisionStep, long minBound, long maxBound);
    public static void SplitIntRange(IntRangeBuilder builder, int precisionStep, int minBound, int maxBound);
    private static void SplitRange(object builder, int valSize, int precisionStep, long minBound, long maxBound);
    private static void AddRange(object builder, int valSize, long minBound, long maxBound, int shift);
}
public class Lucene.Net.Util.OpenBitSet : DocIdSet {
    protected internal Int64[] internalbits;
    protected internal int wlen;
    public bool IsCacheable { get; }
    public Int64[] Bits { get; public set; }
    public int NumWords { get; public set; }
    public OpenBitSet(long numBits);
    public OpenBitSet(Int64[] bits, int numWords);
    public virtual DocIdSetIterator Iterator(IState state);
    public virtual bool get_IsCacheable();
    public virtual long Capacity();
    public virtual long Size();
    public virtual bool IsEmpty();
    public virtual void set_Bits(Int64[] value);
    public virtual Int64[] get_Bits();
    public virtual int get_NumWords();
    public virtual void set_NumWords(int value);
    public virtual bool Get(int index);
    public virtual bool FastGet(int index);
    public virtual bool Get(long index);
    public virtual bool FastGet(long index);
    public virtual int GetBit(int index);
    public virtual void Set(long index);
    public virtual void FastSet(int index);
    public virtual void FastSet(long index);
    public virtual void Set(long startIndex, long endIndex);
    protected internal virtual int ExpandingWordNum(long index);
    public virtual void FastClear(int index);
    public virtual void FastClear(long index);
    public virtual void Clear(long index);
    public virtual void Clear(int startIndex, int endIndex);
    public virtual void Clear(long startIndex, long endIndex);
    public virtual bool GetAndSet(int index);
    public virtual bool GetAndSet(long index);
    public virtual void FastFlip(int index);
    public virtual void FastFlip(long index);
    public virtual void Flip(long index);
    public virtual bool FlipAndGet(int index);
    public virtual bool FlipAndGet(long index);
    public virtual void Flip(long startIndex, long endIndex);
    public virtual long Cardinality();
    public static long IntersectionCount(OpenBitSet a, OpenBitSet b);
    public static long UnionCount(OpenBitSet a, OpenBitSet b);
    public static long AndNotCount(OpenBitSet a, OpenBitSet b);
    public static long XorCount(OpenBitSet a, OpenBitSet b);
    public virtual int NextSetBit(int index);
    public virtual long NextSetBit(long index);
    public virtual object Clone();
    public virtual void Intersect(OpenBitSet other);
    public virtual void Union(OpenBitSet other);
    public virtual void Remove(OpenBitSet other);
    public virtual void Xor(OpenBitSet other);
    public virtual void And(OpenBitSet other);
    public virtual void Or(OpenBitSet other);
    public virtual void AndNot(OpenBitSet other);
    public virtual bool Intersects(OpenBitSet other);
    public virtual void EnsureCapacityWords(int numWords);
    public virtual void EnsureCapacity(long numBits);
    public virtual void TrimTrailingZeros();
    public static int Bits2words(long numBits);
    public virtual bool Equals(object o);
    public virtual int GetHashCode();
}
public class Lucene.Net.Util.OpenBitSetDISI : OpenBitSet {
    public OpenBitSetDISI(DocIdSetIterator disi, int maxSize, IState state);
    public OpenBitSetDISI(int maxSize);
    public virtual void InPlaceOr(DocIdSetIterator disi, IState state);
    public virtual void InPlaceAnd(DocIdSetIterator disi, IState state);
    public virtual void InPlaceNot(DocIdSetIterator disi, IState state);
    public virtual void InPlaceXor(DocIdSetIterator disi, IState state);
}
public class Lucene.Net.Util.OpenBitSetIterator : DocIdSetIterator {
    internal static UInt32[] bitlist;
    private Int64[] arr;
    private int words;
    private int i;
    private long word;
    private int wordShift;
    private int indexArray;
    private int curDocId;
    public OpenBitSetIterator(OpenBitSet obs);
    public OpenBitSetIterator(Int64[] bits, int numWords);
    private static OpenBitSetIterator();
    private void Shift();
    public virtual int NextDoc(IState state);
    public virtual int Advance(int target, IState state);
    public virtual int DocID();
}
public abstract class Lucene.Net.Util.PriorityQueue`1 : object {
    private int size;
    private int maxSize;
    protected internal T[] heap;
    protected internal T SentinelObject { get; }
    public abstract virtual bool LessThan(T a, T b);
    protected internal virtual T get_SentinelObject();
    protected internal void Initialize(int maxSize);
    public T Add(T element);
    public virtual T InsertWithOverflow(T element);
    public T Top();
    public T Pop();
    public T UpdateTop();
    public int Size();
    public void Clear();
    private void UpHeap();
    private void DownHeap();
}
public class Lucene.Net.Util.RamUsageEstimator : object {
    private MemoryModel memoryModel;
    private Dictionary`2<object, object> seen;
    private int refSize;
    private int arraySize;
    private int classSize;
    private bool checkInterned;
    private static long ONE_KB;
    private static long ONE_MB;
    private static long ONE_GB;
    public RamUsageEstimator(bool checkInterned);
    public RamUsageEstimator(MemoryModel memoryModel);
    public RamUsageEstimator(MemoryModel memoryModel, bool checkInterned);
    private static RamUsageEstimator();
    public long EstimateRamUsage(object obj);
    private long Size(object obj);
    private long SizeOfArray(object obj);
    public static string HumanReadableUnits(long bytes, IFormatProvider df);
}
public class Lucene.Net.Util.ReaderUtil : object {
    public static void GatherSubReaders(IList`1<IndexReader> allSubReaders, IndexReader reader);
    public static IndexReader SubReader(int doc, IndexReader reader);
    public static IndexReader SubReader(IndexReader reader, int subIndex);
    public static int SubIndex(int n, Int32[] docStarts);
}
public class Lucene.Net.Util.ScorerDocQueue : object {
    private HeapedScorerDoc[] heap;
    private int maxSize;
    private int size;
    private HeapedScorerDoc topHSD;
    public int MaxSize { get; }
    public ScorerDocQueue(int maxSize);
    public int get_MaxSize();
    public void Put(Scorer scorer);
    public virtual bool Insert(Scorer scorer);
    public Scorer Top();
    public int TopDoc();
    public float TopScore(IState state);
    public bool TopNextAndAdjustElsePop(IState state);
    public bool TopSkipToAndAdjustElsePop(int target, IState state);
    private bool CheckAdjustElsePop(bool cond);
    public Scorer Pop();
    private void PopNoResult();
    public void AdjustTop();
    public int Size();
    public void Clear();
    private void UpHeap();
    private void DownHeap();
}
public class Lucene.Net.Util.SimpleStringInterner : StringInterner {
    private Entry[] cache;
    private int maxChainLength;
    public SimpleStringInterner(int tableSize, int maxChainLength);
    public virtual string Intern(string s);
}
public class Lucene.Net.Util.SmallFloat : object {
    public static sbyte FloatToByte(float f, int numMantissaBits, int zeroExp);
    public static float ByteToFloat(byte b, int numMantissaBits, int zeroExp);
    public static sbyte FloatToByte315(float f);
    public static float Byte315ToFloat(byte b);
    public static sbyte FloatToByte52(float f);
    public static float Byte52ToFloat(byte b);
}
public class Lucene.Net.Util.SortedVIntList : DocIdSet {
    internal static int BITS2VINTLIST_SIZE;
    private int size;
    private SByte[] bytes;
    private int lastBytePos;
    private static int VB1;
    private static int BIT_SHIFT;
    private int MAX_BYTES_PER_INT;
    public int Size { get; }
    public int ByteSize { get; }
    public bool IsCacheable { get; }
    public SortedVIntList(Int32[] sortedInts);
    public SortedVIntList(Int32[] sortedInts, int inputSize);
    public SortedVIntList(BitArray bits);
    public SortedVIntList(OpenBitSet bits);
    public SortedVIntList(DocIdSetIterator docIdSetIterator, IState state);
    private void InitBytes();
    private void ResizeBytes(int newSize);
    public virtual int get_Size();
    public virtual int get_ByteSize();
    public virtual bool get_IsCacheable();
    public virtual DocIdSetIterator Iterator(IState state);
}
public class Lucene.Net.Util.Sorter`2 : ValueType {
    private TSorter _sorter;
    private static int SizeThreshold;
    public Sorter`2(TSorter sorter);
    public void Sort(T[] keys);
    public void Sort(T[] keys, int index, int length);
    private void SwapIfGreaterWithItems3(T[] keys, int a, int b, int c);
    private void SwapIfGreaterWithItems(T[] keys, int a, int b);
    private bool TrySwapIfGreaterWithItems(T[] keys, int a, int b);
    private void Swap(T[] keys, int x, int y);
    private void IntroSort(T[] keys, int lo, int hi, int depthLimit);
    private int PickPivotAndPartitionUnlikely(T[] keys, int lo, int hi, int middle);
    private void HeapSort(T[] keys, int lo, int hi);
    private void DownHeap(T[] keys, int i, int n, int lo);
    private void InsertionSort(T[] keys, int lo, int hi);
}
public class Lucene.Net.Util.Sorter`3 : ValueType {
    private TSorter _sorter;
    private static int SizeThreshold;
    public Sorter`3(TSorter sorter);
    public void Sort(T[] keys, V[] values);
    public void Sort(T[] keys, V[] values, int index, int length);
    private void SwapIfGreaterWithItems3(T[] keys, V[] values, int a, int b, int c);
    private void Swap(T[] keys, V[] values, int x, int y);
    private void IntroSort(T[] keys, V[] values, int lo, int hi, int depthLimit);
    private int PickPivotAndPartitionUnlikely(T[] keys, V[] values, int lo, int hi, int middle);
    private void HeapSort(T[] keys, V[] values, int lo, int hi);
    private void DownHeap(T[] keys, V[] values, int i, int n, int lo);
    private void InsertionSort(T[] keys, V[] values, int lo, int hi);
}
public abstract class Lucene.Net.Util.SorterTemplate : object {
    private static int MERGESORT_THRESHOLD;
    private static int QUICKSORT_THRESHOLD;
    protected internal abstract virtual void Swap(int i, int j);
    protected internal abstract virtual int Compare(int i, int j);
    public virtual void QuickSort(int lo, int hi);
    private void QuickSortHelper(int lo, int hi);
    private void InsertionSort(int lo, int hi);
    protected internal virtual void MergeSort(int lo, int hi);
    private void Merge(int lo, int pivot, int hi, int len1, int len2);
    private void Rotate(int lo, int mid, int hi);
    private int Lower(int lo, int hi, int val);
    private int Upper(int lo, int hi, int val);
}
public abstract class Lucene.Net.Util.StringHelper : object {
    public static StringInterner interner;
    private static StringHelper();
    public static string Intern(string s);
    public static int BytesDifference(Byte[] bytes1, int len1, Byte[] bytes2, int len2);
    public static int StringDifference(string s1, string s2);
}
public class Lucene.Net.Util.StringInterner : object {
    public virtual string Intern(string s);
    public virtual string Intern(Char[] arr, int offset, int len);
}
public class Lucene.Net.Util.ToStringUtils : object {
    public static string Boost(float boost);
}
public static class Lucene.Net.Util.UnicodeUtil : object {
    public static int UNI_SUR_HIGH_START;
    public static int UNI_SUR_HIGH_END;
    public static int UNI_SUR_LOW_START;
    public static int UNI_SUR_LOW_END;
    public static int UNI_REPLACEMENT_CHAR;
    private static long UNI_MAX_BMP;
    private static int HALF_BASE;
    private static long HALF_SHIFT;
    private static long HALF_MASK;
    public static void UTF16toUTF8(Char[] source, int offset, UTF8Result result);
    public static void UTF16toUTF8(Char[] source, int offset, int length, UTF8Result result);
    public static void UTF16toUTF8(string s, int offset, int length, UTF8Result result);
    public static void UTF8toUTF16(Byte[] utf8, int offset, int length, UTF16Result result);
}
[DefaultMemberAttribute("Item")]
public class Lucene.Net.Util.UnmanagedStringArray : object {
    private UnmanagedString[] _strings;
    private List`1<Segment> _segments;
    public int _index;
    public int Length { get; }
    public UnmanagedString Item { get; public set; }
    public UnmanagedStringArray(int size);
    public int get_Length();
    private Segment GetSegment(int size);
    private static int AdjustSegmentSize(int segmentSize, int size);
    private Segment GetAndAddNewSegment(int segmentSize);
    public void Add(Span`1<char> str);
    public void AddDeleted(TermBuffer termBuffer);
    public UnmanagedString get_Item(int position);
    public void set_Item(int position, UnmanagedString value);
    public sealed virtual void Dispose();
}
public enum Lucene.Net.Util.Version : Enum {
    public int value__;
    public static Version LUCENE_20;
    public static Version LUCENE_21;
    public static Version LUCENE_22;
    public static Version LUCENE_23;
    public static Version LUCENE_24;
    public static Version LUCENE_29;
    public static Version LUCENE_30;
    [ObsoleteAttribute("Use an actual version instead.")]
public static Version LUCENE_CURRENT;
}
[ExtensionAttribute]
public static class Lucene.Net.Util.VersionEnumExtensions : object {
    [ExtensionAttribute]
public static bool OnOrAfter(Version first, Version other);
}
[CompilerGeneratedAttribute]
[EmbeddedAttribute]
internal class Microsoft.CodeAnalysis.EmbeddedAttribute : Attribute {
}
public class Simplicit.Net.Lzo.LZOCompressor : object {
    private static TraceSwitch _traceSwitch;
    private Byte[] _workMemory;
    public string Version { get; }
    public string VersionDate { get; }
    private static LZOCompressor();
    private static int __lzo_init3();
    private static string lzo_version_string();
    private static string lzo_version_date();
    private static int lzo1x_1_compress(Byte[] src, int src_len, Byte[] dst, Int32& dst_len, Byte[] wrkmem);
    private static int lzo1x_decompress(Byte[] src, int src_len, Byte[] dst, Int32& dst_len, Byte[] wrkmem);
    public string get_Version();
    public string get_VersionDate();
    public Byte[] Compress(Byte[] src);
    public Byte[] Decompress(Byte[] src);
}
[CompilerGeneratedAttribute]
[EmbeddedAttribute]
[AttributeUsageAttribute("2")]
internal class System.Runtime.CompilerServices.RefSafetyRulesAttribute : Attribute {
    public int Version;
    public RefSafetyRulesAttribute(int );
}
